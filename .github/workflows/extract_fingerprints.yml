name: Extract fingerprints

on:
  workflow_dispatch:
    inputs:
      model:
        description: "OpenAI model name"
        required: true
        default: "gpt-4.1"

jobs:
  extract:
    runs-on: ubuntu-latest
    timeout-minutes: 360

    steps:
      - name: Check out repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install openai

      - name: Run batch extraction (all chats, writes per batch)
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          set -euo pipefail

          MODEL="${{ inputs.model }}"
          BATCH_SIZE=100
          SYNTHESIS_DIR="synthesis"
          echo "Model: ${MODEL}"
          echo "Batch size: ${BATCH_SIZE}"
          echo "Synthesis dir: ${SYNTHESIS_DIR}"

          mkdir -p "${SYNTHESIS_DIR}"

          # Full run: process all chats. Each batch is persisted immediately to avoid loss on timeouts.
          python extract_fingerprints.py \
            --input_dir output \
            --largest \
            --batch-size "${BATCH_SIZE}" \
            --synthesis-dir "${SYNTHESIS_DIR}" \
            --model "${MODEL}" \
            --out "${SYNTHESIS_DIR}/fingerprints_full.md" \
            --cache .fingerprint_cache_preview_10.json

          echo "Batch outputs written to ${SYNTHESIS_DIR}"
          ls -la "${SYNTHESIS_DIR}"

      - name: Upload results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: fingerprints_preview_10
          compression-level: 0
          path: |
            synthesis
            .fingerprint_cache_preview_10.json
