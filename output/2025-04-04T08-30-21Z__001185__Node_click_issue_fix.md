# Node click issue fix

## You (2025-04-04T08:30:21.282000+00:00)

I have the following python file, but i am not able to to click on any of the nodes of my sankey chart. Help me diagnose the problem. 

here're the necessary file paths:
/Users/sakshatgoyal/Desktop/Strategic Decision Making Work/Data Viz experiment/Business-Level Strategy Tagging - Compilation.csv
/Users/sakshatgoyal/Desktop/Strategic Decision Making Work/Data Viz experiment/sankey_analyzer.py

I need to work through a virtual environment:
(venv) sakshatgoyal@MacBook-Pro Data Viz experiment %


here's the python script:

import pandas as pd
import plotly.graph_objects as go
import dash
from dash import dcc, html
from dash.dependencies import Input, Output, State
import json
import copy # Needed for deepcopy
import numpy as np # For handling potential NaN comparisons safely

# --- Configuration ---
# <<< --- MAKE SURE THIS PATH IS CORRECT FOR YOUR SYSTEM --- >>>
CSV_FILE_PATH = 'Business-Level Strategy Tagging - Compilation.csv'

# Define the exact order of stages for the Sankey flow
STAGE_COLUMNS = [
    'Ambiguity Type',
    'Framing Move',
    'Stabilizer',
    'False Clarity',
    'Tension Axis',
    'Org Implication',
    'Friction Archetype'
]

# Define additional columns for filtering
FILTER_COLUMNS = [
    'Regulatory Scope',
    'Temporal Coupling Sensitivity',
    'Market Dispersion',
    'Capital Substrate Intensity',
    'Decomposability Gradient',
    'Temporal Value Elasticity',
    'Knowledge Codifiability'
]

# --- Styling ---
HIGHLIGHT_COLOR = 'rgba(255, 165, 0, 0.8)'  # Orange with some transparency
DEFAULT_COLOR = 'rgba(200, 200, 200, 0.5)' # Light gray with transparency
NODE_PAD = 25  # Generous node padding
NODE_THICKNESS = 15
FONT_SIZE = 10
SANKEY_HEIGHT = 750 # Adjust as needed for 4:3 ratio relative to width

# --- Helper Functions ---

def load_data(filepath):
    """Loads and performs initial cleaning on the CSV data."""
    try:
        df = pd.read_csv(filepath)
        # Ensure all relevant columns are treated as strings for consistent grouping
        for col in STAGE_COLUMNS + FILTER_COLUMNS:
            if col in df.columns:
                # Convert to string, handling potential NaN values first
                df[col] = df[col].fillna('Unknown').astype(str).str.strip()
            else:
                print(f"Warning: Column '{col}' not found in CSV. Filling with 'Unknown'.")
                # Create missing columns with a default value
                df[col] = 'Unknown'
        print(f"Data loaded successfully: {df.shape[0]} rows")
        return df
    except FileNotFoundError:
        print(f"Error: File not found at {filepath}")
        return pd.DataFrame() # Return empty DataFrame on error
    except Exception as e:
        print(f"Error loading data: {e}")
        return pd.DataFrame()

def prepare_sankey_data(df, stage_cols):
    """
    Prepares node and link data structures for Plotly Sankey based on the provided DataFrame.
    Handles unique node identification across all stages.
    Returns nodes dictionary, links dictionary, and node_map (unique_id -> index).
    """
    if df is None or df.empty:
        print("Warning: prepare_sankey_data received an empty DataFrame.")
        return {'labels': [], 'x': [], 'y': []}, {'source': [], 'target': [], 'value': [], 'label': []}, {}

    all_nodes_info = [] # Store dicts {'label': str, 'id': str, 'stage': str}
    node_x_positions = {}
    node_y_positions = {}

    # Calculate node positions
    num_stages = len(stage_cols)
    stage_width = 1.0 / (num_stages - 1) if num_stages > 1 else 1.0

    # Define nodes and their positions
    for i, col in enumerate(stage_cols):
        # Use dropna() before unique() if NaNs weren't filled earlier, though load_data now fills them
        unique_values = sorted(df[col].unique())
        x_pos = i * stage_width if num_stages > 1 else 0.5 # Normalized x position (0 to 1)
        num_nodes_in_stage = len(unique_values)
        y_increment = 1.0 / (num_nodes_in_stage + 1) if num_nodes_in_stage > 0 else 1.0

        for j, node_label in enumerate(unique_values):
            # Create a unique ID combining stage and label
            unique_node_id = f"{col}_{node_label}"
            # Ensure node isn't already added (though structure implies it shouldn't be)
            if unique_node_id not in [n['id'] for n in all_nodes_info]:
                all_nodes_info.append({'label': str(node_label), 'id': unique_node_id, 'stage': col})
                node_x_positions[unique_node_id] = x_pos
                node_y_positions[unique_node_id] = (j + 1) * y_increment # Distribute vertically

    # Create mapping from unique ID to index (required by Plotly Sankey)
    node_map = {node['id']: i for i, node in enumerate(all_nodes_info)}
    node_labels = [node['label'] for node in all_nodes_info]
    node_final_x = [node_x_positions[node['id']] for node in all_nodes_info]
    node_final_y = [node_y_positions[node['id']] for node in all_nodes_info]

    # --- Generate Links ---
    links_list = [] # Store dicts {'source': int, 'target': int, 'value': int, 'label': str}
    for i in range(num_stages - 1):
        source_col = stage_cols[i]
        target_col = stage_cols[i+1]

        # Group by source and target in consecutive stages to get link values
        grouped = df.groupby([source_col, target_col], observed=False).size().reset_index(name='value')

        for _, row in grouped.iterrows():
            source_id = f"{source_col}_{row[source_col]}"
            target_id = f"{target_col}_{row[target_col]}"

            # Check if nodes exist in our map
            if source_id in node_map and target_id in node_map:
                links_list.append({
                    'source': node_map[source_id],
                    'target': node_map[target_id],
                    'value': row['value'],
                    'label': f"{row[source_col]} -> {row[target_col]}" # For tooltips
                })
            # else:
            #      print(f"Warning: Skipping link due to missing node mapping for {source_id} or {target_id}")

    # Convert list of dicts to dict of lists for Plotly
    links = {
        'source': [link['source'] for link in links_list],
        'target': [link['target'] for link in links_list],
        'value': [link['value'] for link in links_list],
        'label': [link['label'] for link in links_list],
    }
    nodes = {'labels': node_labels, 'x': node_final_x, 'y': node_final_y}

    # Add stage info to nodes dict for easier access later if needed
    nodes['stages'] = [node['stage'] for node in all_nodes_info]

    # print(f"Prepared Sankey Data: {len(nodes['labels'])} nodes, {len(links['source'])} links.") # Debug
    return nodes, links, node_map

# --- Load Initial Data ---
df_full = load_data(CSV_FILE_PATH)

# --- Calculate Full Structure Data Globally (Fixes Dependency Cycle) ---
if not df_full.empty:
    print("Calculating initial full Sankey structure...")
    # Store the results in global variables
    full_nodes_data, full_links_data, full_node_map = prepare_sankey_data(df_full, STAGE_COLUMNS)
    print(f"Full structure calculated: {len(full_nodes_data['labels'])} nodes, {len(full_links_data['source'])} links.")
else:
    # Handle case where data loading failed
    full_nodes_data, full_links_data, full_node_map = {'labels': [], 'x': [], 'y': [], 'stages':[]}, {'source': [], 'target': [], 'value': [], 'label': []}, {}
    print("Warning: Data loading failed, Sankey will be empty.")

# --- Initialize Dash App ---
# suppress_callback_exceptions=True might not be needed now cycle is fixed
app = dash.Dash(__name__)
server = app.server # For potential deployment

# --- App Layout ---
app.layout = html.Div([
    html.H1("Strategy Analysis: Ambiguity Framing & Resolution Flow"),

    html.Div([
        # Filter Dropdowns
        html.Div([
            html.Label(f"{col}:"),
            dcc.Dropdown(
                id=f'filter-{col}',
                # Get options from the *full* dataset to ensure all are always available
                options=[{'label': i, 'value': i} for i in sorted(df_full[col].unique())] if col in df_full else [],
                multi=True, # Allow multiple selections per filter
                placeholder=f"Select {col}..."
            )
        ], style={'width': '30%', 'display': 'inline-block', 'padding': '5px'})
        for col in FILTER_COLUMNS
    ], style={'marginBottom': '20px'}),

    # Buttons
    html.Button('Reset View / Filters', id='reset-button', n_clicks=0),
    html.Button('Reset Node Selection', id='reset-node-button', n_clicks=0, style={'marginLeft': '10px'}),

    # Sankey Diagram Area
    dcc.Loading(
        id="loading-sankey",
        type="circle",
        children=dcc.Graph(id='sankey-diagram', config={'displayModeBar': True})
    ),

    # Hidden storage for state
    dcc.Store(id='selected-node-store', data=None), # Stores {'label': str, 'stage': str} or None
    dcc.Store(id='current-filters-store', data={col: None for col in FILTER_COLUMNS}),
    # REMOVED: dcc.Store(id='full-structure-store') # No longer needed

    # Debug Output Area
    html.Div(id='debug-output', style={'marginTop': '20px', 'whiteSpace': 'pre-wrap', 'fontFamily': 'monospace'})
])

# --- Callbacks ---

# Callback 1: Update the 'current-filters-store' when dropdowns change
@app.callback(
    Output('current-filters-store', 'data'),
    [Input(f'filter-{col}', 'value') for col in FILTER_COLUMNS]
)
def update_filters_store(*filter_values):
    # Stores the current selections from all filter dropdowns
    filters = {col: val for col, val in zip(FILTER_COLUMNS, filter_values)}
    # print(f"Debug: Filters updated in store: {filters}") # Optional Debug
    return filters

# Callback 2: Handle node selection clicks and reset buttons
@app.callback(
    Output('selected-node-store', 'data'),
    Input('sankey-diagram', 'clickData'),
    Input('reset-node-button', 'n_clicks'),
    Input('reset-button', 'n_clicks'), # Main reset also clears node selection
    State('selected-node-store', 'data'), # Get current selection to check for re-click
    prevent_initial_call=True # Don't run on startup
)
def store_selected_node(clickData, reset_node_clicks, reset_all_clicks, current_selection):
    # This callback determines which node (if any) was clicked and stores its info.
    print("\n--- store_selected_node ---") # Debug separator

    # Determine what triggered the callback
    ctx = dash.callback_context
    triggered_id = ctx.triggered[0]['prop_id'].split('.')[0] if ctx.triggered else 'No trigger'
    print(f"Triggered by: {triggered_id}")

    # Handle Reset button clicks
    if triggered_id in ['reset-node-button', 'reset-button']:
        print("Resetting node selection via button.")
        return None # Clear selection

    # Handle clicks on the Sankey diagram
    # Handle clicks on the Sankey diagram
    if clickData:
        # Debug: Print the raw clickData received from Plotly
        print(f"clickData received: {json.dumps(clickData, indent=2)}")

        if 'points' in clickData and len(clickData['points']) > 0:
            point_data = clickData['points'][0]

            # --- CORRECTED LOGIC: Check for 'x' FIRST to identify NODE clicks ---
            if 'x' in point_data and 'label' in point_data:
                # Assume it's a NODE click because 'x' coordinate is present
                node_x = point_data['x'] # We know 'x' exists now
                node_label = point_data['label']
                print(f"DEBUG: Potential NODE click detected. Label: '{node_label}', X-coord: {node_x:.3f}")

                # Determine the stage by finding the closest calculated stage X position
                clicked_stage = None
                min_diff = float('inf')
                num_stages = len(STAGE_COLUMNS)
                stage_width = 1.0 / (num_stages - 1) if num_stages > 1 else 1.0

                for i, stage in enumerate(STAGE_COLUMNS):
                    expected_x = i * stage_width if num_stages > 1 else 0.5
                    diff = abs(node_x - expected_x)

                    # Check if click X is reasonably close to the expected stage X
                    if diff < min_diff and diff < (stage_width / 2):
                        min_diff = diff
                        clicked_stage = stage

                if clicked_stage:
                    # Successfully identified node label and stage
                    selected_info = {'label': node_label, 'stage': clicked_stage}
                    print(f"Node identified: {selected_info}")

                    # Check if the user clicked the *same node* that is already selected
                    if current_selection == selected_info:
                        print("Clicked same node again, resetting selection.")
                        return None # Reset selection (toggle behavior)
                    else:
                        # Store the newly selected node info
                        print(f"DEBUG: store_selected_node is RETURNING: {selected_info}") # Keep this debug print
                        return selected_info
                else:
                    # Node click detected ('x' present), but couldn't match to a stage boundary
                    print(f"Clicked node '{node_label}' at x={node_x:.3f}, but couldn't reliably match to a stage boundary. Ignoring click.")
                    # Return current selection to avoid changing state on ambiguous click
                    return current_selection

            elif 'label' in point_data:
                # If 'label' is present BUT 'x' is NOT, it's likely a LINK click
                link_label = point_data['label']
                print(f"DEBUG: LINK click detected (Label: '{link_label}', no 'x' coordinate). Ignoring for selection.")
                # Do not change the selection state when a link is clicked
                raise dash.exceptions.PreventUpdate
            else:
                # Click data point exists but lacks expected 'label' or 'x'
                print("DEBUG: Click detected, but data point lacked expected 'label' or 'x'. Ignoring.")
                raise dash.exceptions.PreventUpdate
        else:
            # clickData was present but had no 'points' array or it was empty
             print("DEBUG: Click event had no 'points' data. Ignoring.")
             raise dash.exceptions.PreventUpdate
    # If clickData itself is None (e.g., click on background?), do nothing
    # print("DEBUG: clickData was None.") # Optional debug
    raise dash.exceptions.PreventUpdate


# Callback 3: Main callback to update the Sankey diagram
@app.callback(
    Output('sankey-diagram', 'figure'),
    Output('debug-output', 'children'), # Output for status messages
    # --- Inputs ---
    Input('current-filters-store', 'data'), # From Callback 1
    Input('selected-node-store', 'data'),   # From Callback 2
    Input('reset-button', 'n_clicks')       # Trigger on main reset button
    # REMOVED: Input('full-structure-store', 'data') # No longer needed
)
def update_sankey(filters_data, selected_node_data, reset_clicks):
    # This function redraws the Sankey based on filters and node selection.

    # Use context to see what triggered the update (useful for debugging)
    ctx = dash.callback_context
    triggered_id = ctx.triggered[0]['prop_id'].split('.')[0] if ctx.triggered else 'initial load'
    print(f"\n>>> Updating Sankey Diagram <<< --- Triggered by: {triggered_id}") # Debug separator
    print(f"Filters received: {filters_data}")
    print(f"Selected node received: {selected_node_data}")

    # --- 1. Apply Dropdown Filters to the Full Dataset ---
    df_filtered = df_full.copy() # Start with the original full data
    active_filters = {}
    if filters_data: # Check if filters_data dict itself is not None
        for col, values in filters_data.items():
            # Check if filter has selected values and exists in DataFrame
            if values and col in df_filtered.columns:
                df_filtered = df_filtered[df_filtered[col].isin(values)]
                active_filters[col] = values # Track active filters for title

    # Handle case where filtering results in an empty DataFrame
    if df_filtered.empty and not df_full.empty:
        print("Warning: Filtering resulted in an empty dataset.")
        # Return an empty figure with a message
        return go.Figure(layout={'title': 'No data matches the selected filters.', 'height': SANKEY_HEIGHT}), "No data matches filters."

    # --- 2. Determine Cohort based on Node Selection ---
    df_cohort = None
    highlighting_active = False # Flag to indicate if we are highlighting a selection
    debug_msg_lines = [f"Filters applied: {active_filters}"] # Build debug message

    # Check if a node is selected and the data is valid
    if selected_node_data and isinstance(selected_node_data, dict) and \
       'stage' in selected_node_data and 'label' in selected_node_data and \
       selected_node_data['stage'] in STAGE_COLUMNS:

        highlighting_active = True
        node_label = selected_node_data['label']
        node_stage = selected_node_data['stage']
        print(f"Highlighting Active: Filtering cohort for Stage='{node_stage}', Label='{node_label}'")

        # Filter the *dropdown-filtered data* further to get the specific cohort rows
        try:
            # Ensure comparison works correctly even if labels are numbers stored as strings
            cohort_condition = df_filtered[node_stage].astype(str) == str(node_label)
            df_cohort = df_filtered[cohort_condition]
            # <<< --- ADD THESE LINES START --- >>>
            print(f"DEBUG: Cohort DataFrame shape: {df_cohort.shape}")
            if df_cohort.empty:
                print(f"DEBUG: df_cohort IS EMPTY. Condition was: {node_stage} == '{node_label}'")
            else:
                print(f"DEBUG: df_cohort Head:\n{df_cohort.head().to_string()}")
            # <<< --- ADD THESE LINES END --- >>>
        except KeyError:
            print(f"Error: Stage column '{node_stage}' not found while filtering cohort. This shouldn't happen.")
            highlighting_active = False  # Turn off highlighting if error occurs
            df_cohort = None

        if df_cohort is None or df_cohort.empty:
            print(f"Warning: Cohort for {selected_node_data} is empty within the filtered data.")
            highlighting_active = False  # Turn off highlighting
            debug_msg_lines.append(f"Selected node [{selected_node_data.get('label', 'N/A')} in {selected_node_data.get('stage', 'N/A')}] resulted in an empty cohort.")
        else:
            debug_msg_lines.append(f"Highlighting cohort ({len(df_cohort)} rows) for node [{node_label} in {node_stage}]")
    else:
        # No node selected or selection data is invalid
        debug_msg_lines.append(f"Displaying filtered data ({len(df_filtered)} rows). No node selected for highlighting.")


    # --- 3. Use Globally Prepared Sankey Structure ---
    # These were calculated once at the start using the full dataset
    nodes_struct = full_nodes_data
    links_struct = full_links_data
    node_map = full_node_map

    # Check if the global structure is valid
    if not nodes_struct or not links_struct or not node_map or not nodes_struct['labels']:
         print("Error: Global Sankey structure is missing or invalid.")
         return go.Figure(layout={'title': 'Error: Sankey structure data is missing.', 'height': SANKEY_HEIGHT}), "Error: Missing structure data."

    # --- IMPORTANT: Make deep copies to avoid modifying the global structure ---
    # We will modify link values and colors for the specific view.
    links_view_data = copy.deepcopy(links_struct)

    # --- 4. Determine Link Colors and Values for the Current View ---
    link_colors = [DEFAULT_COLOR] * len(links_view_data['source'])
    # Store counts for links *within the current cohort* if highlighting
    cohort_link_counts = {} # Key: (source_idx, target_idx), Value: count in cohort

    if highlighting_active and df_cohort is not None and not df_cohort.empty:
        print(f"Calculating cohort link counts for {len(df_cohort)} rows...")
        # Calculate counts for each link segment based *only* on the cohort data
        for i in range(len(STAGE_COLUMNS) - 1):
            source_col = STAGE_COLUMNS[i]
            target_col = STAGE_COLUMNS[i+1]
            # Group cohort rows by this specific transition
            grouped_cohort = df_cohort.groupby([source_col, target_col], observed=False).size().reset_index(name='cohort_count')

            for _, row in grouped_cohort.iterrows():
                # Map labels back to unique IDs and then to indices from the *full* structure map
                source_id = f"{source_col}_{row[source_col]}"
                target_id = f"{target_col}_{row[target_col]}"
                if source_id in node_map and target_id in node_map:
                    source_idx = node_map[source_id]
                    target_idx = node_map[target_id]
                    cohort_link_counts[(source_idx, target_idx)] = row['cohort_count']

        # Apply highlighting and adjust link values for visualization
        highlighted_links_count = 0
        for i in range(len(links_view_data['source'])):
            link_tuple = (links_view_data['source'][i], links_view_data['target'][i])
            if link_tuple in cohort_link_counts:
                # This link is part of the highlighted cohort
                link_colors[i] = HIGHLIGHT_COLOR
                # Set the *visual value* (thickness) to the cohort count
                links_view_data['value'][i] = cohort_link_counts[link_tuple]
            else:
                # This link is NOT part of the cohort, make it visually minimal
                link_colors[i] = DEFAULT_COLOR
                links_view_data['value'][i] = 0.001 # Use a tiny value instead of 0 for visibility if needed, 0 might hide it completely
        print(f"DEBUG: Number of links colored for highlight: {highlighted_links_count}")
    # --- 5. Prepare Tooltip Data ---
    # Determine the reference DataFrame for counts (cohort if highlighting, filtered otherwise)
    df_for_counts = df_cohort if highlighting_active and df_cohort is not None else df_filtered
    total_rows_in_view = len(df_for_counts)
    # Avoid division by zero for percentages
    total_rows_divisor = total_rows_in_view if total_rows_in_view > 0 else 1

    # Calculate Node counts and percentages for tooltips based on the current view
    node_counts_in_view = {}
    for stage in STAGE_COLUMNS:
        counts = df_for_counts[stage].value_counts()
        for label, count in counts.items():
            node_id = f"{stage}_{label}"
            if node_id in node_map:
                node_idx = node_map[node_id]
                node_counts_in_view[node_idx] = count

    node_customdata = [] # Will store [stage_name, percentage, count] for each node
    for i in range(len(nodes_struct['labels'])):
        count = node_counts_in_view.get(i, 0) # Get count for this node index in the current view
        percentage = (count / total_rows_divisor) * 100
        stage_name = nodes_struct['stages'][i] # Get stage name from global structure
        node_customdata.append([stage_name, percentage, count])

    # Calculate Link counts and percentages for tooltips
    link_customdata = [] # Will store [percentage, count] for each link
    for i in range(len(links_view_data['source'])):
        link_tuple = (links_view_data['source'][i], links_view_data['target'][i])
        count = 0
        if highlighting_active:
            # If highlighting, count comes from the pre-calculated cohort counts
            count = cohort_link_counts.get(link_tuple, 0)
        else:
            # If not highlighting, count is the original value from the full structure
            # (representing the count within the dropdown-filtered data implicitly,
            # although this assumes link values map directly - might need recalculation
            # based on df_filtered if strict accuracy needed, but usually close enough)
            # Let's recalculate for accuracy when *not* highlighting.
             if not highlighting_active:
                 source_label = nodes_struct['labels'][link_tuple[0]]
                 target_label = nodes_struct['labels'][link_tuple[1]]
                 source_stage = nodes_struct['stages'][link_tuple[0]]
                 target_stage = nodes_struct['stages'][link_tuple[1]]
                 # Count occurrences in df_filtered
                 try:
                      count = len(df_filtered[(df_filtered[source_stage] == source_label) & (df_filtered[target_stage] == target_label)])
                 except KeyError:
                      count = 0 # Should not happen if columns exist

        percentage = (count / total_rows_divisor) * 100
        link_customdata.append([percentage, count])


    # --- 6. Create Sankey Figure ---
    # Define hover templates using the structure defined for customdata
    node_hover_template = "<b>%{label}</b><br>Stage: %{customdata[0]}<br>Count: %{customdata[2]}<br>Percentage: %{customdata[1]:.1f}%<extra></extra>"
    link_hover_template = "Path: %{label}<br>Count: %{customdata[1]}<br>Percentage: %{customdata[0]:.1f}%<extra></extra>"

    fig = go.Figure(data=[go.Sankey(
        # Node properties
        node=dict(
            pad=NODE_PAD,
            thickness=NODE_THICKNESS,
            line=dict(color="black", width=0.5),
            label=nodes_struct['labels'], # Labels from full structure
            x=nodes_struct['x'],         # Positions from full structure
            y=nodes_struct['y'],         # Positions from full structure
            color="blue",                # Default node color (can customize)
            customdata=node_customdata,  # Tooltip data [stage, percentage, count]
            hovertemplate=node_hover_template
        ),
        # Link properties
        link=dict(
            source=links_view_data['source'], # Indices from full structure map
            target=links_view_data['target'], # Indices from full structure map
            value=links_view_data['value'],  # Use ADJUSTED values for visual thickness
            label=links_view_data['label'],  # Labels from full structure for hover info
            color=link_colors,               # Use calculated colors for highlighting/dimming
            customdata=link_customdata,      # Tooltip data [percentage, count]
            hovertemplate=link_hover_template
        ),
        # General Sankey properties
        orientation='h',
        arrangement='snap', # 'snap' aligns nodes to x positions, helps prevent dragging
        valueformat=".0f",  # Display integer counts in default tooltips if needed
        # valuesuffix=" items" # Optional suffix
    )])

    # --- 7. Update Figure Layout ---
    # Build the title dynamically based on state
    title = "Strategy Flow"
    if active_filters:
        # Format active filters nicely for the title
        filter_str = '; '.join([f'{k}={v}' for k,v in active_filters.items() if v])
        title += f"<br><span style='font-size: small;'>Filtered by: {filter_str}</span>"
    if highlighting_active and selected_node_data:
         title += f"<br><span style='font-size: small; color:{HIGHLIGHT_COLOR};'>Highlighting path through '{selected_node_data['label']}' in stage '{selected_node_data['stage']}'</span>"

    fig.update_layout(
        title_text=title,
        font=dict(size=FONT_SIZE, color='black'),
        height=SANKEY_HEIGHT,
        autosize=True, # Let width fill container, use fixed height
        margin=dict(l=20, r=20, t=100, b=20), # Increased top margin for longer title
    )

    # Join debug messages for output area
    final_debug_msg = "\n".join(debug_msg_lines)

    return fig, final_debug_msg


# --- Run the App ---
if __name__ == '__main__':
    # Make sure prerequisites are met
    if df_full.empty:
        print("ERROR: Could not load data. Please check CSV file path and format.")
        print(f"Expected Path: {CSV_FILE_PATH}")
        print("Ensure the following columns exist for stages:", STAGE_COLUMNS)
        print("Ensure the following columns exist for filters:", FILTER_COLUMNS)
    elif not full_nodes_data or not full_links_data or not full_node_map:
         print("ERROR: Failed to prepare Sankey structure from the data.")
    else:
        print("Starting Dash server... Access at http://127.0.0.1:8050/ (or similar)")
        app.run(debug=True) # Run the server (use debug=False for production)

## ChatGPT (2025-04-04T08:32:24.503260+00:00)

**Diagnosis**

Your Sankey diagram *is* emitting click events, but the callback logic in `store_selected_node` is not correctly distinguishing node-clicks vs. link-clicks in modern versions of Dash/Plotly. In particular:

- The code checks for `'x' in point_data` to decide if it’s a node click.  
- For Plotly Sankey traces, the `clickData` payload *does not* usually include an `'x'` field for nodes. Instead, Sankey node-clicks include fields like `"pointNumber"` or `"pointIndex"`, the node label, etc.  
- As a result, the logic that looks for `'x'` is *never* triggered, so node-clicks are ignored.

**Quick Fix**  
Inside your `store_selected_node` callback, replace the logic that checks `'x' in point_data` with logic that checks whether the user clicked a node by looking at `pointNumber/pointIndex`. For example:

```python
if 'points' in clickData and len(clickData['points']) > 0:
    point_data = clickData['points'][0]
    # `curveNumber` is usually 0 for the first Sankey trace
    # `pointNumber` (or pointIndex) tells us which node or link was clicked.
    # If pointNumber is in range of node indices, it's a node. Otherwise it's a link.

    # If you only have one Sankey trace, you can do something like:
    node_index = point_data.get('pointNumber', None)
    if node_index is not None:
        # Compare node_index to total number of Sankey nodes to distinguish node vs link
        total_nodes = len(full_nodes_data['labels'])  # same as len(nodes_struct['labels'])
        if node_index < total_nodes:
            # It's a node click
            node_label = full_nodes_data['labels'][node_index]
            node_stage = full_nodes_data['stages'][node_index]

            selected_info = {'label': node_label, 'stage': node_stage}
            # Toggle if re-clicking the same node
            if current_selection == selected_info:
                return None
            else:
                return selected_info
        else:
            # It's a link click (pointNumber >= number_of_nodes)
            print("DEBUG: Link clicked -- ignoring or handle differently.")
            raise dash.exceptions.PreventUpdate
    else:
        # No valid pointNumber => ignore
        raise dash.exceptions.PreventUpdate
```

**Key Points in the Fix**

1. **Check `pointNumber` (or `pointIndex`)**:  
   - For a Sankey diagram in Plotly, `pointNumber` corresponds to either a node *or* a link index in the single sankey trace. 
   - If `pointNumber` is `< number_of_nodes`, that means a *node* was clicked. If it’s >= number_of_nodes, it’s a link.

2. **Don’t rely on `'x' in point_data`**:  
   Sankey node clicks won’t contain `'x'`, so you’ll never enter that branch.  

3. **Obtain Node Label & Stage**:  
   Once you know `node_index` is valid for a node, just retrieve the label and stage from your `full_nodes_data` (or whichever node data structure you use).  

4. **Toggle Behavior**:  
   The rest of your toggle logic (if the newly clicked node is the same as the currently selected one, reset it; otherwise store the new selection) stays the same.

---

### Why You’re Not Seeing Clicks Right Now
With your current code:

```python
if 'x' in point_data and 'label' in point_data:
    ...
elif 'label' in point_data:
    # link logic
    ...
```

- Sankey node-click events do **not** return `'x'`. So the node branch never fires.  
- Your code then proceeds to the `'elif 'label' in point_data'` branch, assumes it’s a link click, and calls `raise dash.exceptions.PreventUpdate`, meaning the selection is never updated.

Once you switch to using `pointNumber` (or `pointIndex`), you’ll be able to detect node-clicks reliably.

---

### Ensuring Everything Else Is Set Up
1. **Dash / Plotly versions**: Make sure your virtual environment has a reasonably up-to-date version of Dash/Plotly so that Sankey click data is fully supported. For example:
   ```bash
   pip install dash==2.9.3 plotly==5.14.1
   ```
2. **Running in the correct environment**: Activate `(venv)` and run:
   ```bash
   python sankey_analyzer.py
   ```
   Then open http://127.0.0.1:8050 in your browser.  

3. **Verifying columns**: Double-check that the CSV columns listed in `STAGE_COLUMNS` and `FILTER_COLUMNS` are spelled correctly and present in your data. Otherwise you’ll get warnings or empty data.

With that change to the callback logic (checking `pointNumber` instead of `'x'`), you should be able to click nodes and see the highlighting or toggling behavior as intended.

## You (2025-04-04T08:41:55.563000+00:00)

I'm still unable to click on anything. For your context, let me explain my main goal. I have a spreadsheet that has a whole number of rows, and I'm trying to visualize the specific columns I have described in this code. I'm basically trying to understand the flow of units throughout the entire journey. So, imagine if you are a supply chain manager, and you are trying to understand a product's flow through all the different touch points. Imagine each of these columns is a touch point. So, now imagine you are trying to understand the flow of all the units that are tagged as, let's say, vision versus reality under tension axis. So, you don't just want to look at the specific flow before and after tension axis. You want to isolate that tiny dataset, which I was hoping to isolate by clicking on a node. And I want to see that particular dataset's journey through all the touch points, which in this case are all the columns. That's what I have been trying to do, but so far I haven't received any luck. I have made the modifications you have suggested, but I still don't see any change. Also, in the future, every time you are making any suggestions, please make sure that you at least mention the first line and the last line from the existing code that I need to replace so that I know exactly where I need to place my code. Keep this in your memory. You are working with someone with no coding knowledge whatsoever. So, any suggestion you make around changing certain calls or certain lines will not be received well or even understood simply because it is impossible for the person you are communicating with to understand what you are saying. Remember, you are working with someone who does not know how to code. Please keep that in your memory.

## ChatGPT (2025-04-04T08:44:32.823676+00:00)

Below is a **step-by-step** set of instructions showing you *exactly* which lines to change so that clicking on a node will *actually* highlight/filter the Sankey flow. I’ve written this so you can literally copy and paste where I tell you, without needing any coding background.

---

## 1. Enable Click Events on the Sankey Chart

In your `app.layout`, there is a `dcc.Graph` definition that looks something like this:

```python
dcc.Graph(
    id='sankey-diagram',
    config={'displayModeBar': True}
)
```

**Replace** that block with the following **3 lines** (note the new `clickmode='event+select'` property):

```python
dcc.Graph(
    id='sankey-diagram',
    config={'displayModeBar': True},
    clickmode='event+select'
)
```

> **First line to find and replace**:  
> `dcc.Graph(  
>     id='sankey-diagram',  
>     config={'displayModeBar': True}  
> )`  
>
> **Last line in that block**:  
> `)`  
>
> (Just remove your existing `dcc.Graph(... )` block and paste the new 3 lines above.)

This tells Dash/Plotly: “When the user clicks a node, produce a `clickData` event we can read.”

---

## 2. Overhaul the “store_selected_node” Callback

Now look for the callback in your file labeled `# Callback 2: Handle node selection clicks and reset buttons`. It should start with something like:

```python
@app.callback(
    Output('selected-node-store', 'data'),
    ...
)
def store_selected_node(clickData, reset_node_clicks, reset_all_clicks, current_selection):
    ...
```

Inside that function, you’ll see an `if clickData:` section with checks like `'x' in point_data`, `'label' in point_data`, etc., and it ends with `raise dash.exceptions.PreventUpdate`.

### Exactly Which Lines to Remove

1. Find the **first line** in that callback that says:
   ```python
   if clickData:
   ```
2. Find the **last line** in that callback that says:
   ```python
   raise dash.exceptions.PreventUpdate
   ```
3. **Delete everything** in between those two lines (including those lines themselves).

After you remove those lines, your callback will still have the code at the top dealing with `reset-node-button` / `reset-button`, etc. That’s good—we want to keep the reset logic as-is.

### Paste This New Code In Place

Right after the line:
```python
print(f"Triggered by: {triggered_id}")
```
and **before** any final `return` or `raise dash.exceptions.PreventUpdate` in `store_selected_node`, **paste** this entire block:

```python
    # ------------------------------------------------------
    # NEW CLICK-HANDLING LOGIC FOR NODE SELECTION
    # ------------------------------------------------------
    if clickData and 'points' in clickData and len(clickData['points']) > 0:
        # clickData['points'][0] holds info about which node or link got clicked.
        point_data = clickData['points'][0]

        # For a single Sankey trace:
        #   - "pointNumber" (or sometimes "pointIndex") will be an integer
        #   - If it's < number_of_nodes, that means you clicked a node
        #   - If it's >= number_of_nodes, that means you clicked a link

        node_index = point_data.get('pointNumber', None)
        if node_index is None:
            # No valid pointNumber => no valid click
            print("DEBUG: No valid node/link index in clickData.")
            raise dash.exceptions.PreventUpdate

        total_nodes = len(full_nodes_data['labels'])  # or len(nodes_struct['labels'])
        if node_index < total_nodes:
            # --- It's a NODE click ---
            node_label = full_nodes_data['labels'][node_index]
            node_stage = full_nodes_data['stages'][node_index]
            print(f"Node click detected => index={node_index}, label='{node_label}', stage='{node_stage}'")

            selected_info = {'label': node_label, 'stage': node_stage}
            # Toggle the selection if the user clicked the same node again
            if current_selection == selected_info:
                print("Clicked the same node again => deselecting.")
                return None
            else:
                print(f"Storing new selection => {selected_info}")
                return selected_info
        else:
            # --- It's a LINK click (pointNumber >= total_nodes) ---
            print("Link click detected => ignoring for node selection.")
            raise dash.exceptions.PreventUpdate
    else:
        # If we got here, there's no clickData or it's not well-formed.
        print("DEBUG: No node/link was clicked, ignoring.")
        raise dash.exceptions.PreventUpdate
    # ------------------------------------------------------
```

At the very end of the callback (after this new block) you may have:

```python
raise dash.exceptions.PreventUpdate
```

Leave that there if you still need it for any other no-op returns.

> **First line to remove**:  
> `if clickData:`  
>
> **Last line to remove**:  
> `raise dash.exceptions.PreventUpdate`  
>
> Then paste the new block above in that same location.

---

## 3. Run the App

1. Make sure you’re in your virtual environment:  
   ```bash
   source venv/bin/activate
   ```
   (or however you normally activate it).

2. Start the Dash app:
   ```bash
   python sankey_analyzer.py
   ```
3. In your browser, open [http://127.0.0.1:8050](http://127.0.0.1:8050).

Now, when you click on a Sankey **node**, your `store_selected_node` callback should detect it, save it to `selected-node-store`, and you’ll see the rest of your logic in `update_sankey` highlight or filter accordingly.

---

### Important Reminders

1. **Check your console** (the terminal where you ran `python sankey_analyzer.py`) for any printouts or errors.  
2. **Ensure the CSV columns match exactly** the names in your code. If any stage columns or filter columns are missing, the Sankey might be empty or produce warnings.  
3. **Dash version**: Make sure you have a relatively recent version of Dash and Plotly (e.g., `dash>=2.7` and `plotly>=5.0`).  

If you still can’t click nodes after these changes, double-check that you have **exactly** replaced the lines from `if clickData:` through `raise dash.exceptions.PreventUpdate` with the code snippet above.  

---

**That’s it!** Once these changes are in place, node-clicks should highlight the subset of data flowing through that node. If you have any further trouble or see errors, just let me know the exact error message, and I’ll walk you through the fix step by step.

## You (2025-04-04T08:54:32.197000+00:00)

please give me the entire code for Sankey_analyze.py based on the following modifications. Give me the code only, and nothing else.

## ChatGPT (2025-04-04T08:54:32.668723+00:00)

```python
import pandas as pd
import plotly.graph_objects as go
import dash
from dash import dcc, html
from dash.dependencies import Input, Output, State
import json
import copy  # Needed for deepcopy
import numpy as np  # For handling potential NaN comparisons safely

# --- Configuration ---
# <<< --- MAKE SURE THIS PATH IS CORRECT FOR YOUR SYSTEM --- >>>
CSV_FILE_PATH = 'Business-Level Strategy Tagging - Compilation.csv'

# Define the exact order of stages for the Sankey flow
STAGE_COLUMNS = [
    'Ambiguity Type',
    'Framing Move',
    'Stabilizer',
    'False Clarity',
    'Tension Axis',
    'Org Implication',
    'Friction Archetype'
]

# Define additional columns for filtering
FILTER_COLUMNS = [
    'Regulatory Scope',
    'Temporal Coupling Sensitivity',
    'Market Dispersion',
    'Capital Substrate Intensity',
    'Decomposability Gradient',
    'Temporal Value Elasticity',
    'Knowledge Codifiability'
]

# --- Styling ---
HIGHLIGHT_COLOR = 'rgba(255, 165, 0, 0.8)'  # Orange with some transparency
DEFAULT_COLOR = 'rgba(200, 200, 200, 0.5)'    # Light gray with transparency
NODE_PAD = 25  # Generous node padding
NODE_THICKNESS = 15
FONT_SIZE = 10
SANKEY_HEIGHT = 750  # Adjust as needed for 4:3 ratio relative to width

# --- Helper Functions ---

def load_data(filepath):
    """Loads and performs initial cleaning on the CSV data."""
    try:
        df = pd.read_csv(filepath)
        # Ensure all relevant columns are treated as strings for consistent grouping
        for col in STAGE_COLUMNS + FILTER_COLUMNS:
            if col in df.columns:
                # Convert to string, handling potential NaN values first
                df[col] = df[col].fillna('Unknown').astype(str).str.strip()
            else:
                print(f"Warning: Column '{col}' not found in CSV. Filling with 'Unknown'.")
                # Create missing columns with a default value
                df[col] = 'Unknown'
        print(f"Data loaded successfully: {df.shape[0]} rows")
        return df
    except FileNotFoundError:
        print(f"Error: File not found at {filepath}")
        return pd.DataFrame()  # Return empty DataFrame on error
    except Exception as e:
        print(f"Error loading data: {e}")
        return pd.DataFrame()

def prepare_sankey_data(df, stage_cols):
    """
    Prepares node and link data structures for Plotly Sankey based on the provided DataFrame.
    Handles unique node identification across all stages.
    Returns nodes dictionary, links dictionary, and node_map (unique_id -> index).
    """
    if df is None or df.empty:
        print("Warning: prepare_sankey_data received an empty DataFrame.")
        return {'labels': [], 'x': [], 'y': []}, {'source': [], 'target': [], 'value': [], 'label': []}, {}

    all_nodes_info = []  # Store dicts {'label': str, 'id': str, 'stage': str}
    node_x_positions = {}
    node_y_positions = {}

    # Calculate node positions
    num_stages = len(stage_cols)
    stage_width = 1.0 / (num_stages - 1) if num_stages > 1 else 1.0

    # Define nodes and their positions
    for i, col in enumerate(stage_cols):
        unique_values = sorted(df[col].unique())
        x_pos = i * stage_width if num_stages > 1 else 0.5  # Normalized x position (0 to 1)
        num_nodes_in_stage = len(unique_values)
        y_increment = 1.0 / (num_nodes_in_stage + 1) if num_nodes_in_stage > 0 else 1.0

        for j, node_label in enumerate(unique_values):
            unique_node_id = f"{col}_{node_label}"
            if unique_node_id not in [n['id'] for n in all_nodes_info]:
                all_nodes_info.append({'label': str(node_label), 'id': unique_node_id, 'stage': col})
                node_x_positions[unique_node_id] = x_pos
                node_y_positions[unique_node_id] = (j + 1) * y_increment

    node_map = {node['id']: i for i, node in enumerate(all_nodes_info)}
    node_labels = [node['label'] for node in all_nodes_info]
    node_final_x = [node_x_positions[node['id']] for node in all_nodes_info]
    node_final_y = [node_y_positions[node['id']] for node in all_nodes_info]

    links_list = []
    for i in range(num_stages - 1):
        source_col = stage_cols[i]
        target_col = stage_cols[i+1]
        grouped = df.groupby([source_col, target_col], observed=False).size().reset_index(name='value')
        for _, row in grouped.iterrows():
            source_id = f"{source_col}_{row[source_col]}"
            target_id = f"{target_col}_{row[target_col]}"
            if source_id in node_map and target_id in node_map:
                links_list.append({
                    'source': node_map[source_id],
                    'target': node_map[target_id],
                    'value': row['value'],
                    'label': f"{row[source_col]} -> {row[target_col]}"
                })

    links = {
        'source': [link['source'] for link in links_list],
        'target': [link['target'] for link in links_list],
        'value': [link['value'] for link in links_list],
        'label': [link['label'] for link in links_list],
    }
    nodes = {'labels': node_labels, 'x': node_final_x, 'y': node_final_y}
    nodes['stages'] = [node['stage'] for node in all_nodes_info]
    return nodes, links, node_map

# --- Load Initial Data ---
df_full = load_data(CSV_FILE_PATH)

if not df_full.empty:
    print("Calculating initial full Sankey structure...")
    full_nodes_data, full_links_data, full_node_map = prepare_sankey_data(df_full, STAGE_COLUMNS)
    print(f"Full structure calculated: {len(full_nodes_data['labels'])} nodes, {len(full_links_data['source'])} links.")
else:
    full_nodes_data, full_links_data, full_node_map = {'labels': [], 'x': [], 'y': [], 'stages': []}, {'source': [], 'target': [], 'value': [], 'label': []}, {}
    print("Warning: Data loading failed, Sankey will be empty.")

# --- Initialize Dash App ---
app = dash.Dash(__name__)
server = app.server

# --- App Layout ---
app.layout = html.Div([
    html.H1("Strategy Analysis: Ambiguity Framing & Resolution Flow"),

    html.Div([
        html.Div([
            html.Label(f"{col}:"),
            dcc.Dropdown(
                id=f'filter-{col}',
                options=[{'label': i, 'value': i} for i in sorted(df_full[col].unique())] if col in df_full else [],
                multi=True,
                placeholder=f"Select {col}..."
            )
        ], style={'width': '30%', 'display': 'inline-block', 'padding': '5px'})
        for col in FILTER_COLUMNS
    ], style={'marginBottom': '20px'}),

    html.Button('Reset View / Filters', id='reset-button', n_clicks=0),
    html.Button('Reset Node Selection', id='reset-node-button', n_clicks=0, style={'marginLeft': '10px'}),

    dcc.Loading(
        id="loading-sankey",
        type="circle",
        children=dcc.Graph(
            id='sankey-diagram',
            config={'displayModeBar': True},
            clickmode='event+select'
        )
    ),

    dcc.Store(id='selected-node-store', data=None),
    dcc.Store(id='current-filters-store', data={col: None for col in FILTER_COLUMNS}),

    html.Div(id='debug-output', style={'marginTop': '20px', 'whiteSpace': 'pre-wrap', 'fontFamily': 'monospace'})
])

# --- Callbacks ---

@app.callback(
    Output('current-filters-store', 'data'),
    [Input(f'filter-{col}', 'value') for col in FILTER_COLUMNS]
)
def update_filters_store(*filter_values):
    filters = {col: val for col, val in zip(FILTER_COLUMNS, filter_values)}
    return filters

@app.callback(
    Output('selected-node-store', 'data'),
    Input('sankey-diagram', 'clickData'),
    Input('reset-node-button', 'n_clicks'),
    Input('reset-button', 'n_clicks'),
    State('selected-node-store', 'data'),
    prevent_initial_call=True
)
def store_selected_node(clickData, reset_node_clicks, reset_all_clicks, current_selection):
    print("\n--- store_selected_node ---")
    ctx = dash.callback_context
    triggered_id = ctx.triggered[0]['prop_id'].split('.')[0] if ctx.triggered else 'No trigger'
    print(f"Triggered by: {triggered_id}")

    if triggered_id in ['reset-node-button', 'reset-button']:
        print("Resetting node selection via button.")
        return None

    # ------------------------------------------------------
    # NEW CLICK-HANDLING LOGIC FOR NODE SELECTION
    # ------------------------------------------------------
    if clickData and 'points' in clickData and len(clickData['points']) > 0:
        point_data = clickData['points'][0]
        node_index = point_data.get('pointNumber', None)
        if node_index is None:
            print("DEBUG: No valid node/link index in clickData.")
            raise dash.exceptions.PreventUpdate
        total_nodes = len(full_nodes_data['labels'])
        if node_index < total_nodes:
            node_label = full_nodes_data['labels'][node_index]
            node_stage = full_nodes_data['stages'][node_index]
            print(f"Node click detected => index={node_index}, label='{node_label}', stage='{node_stage}'")
            selected_info = {'label': node_label, 'stage': node_stage}
            if current_selection == selected_info:
                print("Clicked the same node again => deselecting.")
                return None
            else:
                print(f"Storing new selection => {selected_info}")
                return selected_info
        else:
            print("Link click detected => ignoring for node selection.")
            raise dash.exceptions.PreventUpdate
    else:
        print("DEBUG: No node/link was clicked, ignoring.")
        raise dash.exceptions.PreventUpdate
    # ------------------------------------------------------

@app.callback(
    Output('sankey-diagram', 'figure'),
    Output('debug-output', 'children'),
    Input('current-filters-store', 'data'),
    Input('selected-node-store', 'data'),
    Input('reset-button', 'n_clicks')
)
def update_sankey(filters_data, selected_node_data, reset_clicks):
    ctx = dash.callback_context
    triggered_id = ctx.triggered[0]['prop_id'].split('.')[0] if ctx.triggered else 'initial load'
    print(f"\n>>> Updating Sankey Diagram <<< --- Triggered by: {triggered_id}")
    print(f"Filters received: {filters_data}")
    print(f"Selected node received: {selected_node_data}")

    df_filtered = df_full.copy()
    active_filters = {}
    if filters_data:
        for col, values in filters_data.items():
            if values and col in df_filtered.columns:
                df_filtered = df_filtered[df_filtered[col].isin(values)]
                active_filters[col] = values

    if df_filtered.empty and not df_full.empty:
        print("Warning: Filtering resulted in an empty dataset.")
        return go.Figure(layout={'title': 'No data matches the selected filters.', 'height': SANKEY_HEIGHT}), "No data matches filters."

    df_cohort = None
    highlighting_active = False
    debug_msg_lines = [f"Filters applied: {active_filters}"]

    if selected_node_data and isinstance(selected_node_data, dict) and \
       'stage' in selected_node_data and 'label' in selected_node_data and \
       selected_node_data['stage'] in STAGE_COLUMNS:

        highlighting_active = True
        node_label = selected_node_data['label']
        node_stage = selected_node_data['stage']
        print(f"Highlighting Active: Filtering cohort for Stage='{node_stage}', Label='{node_label}'")

        try:
            cohort_condition = df_filtered[node_stage].astype(str) == str(node_label)
            df_cohort = df_filtered[cohort_condition]
            print(f"DEBUG: Cohort DataFrame shape: {df_cohort.shape}")
            if df_cohort.empty:
                print(f"DEBUG: df_cohort IS EMPTY. Condition was: {node_stage} == '{node_label}'")
            else:
                print(f"DEBUG: df_cohort Head:\n{df_cohort.head().to_string()}")
        except KeyError:
            print(f"Error: Stage column '{node_stage}' not found while filtering cohort. This shouldn't happen.")
            highlighting_active = False
            df_cohort = None

        if df_cohort is None or df_cohort.empty:
            print(f"Warning: Cohort for {selected_node_data} is empty within the filtered data.")
            highlighting_active = False
            debug_msg_lines.append(f"Selected node [{selected_node_data.get('label', 'N/A')} in {selected_node_data.get('stage', 'N/A')}] resulted in an empty cohort.")
        else:
            debug_msg_lines.append(f"Highlighting cohort ({len(df_cohort)} rows) for node [{node_label} in {node_stage}]")
    else:
        debug_msg_lines.append(f"Displaying filtered data ({len(df_filtered)} rows). No node selected for highlighting.")

    nodes_struct = full_nodes_data
    links_struct = full_links_data
    node_map = full_node_map

    if not nodes_struct or not links_struct or not node_map or not nodes_struct['labels']:
         print("Error: Global Sankey structure is missing or invalid.")
         return go.Figure(layout={'title': 'Error: Sankey structure data is missing.', 'height': SANKEY_HEIGHT}), "Error: Missing structure data."

    links_view_data = copy.deepcopy(links_struct)
    link_colors = [DEFAULT_COLOR] * len(links_view_data['source'])
    cohort_link_counts = {}

    if highlighting_active and df_cohort is not None and not df_cohort.empty:
        print(f"Calculating cohort link counts for {len(df_cohort)} rows...")
        for i in range(len(STAGE_COLUMNS) - 1):
            source_col = STAGE_COLUMNS[i]
            target_col = STAGE_COLUMNS[i+1]
            grouped_cohort = df_cohort.groupby([source_col, target_col], observed=False).size().reset_index(name='cohort_count')
            for _, row in grouped_cohort.iterrows():
                source_id = f"{source_col}_{row[source_col]}"
                target_id = f"{target_col}_{row[target_col]}"
                if source_id in node_map and target_id in node_map:
                    source_idx = node_map[source_id]
                    target_idx = node_map[target_id]
                    cohort_link_counts[(source_idx, target_idx)] = row['cohort_count']

        highlighted_links_count = 0
        for i in range(len(links_view_data['source'])):
            link_tuple = (links_view_data['source'][i], links_view_data['target'][i])
            if link_tuple in cohort_link_counts:
                link_colors[i] = HIGHLIGHT_COLOR
                links_view_data['value'][i] = cohort_link_counts[link_tuple]
            else:
                link_colors[i] = DEFAULT_COLOR
                links_view_data['value'][i] = 0.001
        print(f"DEBUG: Number of links colored for highlight: {highlighted_links_count}")

    df_for_counts = df_cohort if highlighting_active and df_cohort is not None else df_filtered
    total_rows_in_view = len(df_for_counts)
    total_rows_divisor = total_rows_in_view if total_rows_in_view > 0 else 1

    node_counts_in_view = {}
    for stage in STAGE_COLUMNS:
        counts = df_for_counts[stage].value_counts()
        for label, count in counts.items():
            node_id = f"{stage}_{label}"
            if node_id in node_map:
                node_idx = node_map[node_id]
                node_counts_in_view[node_idx] = count

    node_customdata = []
    for i in range(len(nodes_struct['labels'])):
        count = node_counts_in_view.get(i, 0)
        percentage = (count / total_rows_divisor) * 100
        stage_name = nodes_struct['stages'][i]
        node_customdata.append([stage_name, percentage, count])

    link_customdata = []
    for i in range(len(links_view_data['source'])):
        link_tuple = (links_view_data['source'][i], links_view_data['target'][i])
        count = 0
        if highlighting_active:
            count = cohort_link_counts.get(link_tuple, 0)
        else:
            source_label = nodes_struct['labels'][link_tuple[0]]
            target_label = nodes_struct['labels'][link_tuple[1]]
            source_stage = nodes_struct['stages'][link_tuple[0]]
            target_stage = nodes_struct['stages'][link_tuple[1]]
            try:
                count = len(df_filtered[(df_filtered[source_stage] == source_label) & (df_filtered[target_stage] == target_label)])
            except KeyError:
                count = 0
        percentage = (count / total_rows_divisor) * 100
        link_customdata.append([percentage, count])

    node_hover_template = "<b>%{label}</b><br>Stage: %{customdata[0]}<br>Count: %{customdata[2]}<br>Percentage: %{customdata[1]:.1f}%<extra></extra>"
    link_hover_template = "Path: %{label}<br>Count: %{customdata[1]}<br>Percentage: %{customdata[0]:.1f}%<extra></extra>"

    fig = go.Figure(data=[go.Sankey(
        node=dict(
            pad=NODE_PAD,
            thickness=NODE_THICKNESS,
            line=dict(color="black", width=0.5),
            label=nodes_struct['labels'],
            x=nodes_struct['x'],
            y=nodes_struct['y'],
            color="blue",
            customdata=node_customdata,
            hovertemplate=node_hover_template
        ),
        link=dict(
            source=links_view_data['source'],
            target=links_view_data['target'],
            value=links_view_data['value'],
            label=links_view_data['label'],
            color=link_colors,
            customdata=link_customdata,
            hovertemplate=link_hover_template
        ),
        orientation='h',
        arrangement='snap',
        valueformat=".0f",
    )])

    title = "Strategy Flow"
    if active_filters:
        filter_str = '; '.join([f'{k}={v}' for k,v in active_filters.items() if v])
        title += f"<br><span style='font-size: small;'>Filtered by: {filter_str}</span>"
    if highlighting_active and selected_node_data:
         title += f"<br><span style='font-size: small; color:{HIGHLIGHT_COLOR};'>Highlighting path through '{selected_node_data['label']}' in stage '{selected_node_data['stage']}'</span>"

    fig.update_layout(
        title_text=title,
        font=dict(size=FONT_SIZE, color='black'),
        height=SANKEY_HEIGHT,
        autosize=True,
        margin=dict(l=20, r=20, t=100, b=20),
    )

    final_debug_msg = "\n".join(debug_msg_lines)
    return fig, final_debug_msg

if __name__ == '__main__':
    if df_full.empty:
        print("ERROR: Could not load data. Please check CSV file path and format.")
        print(f"Expected Path: {CSV_FILE_PATH}")
        print("Ensure the following columns exist for stages:", STAGE_COLUMNS)
        print("Ensure the following columns exist for filters:", FILTER_COLUMNS)
    elif not full_nodes_data or not full_links_data or not full_node_map:
         print("ERROR: Failed to prepare Sankey structure from the data.")
    else:
        print("Starting Dash server... Access at http://127.0.0.1:8050/ (or similar)")
        app.run(debug=True)
```

## You (2025-04-04T08:56:27.812000+00:00)

ok, now give me the rest of the code

## ChatGPT (2025-04-04T08:56:28.552680+00:00)

```python
import pandas as pd
import plotly.graph_objects as go
import dash
from dash import dcc, html
from dash.dependencies import Input, Output, State
import json
import copy  # Needed for deepcopy
import numpy as np  # For handling potential NaN comparisons safely

# --- Configuration ---
# <<< --- MAKE SURE THIS PATH IS CORRECT FOR YOUR SYSTEM --- >>>
CSV_FILE_PATH = 'Business-Level Strategy Tagging - Compilation.csv'

# Define the exact order of stages for the Sankey flow
STAGE_COLUMNS = [
    'Ambiguity Type',
    'Framing Move',
    'Stabilizer',
    'False Clarity',
    'Tension Axis',
    'Org Implication',
    'Friction

