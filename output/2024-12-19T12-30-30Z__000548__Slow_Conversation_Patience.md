# Slow Conversation Patience





## ChatGPT (2024-12-19T12:30:30.546160+00:00)

Hi there! What's on your mind today?

## You (2024-12-19T12:30:44.964549+00:00)

Okay, so this is going to be a long conversation, so just be patient with me and I'll be talking a little slow today.

## ChatGPT (2024-12-19T12:30:44.988884+00:00)

Take your time, I'm here to listen.

## You (2024-12-19T12:34:56.289975+00:00)

To give you some context on what we're doing, we're working with the D3 Institute at Harvard Business School, and we're essentially creating events that are based on advancements in AI and how different businesses, business leaders, entrepreneurs are approaching AI, along with any ethical concerns and things like that. So we conducted a bunch of interviews, and we found a lot of patterns around similarities in people's opinions. These are independent similarities. A few people were concerned about job replacements, a few people were concerned about, not concerned, but they want to understand how a business understands AI, how they look at AI. So we found a lot of these patterns. Now that's sort of the context for you. Now, a bigger question, what I'm trying to figure out is what should be the next step for D3 Institute. I was listening to a talk by Ethan Moly, where he talked about the fact that with new advancements in any technology, we tend to overestimate the immediate impact and underestimate the long-term impact. And he tried to give an analogy with the dot-com crash, where in the 1990s, people overestimated their immediate impact of the internet, and it led to a sort of failure. In the long run, most of the predictions that people made around the internet were correct. So a similar thing can happen with AI, where people sort of overestimate the immediate impact and underestimate the long-term impact. So what I'm trying to propose to a larger audience is that one way that we can sort of be on the right track is by understanding how individuals, people at an individual level, look at AI. What are their concerns? What are they trying to learn? How are they trying to... What exactly they're trying to learn, how they implement it, things like that. So my whole point is that we have to first invest in capturing data so that once we understand what people are looking for, what people are talking about, then based on that, we can sort of form an opinion and start building out a wider product. So that's my take. Now, could you sort of recap what you understood from my explanation, and then we can move forward.

## ChatGPT (2024-12-19T12:35:04.361631+00:00)

Sure! You're working with the D3 Institute and Harvard Business School on events about AI advancements. You've identified patterns in people's concerns and opinions from interviews, focusing on job replacement and business perspectives. You're considering the long-term impacts of AI, noting that people often overestimate immediate effects and underestimate long-term impacts, similar to the dot-com era. Your proposal is to capture data on individual concerns and learning about AI to build a more informed strategy. Does that sound right?
