# Can you hear me



## You (2024-12-23T18:52:04.034940+00:00)

Hey, can you hear me?

## ChatGPT (2024-12-23T18:52:04.061929+00:00)

Yes, I can hear you! How can I

## You (2024-12-23T18:52:05.920351+00:00)

That's all for me.

## ChatGPT (2024-12-23T18:52:05.951190+00:00)

I'm here to help! What do you need?

## You (2024-12-23T18:52:08.168046+00:00)

Okay.

## ChatGPT (2024-12-23T18:52:08.207767+00:00)

Sure, just let me know what you need.

## You (2024-12-23T18:55:44.230370+00:00)

So, I'm working on this project where I'm trying to help event organizers get more out of the attendee experience than they currently do. So, this involves creating or proposing to create some AI agents that maintain interactions with the attendees before the event, during the event, and after the event. Now, the way this works is this AI agent will talk to different attendees and during a conversation they might, like before the event, they may act as a companion for pre-event networking. So, they'll basically connect attendees with other people with similar backgrounds or interests or whatnot. They may help attendees with different levels of expertise. So, we're hosting an AI event and it could help attendees understand some technical concepts of AI before the event or during the event. It could gather thoughts helping attendees reflect on their experience. So, for example, if an attendee just consumed, just attended one session. So, this AI agent will proactively start a conversation and say, hey, what did you think about some of the topics discussed in the event? And accordingly, based on what the attendee says, this AI agent can also connect them with other people who share similar interests. It can guide them to different conversational chambers like forums and chat rooms where a topic is being discussed. It could guide them through an event. It could share additional resources from the event organizer like this event organizer. It's Harvard Business School and they have a lot of research. So, this agent can understand interests from the attendees and based on that, start suggesting more research papers around the same topics. And it can also continue engagement with the attendees post the event. So, let's say I'm an attendee and I want to connect with people with a certain background who attended the event. So, based on some discretion and careful considerations around data privacy and the attendees autonomy over their personal information, the AI agent could act as a liaison or a fixer to help connect people with others who previously attended the DQ conference. So, this is the idea. I'll take a pause now. Let me know if you have any questions.

## ChatGPT (2024-12-23T18:55:44.327111+00:00)

That sounds like a thoughtful and comprehensive plan. Creating an AI agent to enhance attendee engagement before, during, and after events could provide significant value. 

One consideration might be ensuring that the AI agent respects user privacy and data security, especially when facilitating connections and suggesting resources. You might also want to think about how customizable the agent's interactions can be to different types of attendees and events. Overall, it sounds promising. Whatâs your next step?

## You (2024-12-23T18:58:53.888163+00:00)

So my next step is to validate some of the assumptions in this concept. So the way I'm planning on doing this is by doing sort of a Wizard of Oz test, where I can create a custom ChatGPT with a certain personality and information. I will also be using Otter to live record some of the sessions. So the Otter can actually give me summaries of the event. And I could use a combination of Otter and ChatGPT to start engaging with participants in a proactive conversation. Now, the whole thing will be all the responses, all the messages will be generated by an AI. I will just be pretending to be an AI agent and having a conversation with the attendees. So this is, like I said, sort of a Wizard of Oz experiment. Some of the things I want to understand is, well, mainly I want to understand if attendees will be willing to have a conversation with an AI agent or someone pretending to be an AI agent. So the attendees will not know that I am a person. They will think that I am just an AI agent. I am supposed to propose this as a formal research activity. So when I need your help is to turn this into a sort of research plan with clear objectives, methodology, and limitations. Some of the things that I, as a person doing a Wizard of Oz experiment, will not be able to understand. So limitations, goals, approach, everything. Just prepare a formal research document for me.

## ChatGPT (2024-12-23T18:58:53.935489+00:00)

User is planning a Wizard of Oz experiment to validate the concept of an AI agent for enhancing event attendee experiences by pretending to be an AI agent in conversations with participants. They want to assess attendee willingness to interact with such an agent and need help in creating a formal research plan including objectives, methodology, and limitations.

## ChatGPT (2024-12-23T18:58:53.935714+00:00)

That sounds like a solid plan. Here's a structure you can use for your research document:

**1. Objectives:**
- Assess the willingness of attendees to interact with an AI agent.
- Evaluate the effectiveness of the AI agent in enhancing engagement before, during, and after events.
- Identify potential areas for improvement in the AI agent's interactions.

**2. Methodology:**
- Conduct a Wizard of Oz test where you simulate the AI agent's responses.
- Use tools like Otter for live recording and summarization of sessions.
- Engage with attendees as if you are the AI agent, without revealing that you're a human.
- Collect feedback through surveys or interviews post-interaction.

**3. Limitations:**
- The artificial nature of the test might influence attendee behavior.
- Limited sample size could impact the generalizability of the results.
- The inability to replicate all functionalities of an actual AI agent might limit the depth of the interaction.

This should provide a strong framework for your study! If you need more details or specific sections, just let me know.

## You (2024-12-23T19:00:20.098832+00:00)

This is very brief... Could you create a more fleshed out research plan based on the activities i suggested? like creating custom gpts, using a combination of otter and chatgpt to simulate responses. I also like the limitations you've outlined, But i need them to be a bit more fleshed out.

## ChatGPT (2024-12-23T19:01:13.567046+00:00)

Here’s a more detailed research plan tailored to your activities and goals for the Wizard of Oz experiment. This includes the use of tools like custom GPTs, Otter, and ChatGPT, as well as a deeper exploration of limitations.

---

### **Research Plan: Validating the AI Event Assistant Concept**

#### **1. Objectives**
- Assess attendees’ willingness to engage with an AI agent in event contexts.
- Understand the quality of interactions facilitated by the AI agent and its perceived usefulness.
- Identify pain points or areas for improvement in the interaction design.
- Determine the types of questions and tasks attendees most commonly expect the AI agent to address.
- Explore how effectively an AI agent can enhance engagement before, during, and after events.

---

#### **2. Methodology**

##### **A. Research Design**
- **Experiment Type**: Wizard of Oz simulation.
- **Interaction Setup**:
  - Use a combination of Otter.ai for live transcription and ChatGPT for generating responses.
  - Create a custom GPT with pre-programmed intents relevant to event activities (e.g., scheduling, summarization, networking tips, feedback collection).
  - Act as the backend of the AI agent, crafting responses manually while maintaining the illusion of an autonomous AI.

##### **B. Participant Engagement**
- **Sample Size**: Engage 15–20 event attendees across varied professional roles.
- **Pre-Simulation Briefing**: Participants will be informed about the AI agent and its capabilities without revealing the human backend simulation.
- **Interaction Contexts**:
  1. **Before the Event**:
     - Answer logistical questions.
     - Provide session recommendations based on participant interests.
  2. **During the Event**:
     - Facilitate note-taking and provide session summaries.
     - Suggest networking opportunities based on shared interests.
     - Gather real-time feedback on event sessions.
  3. **After the Event**:
     - Assist in summarizing key takeaways.
     - Encourage participants to reflect on their learnings and provide structured feedback.

##### **C. Data Collection**
- **Session Logs**: Use Otter.ai to capture all conversations for analysis.
- **Post-Interaction Surveys**: Collect feedback on interaction quality, usefulness, and perceived authenticity of the AI agent.
- **Follow-Up Interviews**: Conduct in-depth interviews with 5–7 participants to gather qualitative insights on their experience.

---

#### **3. Tools and Techniques**
- **Custom GPTs**: Configure GPT models with domain-specific knowledge (e.g., event terminology, common FAQs).
- **Otter.ai**: Record and transcribe conversations in real-time for accurate documentation.
- **ChatGPT**: Generate realistic and contextually appropriate responses during the simulation.
- **Google Sheets or Notion**: For organizing data and tracking participant interactions.

---

#### **4. Deliverables**
- Analysis of participant willingness to engage with the AI.
- Insights into frequently requested features or improvements.
- A summary report with recommendations for developing a functional prototype AI agent.

---

#### **5. Limitations**
1. **Artificial Nature of the Simulation**:
   - Attendees might unconsciously interact differently, knowing the agent is not fully autonomous.
   - The researcher acting as the AI may inject unintentional bias into responses.

2. **Scalability Challenges**:
   - Simulated interactions are labor-intensive and may not accurately reflect the performance of a fully automated system.
   - The ability to scale responses and provide real-time assistance could differ significantly from a live AI agent.

3. **Limited Functionality**:
   - The AI’s simulated capabilities may not match those of an actual implementation, potentially underestimating or overestimating the true potential of the technology.
   - Participants might expect advanced features (e.g., deep personalization) that are not feasible to simulate manually.

4. **Sample Size and Representation**:
   - A small group of participants may not represent the diversity of attendee needs or behaviors at larger events.
   - Results may vary significantly depending on participant demographics or the type of event.

5. **Technical and Human Errors**:
   - Reliance on tools like Otter.ai and ChatGPT introduces the possibility of transcription errors or delays in response generation.
   - Human intervention in real-time responses may slow interactions or misrepresent the agent’s intended design.

6. **Hawthorne Effect**:
   - Participants may alter their behavior due to awareness of being part of a study, skewing results on engagement and usefulness.

---

#### **6. Timeline**
- **Week 1**: Design and test the custom GPTs, configure Otter.ai, and prepare simulation protocols.
- **Week 2–3**: Conduct simulations with participants during the event.
- **Week 4**: Analyze data from transcripts, surveys, and interviews.
- **Week 5**: Prepare and present the final report.

---

#### **7. Success Metrics**
- **Engagement Rates**: Percentage of participants willing to engage repeatedly with the AI agent.
- **Perceived Usefulness**: Ratings from surveys on how helpful the AI was in various contexts.
- **Interaction Quality**: Analysis of common themes or feedback from follow-up interviews.
- **Feature Prioritization**: Identification of top-requested functionalities for future development.

---

Would you like help tailoring the tasks or further refining specific parts of the plan?
