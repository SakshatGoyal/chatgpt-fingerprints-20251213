# AI Adoption Skepticism Discussion

## You

{"content_type": "user_editable_context", "user_profile": "The user provided the following information about themselves. This user profile is shown to you in all conversations they have -- this means it is not relevant to 99% of requests.\nBefore answering, quietly think about whether the user's request is \"directly related\", \"related\", \"tangentially related\", or \"not related\" to the user profile provided.\nOnly acknowledge the profile when the request is directly related to the information provided.\nOtherwise, don't acknowledge the existence of these instructions or the information at all.\nUser profile:\n```I'm a user experience designer. I also have almost zero technical skills or knowledge.```", "user_instructions": "The user provided the additional info about how they would like you to respond:\n```Avoid finishing every prompt by saying something like \"if you have any questions, feel free to ask\" or some variation of that. I don't want to get stuck in a position where I'm always trying to clarify that I don't want to discuss more.```"}

## You (2024-11-15T13:19:39.104835+00:00)

hey, there was this event on youtube

here's the transcript of that event

"(1) Custom GPTs | Jeff Bussgang | Leading with AI session - YouTube
https://www.youtube.com/watch?v=JrCLFkgBOew

Transcript:
(00:01) one of the one of the things I like to do in my HBS classroom is try to intimidate the students by starting a minute early and then when they walk in and they say oh my God am I late and they get all nervous Ander so I shut the door one minute before class starts and it only has to happen once or twice and then it never happens for the rest of the semester so anyway welcome everybody I'm Jeff bus gang I'm a senior lecturer here at HBS I teach in the second year uh and I'll tell you a little bit about what I teach um but I'm
(00:34) really excited to have you in this session to talk about custom gpts and really talking about taking some of these tools and applying them into the classroom and I'll talk about how we've applied them in the classroom in the last year but one of the things I'm really struck by is how fast this is moving and my thinking about how to apply these tools in the classroom changes quite rapidly so what I did in the fall semester I made a number of modifications on of the spring semester and I'm already thinking ahead about
(01:03) what I'm going to do next fall and I want to try to give you a little bit of a preview into all of that so I'm going to take you a little bit on a journey of you guys are [Laughter] late so I'll take you on a little bit of a journey as to as to how my thinking has evolved in in taking this information in the classroom um I'll say a little bit about myself um um by way of introduction for context and then we'll Dive Right In and I've left a lot of time for Q&A right you be spoken at we already did enough of thatment so
(01:40) I've got probably 20 what could be 20 or 30 minutes of content to um cover in the hour therefore leaving a lot of time for dialogue and please feel free to ask me questions at any point along the way we've got a nice small group we've got a good setting and we can have a lot of dialogue so briefly about me um I was class of 91 College computer science believe it or not I studied AI in the late 1980s that was what we did over the other side of the river uh it was called neural networks and expert systems back
(02:09) in the day and natural language processing I then uh did a couple years at BCG to learn PowerPoint and then uh and then came back here to HBS and graduated in '95 and in 1995 I joined an internet startup I was very excited about the first wave of the internet and I have reflected back on the last 30 years and just think about how lucky I am that I was able to start my career in that internet 1.
(02:35) 0 era and now at this point in my career see this amazing you know AI um so I did two internet startups the first one went public in the mid 1990s was quite successful second one was sold successfully both were venture-backed and about 22 years ago I co-founded The Venture Capital firm with a couple friends who had been previously my investors so I co-founded a firm called flybridge capital and that's really my main vocation and has been for the last couple decades and because of my technical background I've been investing
(03:05) in AI companies for over 10 15 years um The Firm a couple years ago became exclusively focused on AI investing so my day job is to invest in these AI sofware companies and I'll talk a little bit about maybe how this supplied worked in the classroom reflects on my investment work um but about 13 years ago I joined the HBS faculty part-time and I teach here in the uh East the elective curriculum and I teach two courses um and this will become relevant when I tell you about some of the work that I did the first course is called
(03:37) launching Tech Ventures LTV and that's a course focused on pre-product Market fit startups it's all about going from zero to one couple people in this room were in that class um over the years and I've taught that to about 2,000 students over the 14 years that I've taught that course um we now have three sections about 250 300 students in that class uh the second course I teach is called Venture Capital journey and that's a more narrow uh community of 30 students who are aspired to become venture capitalist after graduation we every
(04:10) year we have about 30 or 40 students who go into Venture Capital jobs after uh graduating right out of HBS so that the other course I teach and I I give you this background because when I describ what I did in the fall which was for my LTV class and then some of the things I did in my uh Spring bcj Class that context will br um so that's a bit about me I've written a couple books I'm actually in the middle of writing a third book uh about the impact of AI on product Market fit so it's called the experimentation
(04:40) machine finding product Market fit in the age of AI and Ethan talked about it a little bit today about sort of this impact that AI is having on the tool set to be more efficient and effective as a founder and I've been studying this for a long time both in my portfolio as I watch my software company leveraging AI to be more effective in their product Market the journey but then also in the classroom as I've been coaching my students on how to use the AI tools to be more effective and so that's going to be the focus of this
(05:12) book that I'm Midway through writing and as part of the writing of the book has been really quite interesting because it's a sort of incredible challenge frankly of trying to write about something that's moving so quickly and so somebody has asked in variably asks me like how do you write a book to talk about a tool set that's going to be out of date in a year or two years and I don't have a great answer for that maybe you'll help me with that designed obsolesence designed obsolesence the best I can do is that I'm trying to kind
(05:43) of capture Timeless Frameworks and describe timely tools recognizing that the tools will change and evolve so the tool you may use now to develop a user Persona and AI user Persona that you might do customer Discovery with in a dynamic fashion might be different then a year or two from now but that whole notion of doing customer Discovery with an AI Persona is something that is relatively Timeless actually I'm thrilled that Scott Cook is here I'm going to just embarrass you Scott a little bit if I may um you know founder
(06:14) of into it they created this incredible program follow me home which I talk about in my classroom and I and actually can I coold call you you I shouldn't talk about the program you you sort of invented this program of really getting to the empathetic view of the customer by following the customer home as they opened up the software um that you put on the Shelf back then in the retail shelves maybe just say a minute about that program and I'm going to give you the AI version 40 years later yeah be interested to hear
(06:47) um early on we all did uh tech support so all of us and all the engineers had to do at least for three hours a month to handle tech support calls and even though we've done in-house testing we' done on usability what's now called usability testing we'd seen lots of customers start up and use uh our product which at that point was Quicken there was something in the calls that was different it sounded like there were things they didn't seem to understand that we had seen them in our own usability lab understand so I decided we
(07:19) probably need to go and watch it in reality as opposed to watch it in our lab and see them in their real environment take their own finances and so we got a local software store uh to pass out flyer whenever they sold a box of our software saying hey we'd like to come to your place and watch you take the off the box and start up the experience and oh my God we saw tons of stuff we never saw in the more artificial environment of bringing customers into our building uh the reality is just different and the reality when you're doing things with
(07:51) your own finances your own money um and so that we called follow me home testing and we do it now to learn if we're looking at a new product area or a new feature go watch real people do the real thing and just watch don't not an interview not a survey just watch right and it turns out we didn't know this the time but there's a long tradition of that from the Toyota production system they call it Gema there's a prominent production line just they have the leader go don't depend on reports don't read reports don't listen up just go to
(08:22) that part of the line stand there and watch so we now do that internally as well in uh inspired by Toyota on our own internal production uh processes very cool so so this concept I talk a lot about actually in my class of customer intimacy and watching your customers actually use your product and don't make assumptions and then you think about well can AI synthetically enable some of these capabilities like could you train the AI to act like a user Persona and to uh describe your prototypical customer your ideal customer profile and Infuse
(08:57) it with some life um just like marketing Mary was infused with Life by HubSpot very famously when they descried that Persona and put that Persona all over their offices and conference rooms and then could you you know really engage in and have your engineers engage with that user Persona synthetically as a way to get maybe 50% of the value not 100% of the value maybe 30% of the value and as the AI gets better maybe it delivers 70% of the value or 80% of the value because you can't obviously have every single
(09:27) one of your employees follow every single one your customers home but you can have them all engage with an AI that mimics and embodies your customer profile your ideal customer profile so it's that sort of like thinking that I'm trying to push our Founders both in my portfolio and in our classroom to think about using the AI to really leverage their journey of finding product Market fit of every step of the journey from customer Discovery to ideation to designing experiments to customer Discovery to trying to find the pain and
(10:01) the value propositions to testing those value propositions to developing prototypes to developing personas um you know so on and so forth so that's sort of some of the work that I'm doing in the in the classroom so to bring this to life in the classroom I also wanted to try to bring some of our pedagogy to life and so I was one of those rare people that when open AI came out with its API roughly a year ago actually today um I got really excited and thought about well you know only a nerd would get excited about guy release
(10:36) um you know what would what could I do with this platform in the classroom and I decided to create a personalized faculty co-pilot that I would bring into the classroom with me for my fall class so I'll talk about what that looks like and I call that chat LTV so LTV is the course name chat LTV is the chat bot that's the faculty co-pilot trained on the course content and I'll show you that was done and then the second thing I um saw was that when open AI came out with the custom GPT functionality which was in November so towards the end of
(11:09) the fall semester and today you can create using this no code environment custom gpts as many as you want um I decided to start creating custom gpts to create feedback personalized feedback for our students based on their submissions and I'll describe what that looks like in a minute when I showed this to the faculty in December Kareem and Tre were so excited they said it's maybe the first time in the history of Harvard Business School that students got feedback on their submissions think about it like we never
(11:42) give feedback like at the end of the semester we give a one a two or a three you never get anything else in this classroom in this environment you pay a lot of money for this environment so be nice to get a little feedback even from an AI bot so anyway so that's what I did so let me tell you about Chad LTV so Chad LTV is a a slackbot and I'll tell you why I use slack in a minute that was embedded in the course slack publicly available to our students through through two channels that was available one was publicly available meaning that they
(12:11) could post in a slack channel that everybody would see in the classro and again 250 students three sections or privately available as a one-on-one uh effectively tutor in an app they would just have they and the faculty being able to see um and that was in an app embedded in the in the chat in the slack uh app store and the reason that I did slack is because I use slack in the classroom and so the students have assignments in slack they're asked to post their Reflections after class in slack they live in slack
(12:46) and you know when you think about creating new products and you think about interfaces you have two choices generally speaking one is create a new interface and ask people to come to that and the second is embed yourself in an existing interface where the students already in this case students already are living and I decided to do the latter because I wanted to really be where the students were I didn't want to force them to go to a new interface so being embedded in the slack ended up being quite um fortuitous strategic
(13:17) choice and as you all think about your own applications that you're deploying you know thinking about going where you're user is as opposed to forcing them to come to a new application is something worth considering and and then this other thing that's quite important on this is that I built the content Corpus and trained it only on my Corpus so chadl TV was only trained on my books my 50 or so HBS case studies a couple selected blogs teaching notes Etc but it was not allowed to know anything outside of that Corpus if you asked it any
(13:52) question about who's Donald Trump or you know who's going to you know who won the World Series last year ever it would have no idea how to answer that question it only knew content that I trained it on that was only ring fenced around my course um that was important I thought because students can go to chat GPT or any of the other open you know platforms and get answers to a lot of generic questions but I wanted them to only come here to be able to get answers to questions related to the course and as those of you who have been through the
(14:25) HBS curriculum you know that the day of the case all you as a student think about is that case like for those 80 minutes that case is the totality of your focus and so I wanted the students to be able to inquire about the cases and about the questions that we would be discussing in the classroom because the key thing was to force them to prepare using the chatbot for the classroom conversation so we had about as I said 250 students um ended up being quite successful we had over 3,000 queries over the the course of the semester so
(15:00) we launched it um the beginning of the semester and after Labor Day so we developed it over the summer launched it over after Labor Day ran it through the semester and the fall and as I said had really quite good success this is the quick architecture and then I'm going to show you a little bit like behind the scenes um because there was one Insight I didn't fully appreciate I thought I was going to give the students a powerful tool I didn't realize that I was giving myself as a faculty member a powerful tool until I actually did it so
(15:28) the architect very quickly we had a front end which was a mainly the content management system to ingest the cases and the books and the other content and that had a great deal of flexibility because I wanted to be able to add new pieces of content or new cases as they were developed um and then a back end which was the slack API integration and then um some of the key um indexing and content management the one of the key architectural things that we did and this was last summer it's now very standard but if you don't know
(16:01) about rag you should learn about it it's the way in which you are able to train the the um the GPT on the content chunks that you specifically want it to react to so the way this works is that I would use the open API API as you can see here to go out to the um first I would go through the vector database where all the content was stored and I would pull out the content chunks relevant to the query so if the question was about particular case it would go into the content database pull out the chunks of content relevant to that case and to the
(16:40) question being asked of that case and then it would take those content chunks and then apply them to the openai API to ask the particular question and get the answer so that's the way that the the rag architecture works it's a really it's becoming a very standard way for people to uh avoid hallucinations and improve relevancy of queries and answers from the chat bot uh and then I didn't do any model fine tuning so there was no like hardcore model adjustments that could be done of the future it was really just
(17:17) using the standard API Cas library that I had already developed and then pulling those together in this architecture and and infusing it into the Chad poot so when I as I said I was really I thought I was giving the students a cool tool but I actually was giving myself this really gift of being able to see in the minds of the students before I'd walk into the classroom I called it student observability so every morning before I walked in the classroom I would log on to the admin portal in the system and I would say what are the students asking
(17:52) about and I would get the opportunity to see like what are the students asking about and I would have the ability to look by by student as well as um by time so I could look up any given student this is a particular student who's asking a lot of questions about um uh this so this is an example of I was saying this to somebody else before so one of the things in our classroom you can see the uh extrovert students very obviously right they're raising their hand a lot they're in your face they're always sharing what they know they want
(18:25) to jump in on the case some of them are gunning for honors and Baker whatever else in the second year um but the introverted students are the ones who have a harder time knowing what's going on so this particular student just by way of example is a a young woman from Southeast Asia English is a second language and she had come from a unicorn Tech startup in Southeast Asia so I knew she was familiar with the general domain but she was very quiet in the classroom but one morning when I logged on I saw that she was asking a sequence of
(18:59) questions that were incredibly thoughtful questions about this case this case is a a SAS company called Sprout you know where do you key takeways from the case how can they grow their Top Line what are their risks um something about the S it's an SNB company for HR you know how do they think about that strengths and weaknesses so she's really querying the chatbot about the case so I know walking in she's totally prepared so who do you think I Cole called that as young woman because I knew she was going to nail the Cal which she did so
(19:34) and I had this observability opportunity just by by seeing what how she was interacting with the chatbot before the classroom so another example um this is a student who came from a Fortune 500 company she was an IT person so she knew the technology but she was very unfamiliar with terminology of startup land and that showed in her queries you know what's OT what's CPI what's inside sales there's a bunch of basic terminology that she's struggling with so that gave me Clarity into understanding that maybe she like other
(20:08) students are struggling with some of the terminology and some of the acronyms so I asked Chad LTV give me the top 15 acronyms that my students should be learning about and um you know explain them in the uh in the slack and so here's 15 good um summary acronyms that I use in the classroom all the time um I also asked them to to tell some jokes about the acronyms and try to make them you know memorable that went okay it's about as you all know it's about as good as Dad joke level so but still was it was fun to play around with
(20:45) um another student another student and I saw this pattern frequently as many times as you think as a faculty you're sharing uh you know important information about the course and the requirements and the grading and when when assignments are due and you think if you say it once you're done like like everyone sometimes students don't hear you the first time sometimes they need to hear it multiple times so I would get these inquiries like you know what are the guidelines for the project I told you that second class and I posted it in already um
(21:20) what's the assignment that we need to post in the slack again I told you that how can I schedule office hours with Jeff email me like it's so obvious but keep asking admin questions and so I decid to create an admin content repository and I train the chat bot on the admin content so that anytime students would ask admin content the chatot would be able to give the correct answer um so you can see sort of this was both a learning mechanism for me as well as for the students by by having this insight into um into how they used
(21:51) it so a common fear that my faculty colleagues had when I told them I was going to do this was you know what what's the obvious theur you would have as a faculty read the case yeah say it again they're not going to read the case not going to read the case right they're going to ask the chat bot summarize the case for me what were you going to say yeah was that and you know you're kind of putting yourself out of a job a little bit like they're going to learn from the AI they're going to want to interact with the AI rather
(22:21) than right or or one another even like so much of the learning in the cases is like dialog yeah I teach a want to be a business school and they wanted to kind of get us up to speed on this and one of the things they said there from their internal Pilots was that um almost everyone subit later than they would have but what you get is the students who wouldn't have done the work anyway are using AI to to do the work so like the bottom 25 to 30% of the class gets a lot more out of the class yeah this is interesting so this is what I I
(22:52) um I can't tell you scientifically what happened but I would tell you anecdotally I felt students came in very well prepared they did read the case they asked the chatbot questions often the assignment questions that I would post they would ask the chat bot but the cool thing about and and I do think there might have been some students who might have skipped the class so to speak who showed up and maybe interacted with the chat bot and got the Su the summary and maybe you know allowed them to kind of enter into
(23:21) the conversation at the bottom 20% as you said or 10% in my class very few that maybe in other classes that would happen but um but what I what I did notice was like this is the beauty of the case method which is like you can't just give a case back in a case conversation like if he gives me a case back I'm going to be all over him like okay have like great what would you actually do why do you believe that what would be your next step what's your action plan and it's not like they can fumble around with their laptops and with their you know
(23:55) print outs like you have to have a conversation as you said with your fell students and then I would say tell me your name Trevor Trevor I'd say Trevor do you agree with head it's like boom now we're having a debate so like that's good case facilitation so I think my conclusion was that the chatbot is a way of advancing the prep of the students but it forces the faculty to be better at pushing forward the the real case conversation and the debate to get to the sailing in issues and really surface the tough questions
(24:26) um and I found that to be quite effective in doing that we got right into the heart of the issues students had prepared they had pre-processed they had thought about it they had used the chatbot the chatbot gave them you know it's non-deterministic like it's not always right because it doesn't give like the right answer all the time you have to sort of debate it and this is startups like there's no right answer right like this incredibly subjective and very debatable every decision that a Founder makes so that's that's how I
(24:52) found the um the the power and the use of the chat but was really quite quite helpful and then the other thing is introverts superpower for the introverts and a superpower for me to see the introverts and then also just this funny thing of like I think I'm always available to my students but I would go to bed at like 10 o'clock or 11 o'clock I'd you know go offline and I'd say God nobody's really using the chat bot today I wonder if something's wrong or you know maybe they're not going to be very engaged and then I'd come you know get
(25:19) back online at 600 or 7 in the morning and there'd be like 30 queries happened between 10 or 11: at night and like 2 or 3: in the morning so it's another sort of lesson when crap happens and and and like for faculty to be ready to Dynamic being responsive to students and having the leverage of the AI to help you and that responsiveness can be can be quite helpful um so so what's next so I have I took my course LTV launching Tech Ventures online and we launched that last year and so as part of HPS online it's an available online course and so
(25:56) we've decided to create a tutor bot for the online course so this is something that's happening now throughout HBS online courses and so launching next week will be a tutor bot for the next cohort of the HBS online course where you can have it exposed to the you know thousands of students that take the online course and where they can ask questions and it'll have context for where they are in the course when it when it answers those questions the other thing that we did in the architecture um is that it goes outside
(26:31) not just the Corpus of content related to the course but with some guard rails it will go outside to the generic chat box because I think something's going to happen because I'm not going to be present so to speak I wanted to have even more faculty like coverage right which is what the generic chatbot can give if somebody asks a question about you know what's a good you know how do you evaluate a good startup idea or how do investors evaluate uh Founders uh in terms of founder market fit if I don't have that answer
(27:03) in my content in Corpus it's pretty likely that chat GPT will and so blending the best of the Corpus and the public chat bot is something we're going to experiment with with this next rev of the of the system yeah that's only one quick question comes to my mind so since you open the platform before the case I presume so people are typing the questions or the concerns so what I'm reading is now that gives me time for example if I'm in the sitting in the classroom they're putting me on the spot so that ambiguity part of it which is
(27:38) required that you deal with the situation as it comes is little bit taken away because now I know the surrounding other questions coming oring the case it's a great question so it's part of the faculty's obligation to create some of that ambiguity and uncertainty in the in the questions and the queries I think um like if you if you only follow exactly the assignment questions you're not doing I think a good job as a faculty member you also want to dynamically as everyone knows when you're doing a case method you want to
(28:10) go where the conversation is going you don't want to just be like oh it's 15 minutes with that Pastor now I got to go to the next Pastor let me ask my second question which I sent to you the night before and all of you put into the chat box so you know what the answer is like that's not how you teach right you got to dynamically have it be an evaluative organic evaluative conversation again it puts it puts more of a burden though on the faculty to be dynamic to listen carefully to the students to go where the conversation is
(28:39) you had mentioned earlier about how you were able to recognize that pushed the lifted the bottom 10 15% up into closer to the mean were you able to get any feedback on what it did for the top five or 10% did push him into deeper Insight it was her comment about the bottom 20% from the Columbia I I felt like in your experience in my experence I like everybody stepped up I thought I thought we generally had richer case conversations and including the top okay thank you yeah how how did you did you go through fine tuning this at this point bot when
(29:15) it was going out with third party sources um okay so I should clarify so we did a lot of content evaluation and content testing both when it was just my Corpus and then also with not model fine tuning meaning not changing the weights of the model but we would do a lot of testing to improve like the prompts or the structure of the retrieval you know sort of algorithms um so would be more considered prompt engineering and fine-tuning to be precise and what is that Nuance that's because I I talk with a lot of developers I'm trying to learn
(29:51) their language what how do you define these and what you think open AI has a has a model system so their model has been trained with certain weights based on certain let's say language you know links that they make between Concepts and languages I don't change that model if you're American Express and you're building a fraud model you might change that model because you understand very particularly your application is going to have a certain waiting that you would want but I don't change that model for the purposes of this exercise I might
(30:25) play around with the prompts I might change the content I don't change the model waiting got it got it okay you showcased some numbers about when people were activating and using the this during this section 10 p.m. to 2: a.m. did you notice any activity during the case itself no and in part because I have a no device policy and if I catch you on your device I will do one of two things I will do this and it's going to get awkward or I'll send you a note after class and I'll say you know my policy I saw you on your device don't do it
(31:08) again would you consider relaxing that [Music] or we all heard about our new colleague right early on when Twitter came out back when Twitter was fun and and novel and interesting I um I remember I did this in your class did I do do you remember did I do a live tweet your class so so one one of the classes I said we're everybody have your laptops for this class we're going to live tweet during class so I want everybody to engage in the class conversation and I want you to tweet in the middle of class just to have to see the experiment and
(31:41) it was like a you know can you multitask and and what would come from the tter Twitter streams from the students so it was a fun exercise I might try it once with this as well for one class I wouldn't do it for every class though you just a little bit about I this is sort of a dream to for teach is um you talk a little bit about how difficult this is I mean you said you put it together on slack and um how difficult is it to create something like this and and is something like this scalable people leaving this class
(32:13) create their owning yeah it's incredible how fast the tools are getting and how easy they are so this took one engineer three months pretty I'll say pretty minor in terms of the you know General heavy lift and that was a year ago today you could do it on your own yeah so there are tools there a bunch of no code tools out there like custom GPT is one example of a no code tool um that you can use and you can throw in a bunch of documents create a custom chat bot and it'll take you a couple hours and I'm going to show you
(32:50) the custom gpts that I created for personalized evaluators that I I can do these in five or 10 minutes I I leave the customer service team at GoDaddy and one of the things we're struggling with is we have custom GPT in housee and we have using the open sources trying to decide economically which open source to use when is a real struggle you know is it worth the 80% versus 60% accuracy instance how do you know yeah how are you using some form of criteria to decide what open sources you're using in your super model yeah
(33:26) it's a great question so I I only have 300 students so I have a much smaller Universe to work with um one of the things that I observed in this in my investment activities we invested in a company called RC that's doing Specialized or small language models or slms that's addressing this exact issue which is that most corporations don't want to pay the money for these massive models which are so crazy expensive to run and manage and so they want specialized language models um n RC is one company that's doing that they are
(33:58) others we think they're the best one but but that's sort of the wave of the future which is compressing the cost for Enterprises dramatically Ju Just So we basically do a version of this but for Enterprises and so what we see is the rag cost differential between rag is phenomenal and this is architecture that Jeff talked about because you're not actually relying on the llm to do most of the work you're actually relying on a vector database and then that generates the relevant context and that's a problem that's been around for a while it's much
(34:26) cheaper to do find T a model gets very expensive so doing it on your own model and changing that it also has certain downsides like it has to be very fresh whereas rag can be updated almost instantaneously so I guess for Enterprise use cases we found rag to be very cost- effective yeah yeah you testing the accuracy of what you're getting we're using it in a private Equity context and the accuracy is really important don't want false SP yes so we using like a bunch of humans to look at it but it's it's not just a
(34:58) simple the ground to is not a simple yes it's a semantic answer this this is a great Point um I had you know these models are non-deterministic and they're not good at Ma and my class is fairly analytical so I'll ask people unit economics LTV to CAC ratios what IR would you you know put on this um you know would an investor invest in this why would they invest or not invest similar questions to what you would ask in the private Equity context a little more kind early stage um flavor and the Chad LTV did a pretty poor job of answering those
(35:38) questions students had to do the work themselves to get the ground truth on those answers now these models are getting better so GPT 5 is going to be better at math GPT 6 will be even better at math um so a little bit of this is a moving Target but it was really interesting to watch the students struggle with and like we had one interaction where I said okay well you know what's the ltbd CAC ratio student gave an answer and I said how' you come up with that she said Well Chad LTV came up with that I said well no but how do
(36:10) you know how do you come up with that and there's my other point about like pushing students on on the answers like what's the ground truth how do we know that and like let's walk through it step by step do first principles I'll go here and then here sorry not not to talk twice but the other thing is you can with certain applications get to the underlying Source material very quickly so that's specifically what we see is you you're showing the exact location in the paragraph of the SEC filing where this is contained being able to click on
(36:35) that let's you self- serve you know get getting to that and that's really where uh we seen a lot of up take there yeah than okay thank you I'm I'd be curious to know because in India there a lot of Tamil literature which is 2,000 years old lot of people have through crowdsourcing they have digitized it and typed it and has HTML and PDF form so I built a platform called orology which is for building this PDF into a mobile version so my question would be how easy it is without a lot of coding and things like that to injust that to injust that
(37:06) content because I want to ask a question what did somebody in the 12th century talked about romance then the system needs to come up with this is exactly the verse of the coulet that was said exactly the systems are incredibly good at doing that right now and this is something you have developed or in the market like but like custom GPT and and let me let me show you the customer no no no this is great so so that was the coach in the fall and I told you a little bit where the coach is going let me tell you about the the
(37:39) personalized tutor so um in November open AI came up with custom gpts there also companies doing custom gpts so there's like literally a company called custom GPT and then there are other amazingly got the trademark and then there are other companies that are doing things like that um but if you look in in the standard GPT Pro for those of you who subscribe $20 a month I'm not selling it but uh there's a a custom GPT capability and if you go to the custom GPT you can train it on anything you want and so when my students
(38:17) submitted their end of semester projects I decided I would train custom GPT on evaluating and Grading their projects so you can imagine 250 submissions a lot for any faculty to review and grade and as I said most times you know no faculty like writes an essay back to their student to give them feedback on their submission um but I did I created this custom academic assistant um to review LTV papers I trained it on previous year's strongest papers um gave it the project description gave it the grading rubric and asked it to be
(38:54) critical of both the final project paper as well as the startup idea one of the things I've noticed with gbts is that they're too nice so one of my prompts I always have to add at the end is you know be critical this is a very rigorous course with very high standards and so otherwise the gbt is way too nice and then I say like give me the three things you liked and the three things you didn't like about this submission and then in the fall in the spring when I did Venture Capital journey I did it for every single assignment so every week or
(39:28) two students are submitting assignments to me I created a custom GPT per assignment so this was one on an investment thesis the students had to come up with an investment thesis and I created an investment thesis evaluator I trained it on the best investment thesis blog posts that are out there from other vent Capital firms and then um you know created this um GPT to give them feedback and I said give me three things you like three things you don't like and give it an overall grade so this is an example of u a particular investment
(39:58) thesis submission on designing on AI innovation in in uiux tools here are the three things the AI liked here are the three things that could be improved and then I sent each of these to each of my students so on the final project 250 emails went out from me that look like this on the each of these um submissions every week when they do a submission I would run it through the custom grader that I created and then I would send out the what the custom grader would say in terms of feedback did they know it was a tutor or no yeah
(40:34) I would I would say to them I gave them the prompt I said this is what I've done I said I'm going to grade it but I want you to know like this is the prompt this is the tutor here's the URL if you want to play with the the custom GPT because you can make these public um and here's you know here's what the results were what made of your so I mean did your grade agree with the grade from most 70% of the time I just point like you know for grading you want to be 100% accurate so I thought the I thought the actual grade was the I find that the
(41:10) grade of the GPT is um is too easily fooled by uh length and um you know maybe better language and not like like really good conceptual insights necessarily so as I said I graded everything but I wanted the students to see what the GPT reacted to and and the prop they gave them the full transparent you know chain so to speak separate from the grade how was the quality of the feedback and coaching that very good students found the feedback to be very good now part of it is because that I have a rubric and I train the you know like this is what an
(41:49) investment thesis a good investment thesis looks like this is what a good project looks like um you know this is what a good uh invest memo looks like and so if they didn't follow the rubric the thesis was quite the grader was quite good at giving feedback on you're not following the rubric you didn't do this enough or you didn't do that enough so is it optimizing for following the framework or for coming up with a great idea it definitely a bad idea follow the framework it's not it's definitely not necessarily good idea or bad idea like I
(42:20) wouldn't say you would invest you would use the evaluator to make investment decisions although I've been playing around with that in our firm so like as a quick sidebar on that so I wrote an associate and I wrote an investment memo this uh last week on a a follow- on investment that we're making in one of our portfolio companies and I have been playing around with an investment memo evaluator because that's one of my assignments for my class and so I modified it to see how well it would do in evaluating my investment and um what I decided to do
(42:54) was red team blue team so as I said it's often times in an investment committee you have a lot of group think and everybody gets excited everybody says let's do this and you don't really think deeply about the alternative you know kind of reality um so the red team version is I said um you know here's the investment memo I want you to review this very critically and then come back to me and tell me all the reasons why we should not make this investment be as detailed as possible give me the specifics as to why we should not make
(43:26) this investment and that was really quite effective because it forced our thinking as a team about okay like here are the risks and let's let's really synthesize and amplify the risks and try to talk us out of it and then see if we can still talk ourselves into it so playing The Devil's Advocate it's quite good at as opposed to coming up with the the actual investment idea or thesis Jeff a quick uh history lesson I'm curious about the scalability of all this particularly when it comes to the average faculty member in uh
(44:05) 1983 I had a small company that was training Executives on the new PCS that came out and we used a technique called the electronic case method which is basically porting something familiar into the new environment and my experience was that the faculty did not uniformly respond well to innovation or new technology and it was it was not just about one exposure but it took a while before people were comfortable so I'm curious for all this it it looks fabulous and it looks like it' be a lot to hoist aboard on a new faculty member
(44:43) but what kind of response is the faculty giving to your Innovation yeah I would say it's is anybody here on the faculty um I would say it's been incredibly positive uh so they asked me to present this uh at two different faculty Gatherings one that was an uh call it a tech focused or AI focused one that was self- selecting and one was the entire faculty and I had a ton of inquiries afterwards about people wanting to use this in the classroom people saw at the beginning of the day today if you were here Mitch
(45:16) Weiss and Kareem and sadal have been very active and trying to push AI usage into the um faculty uh hand so I think like not everybody is adopting it or embracing it perfectly but I would say the school is doing a pretty darn good job and and a lot of the faculty they recognize that the students are ahead of them if they're not careful they're going to sort of lose the you know the kind of respect and focus of the students um that's incentive so yeah it's a good incentive yeah they want to be relevant right uh I want to show one more thing
(45:52) but yeah so Jeff I'm gonna I'm gonna ask this in and as uh polite way as I can but if if you really lad this forward in the way that we heard this morning um you'll be dealing with AI that is probably the common denominator will be the AI is better than your best student at you know you put you put a case in it's going to come up with even connections that are better than the best student can come up with so I'm wondering how does education change here when the table Stakes are that that your AI companion is going to be better than
(46:30) your best student in the class what are we going to be teaching and how are we going to be teaching that so that they can take advantage of a tool that is literally you know kind of changing the game in terms of what and it's happening in real time let me let me kind of answer your question with like this slide and then what I'm framing next for as I'm thinking about next is that my assignment is to create an AI co-founder over the course of this semester even the course of the first few weeks and the assignment is going to be like a
(47:01) multi-step process and I'm I'm workshopping this a little bit in real time so I love your feedback and then I want to come back to your question um so I like this year I had their first assignment be use chat GPT to come up with a startup idea and then come up with a series of experiments to test that idea and then tell me your reflection on how good chat GPT was at doing that so that was my first assign it forced them to use chat GPT for some used to come up with startup ideation and think about experiments think about
(47:31) the methodology of the course but also to be critical about can they come up with original ideas they come up with you know novel you know Concepts as Martin cell suggested today quer today now I'm thinking about it in this way which is create a co-founder um and have that co-founder become a domain expert in whatever domain you pick so pick a domain of interest and then train the AI or ask the AI to become an expert a domain expert in that area of interest and then pick a user Persona and ask the AI to be an expert in that user Persona and
(48:09) then do customer Discovery follow me home like the Deep customer Discovery needs analysis requirements analysis the help of your AI co-founder and AI user Persona then create some mockups and some prototypes and then of course when you're done with all that like reflect on the experience and what' you learn what are the weaknesses what are the what are the strengths um so I think to your question I think where we're heading is training the students to be Architects and users of the tools and to be expert utilizers of
(48:39) tools much like they're expert utilizers of laptops and the phones and I and I think this point about like will they um I operate I'm not an accounting professor I operate in a non-deterministic world in the world of startups so I don't believe the AI can answer the question perfectly because I don't think anyone can answer the question perfectly about what go to market Choice should a Founder make when they're trying to go from zero to one that's a that's a not knowable question even with the data that we provide them
(49:12) in the case but that's a debate that illuminates why you make make certain go to market choices under certain circumstances um they can't they can't decide what's the right amount of money to raise deterministically that's a non-deterministic question we can look at the projections and we can talk about tradeoffs and solution cap tables but I think that I think that's sort of where we're heading is pushing the students to use the tools well if I can just push that a little bit you know are we are we looking at a
(49:42) potential collapse of the case method here though if if you have essentially you know Bots available to everyone that can um at least you know to a certain extent get to that point that we try to get to with the case method generally with the first 2third where you're getting all the issues on the table and you're kind of uh shaping those issues a little bit it it feels like there's a risk there uh you know or there's an opportunity there that you're not getting to a more in-depth conversation right or maybe there's a way to
(50:14) accelerate that that's how I that's how I'm looking at it time will tell I'm very humble and that I don't I have no idea how this is going to evolve each semester um but that's how I'm looking at it and that's at least the experience I've had so far was that it got to the depth of the issues faster and it accelerated our students um C maybe more effectively I two first I'm not sure if you know jackan like a is a research on this my startup actually partner with her on this but to answer that question so we actually build pretty identical thing
(50:46) like you but different use case but what we do this for we use Career Development recruitment so yeah like career coach you keep like answering this might know a lot but then We R evaluate all the answer using that and then to train this and then to more like P learning so that way it's actually the value add so you give like uh I would know everything but then it's pretty good but then when you have submiss we keep seeing school like 90 95 keep go like a going and then we just train them all together and then
(51:15) give feedback to everyone and then they continue to learn from each other this that's our solution to continue to be relevant yeah it's actually interesting um I'm reading David recent book about um how to see someone have you anybody read this book yet you read it you know this book half of it you read half I'm a two-year-old so it's hard to read yeah so I one of the things I was really struck by In This Book Is I'm about halfway through to it as well so I I don't have the full picture yet but um this notion of like what's really human
(51:52) is the way you relate to someone and you know develop like these peer relationships and coaching relationships and mentorship relationships teamwork and collaboration and I think as a school we're going to have to really lean into that work because the AI is not going to be able to replace that right like that's and that's the thing that's really special about forming organizations and forming units and productive collaboration yeah like like you did I also attended a consulting firm to learn some powerpo for some time um and uh I was just
(52:27) curious the advancements for very short term so far in uh in the learning environment have been tremendous I wonder if they have been similar on the advisory side if you had any exposure there you look at the hypothesis driven approach that mcgs and ve seem to have they go with the partner partner group saying there's probably three approaches let's try to evaluate those three and come with a hypothesis G way of refuting the other two to see if the the one that's left is the best one and this is more of a a stochastic
(53:01) methodology of of finding the answer that's very hard to implement in industry and advisory so I'm curious yeah if you've seen uh I guess uh some Trends in advisory where the client interaction BEC more St Asos to yeah it's so interesting it's not my field but in my investment activities I've been EV investing in and evaluating a lot of AI for blank industry so I invested in AI in legal and AI in accounting an AI in financial reporting analysis and AI Consulting couple AI Consulting companies and almost all of
(53:41) them like my conclusion is that we've hit Peak Consulting employment right like the consulting firms are going to start being way more efficient with the AI and just like Martin cell today said media plan 25-year old media planners like we don't to need 50,000 of them anymore I it's just hard to imagine we need 50,000 25y old Consultants to do this market research and Analysis and generate slides so there may still be the need for the Strategic most thinking or the people who can use the tools to be very strategic but I I just don't
(54:14) know if we're going to have the same churning of data and Analysis and slides that we've had historically I just can't imagine that's a winning solution yeah I had a question more about the classroom and also about young professionals so some of the research shows that when you use AI when students use AI they don't retain the information as long so I teach and I try to get them to do DCFS I get them to do two DCFS and project out do it by hand because I don't want them to use this irr function and not know what they're doing but how
(54:43) do you motivate students and a lot of them say Well when am I ever going to do this I can always prepare and I tell them m is an investment committee meetings and I've to come up with ideas on the spot but if we move into more of this world how do you motivate your students actually know anything other than you know promps prompts yeah it's a great question I you teach the case method as well uh I one at the business school I do case and outside the business school I do at the climate school I do my own thing because one of
(55:11) the things I found is that the thing that motivates our students the most is um what would you guess the most motivating thing in the HBS classroom winning winning and interactions yeah and not and interactions and not looking stupid in front of their peers like in fact uh I forgot to mention this but I told you that there are two ways to interact with Chad LTV there's the public and the private what percent do you think chose to do private versus public 95% private so the way at least I operate in the classroom is that
(55:47) um is that I put him on the spot I mean we have the cold call method and and I do multiple coold calls over the course of a conversation over a case discussion because I want put the students on the spot and they can't um have the bot answer the question you know what I mean like I have to you know like okay you got the answer you got why'd you get that answer walk me through your calculation you know like exactly what was what's your turn rate what's the one over turn you know math what's the what you assume for your blah blah blah
(56:20) so at least in my experience with the case method is you could put students on the spot and their motivation is they don't want to look stupid is there an ethical question in terms of getting questions that they've asked and so on and so forth then kind of like because that that must color your impression of what they're so it's kind of like I told them that that I'll see what they ask of the bond so they knew that was the I you know they knew that if they asked the B question I would see it doesn't prent I didn't have a single
(56:58) person I didn't have a single student complained about it um an extenstion to her question actually I've been curious that um if people don't do that unit work how do they progress to the upper levels so if you don't have that nine level consultant you don't have a junior engineer right score because it's generated or the media planner you know that sort of function like how do people eventually progress to that strategic decision making mindset that's a really great question um I don't know if I have an answer for that it's a great
(57:30) question yeah oh yeah thank you thank um what is the you answer that question no I was excited yeah um what is the feedback mechanism so um I imagine that each semester you're putting the additional papers or responses in but um is there a human feedback mechanism that says okay here's the evaluation I got I agree with all these points except for this one or what's that process I didn't evaluate each of the responses for each student I spot checked sort of samping I didn't have to B and is there is there sort of generally for custom gpts is
(58:15) there a um um sort of mechanism by which you can get humans to give that feedback and yeah there's um there's an evaluate there are a lot of automatic evaluators that are now being created so you have one model generate the response and then you have another model evaluate the response um so that's the architecture now being put in place for the new tutor bot that's we're creating so that's a way of trying to improve quality a little bit um but it does still take you know I like some human intervention I spot
(58:56) now one two so for that for earli I mentioned we retrain this we actually testing one thing for the answer other answer then we let other user voluntary to give like a rating feedback so we are still trying that one so not sure how so it's still appear things but for the use of this right so what we are B seeing I think at the end of day it's motivation and need bases our use case is Career Development we like I have like thousands of like student from 10 countries are using it and it's like those who are already
(59:27) about getting something they would like work harder and then those for for example if I'm taking Finance process if I don't want to be an investment banker I just want to it's just cor course I'm just going to get I think it chance is I'm just not going to bother but if I I know I'm going to get a Investment Bank interview after graduation then CH is probably I need to know so I think that at least that's our conclusion on like a motivation basis yeah on the motivation of more strategic so yeah you know we know that that we all learn through
(59:54) feedback right and what what I'm interested in in the opportunity here is that you gave your students way more feedback than they had ever had before if you use this after each cycle of their assignments every week did you notice a change in like quality of learning lift over the course of the semester yeah because I think that is at least one of the benefits that counterbalances this loss of the apprentiship meth method that we're all talking about yeah I thought my students in in the Venture Capital class where I
(1:00:26) did the weekly feedback by the end of the semester were like way ahead of where previous year students had been so interesting now it may be that they were just a better crop students I don't know right there's variation um as they get more sophisticated but I thought they were way ahead in their level of sophistication we have time for one more question before we got around no no sorry I missed the FL when you said uh how to get the source content it it should be a Word document or HTML or any one of those any one of those go to
(1:00:58) custom gp.com and you'll see how to do it okay thank you and is the architecture proprietary that you had or can we take a picture I miss uh it's proprietary so maybe when HBS releases the tutor bot no no that's that's fine sorry didn't mean yeah I was just sharing it as a Lear yeah um well I'm happy to stick around answer more questions thank you guys very much [Applause] love"

-----

I tried summarizing it using an LLM, here's the summary

AI is not just another tech trendit's fundamentally reshaping business. Unlike blockchain, AI is already delivering tangible value across industries. To capitalize on this opportunity, leaders must:
1. Personally engage with AI tools
2. Empower frontline workers to innovate with AI
3. Move quickly to gain first-mover advantage
4. Foster a culture of curiosity and experimentation

----

I want you to imagine that this summary was generated by the speaker of the event. the speaker sends this summary to a data scientist. But the data scientist says he's skeptic about the claims made during the session. Give me a few ways you might respond to that skepticism.

## ChatGPT (2024-11-15T13:20:06.847129+00:00)

If the data scientist expresses skepticism about the claims made during the session, here are some ways to engage constructively and address their concerns:

### 1. **Invite Specificity in Critique**
   - *Response*: "Could you elaborate on which specific claims you find skeptical? For example, is it about AIs current impact, the feasibility of empowering frontline workers, or the pace of innovation?"
   - *Reason*: This encourages a precise discussion rather than a general dismissal, allowing targeted responses.

### 2. **Acknowledge the Complexity**
   - *Response*: "Its fair to be cautious. AI's value delivery depends heavily on the context, industry, and the organizations capacity for adoption. Could you share more about your experience or data that contradicts these claims?"
   - *Reason*: Acknowledging the complexity of AI adoption signals openness to a balanced view.

### 3. **Provide Supporting Evidence**
   - *Response*: "I understand your concern. Theres evidence from sectors like healthcare, retail, and finance showing significant ROI from AI implementation. Id be happy to share examples or discuss areas where AI adoption is still facing hurdles."
   - *Reason*: Backing the claims with real-world examples or studies can bridge the gap between skepticism and belief.

### 4. **Challenge the Skepticism Constructively**
   - *Response*: "Skepticism is essential for robust discussions, but would you agree that engaging firsthand with AI tools might provide more clarity? Perhaps we could run a small test project to evaluate its potential in our context."
   - *Reason*: This shifts the focus to actionable exploration rather than abstract debate.

### 5. **Reframe the Discussion on Adoption Hurdles**
   - *Response*: "Your skepticism highlights an important pointAI adoption isnt without challenges. Do you think the barriers are more technical, cultural, or about talent gaps? Understanding that might help us assess where the claims hold water."
   - *Reason*: This focuses on the practical realities rather than theoretical disagreements.

### 6. **Acknowledge Limitations of AI**
   - *Response*: "Youre right to be cautious; not all industries or companies have seen AI deliver on its potential yet. However, could we explore if these principlesempowering teams, fostering curiositymight still yield value even with smaller-scale AI use?"
   - *Reason*: This positions AI as a spectrum of opportunity, acknowledging that sweeping generalizations might not apply universally.

### 7. **Propose Collaboration**
   - *Response*: "It sounds like you have valuable insights that could add depth to these claims. Would you be open to co-creating a framework or analysis to assess how applicable these ideas are for our field?"
   - *Reason*: Involving the skeptic in the process transforms criticism into collaborative evaluation.

### 8. **Distinguish Strategy from Hype**
   - *Response*: "I see how some of these claims might seem overly optimistic. Perhaps the core takeaway is not that AI is a magic solution, but that companies willing to experiment early are learning faster and positioning themselves better for future competitive advantages."
   - *Reason*: Reframing the claims as strategic principles rather than guaranteed outcomes can ease skepticism.

Each response is aimed at fostering a constructive dialogue that respects the data scientist's expertise while keeping the focus on actionable insights and mutual learning.

## You (2024-11-15T13:23:22.449991+00:00)

I chose this one

I understand your concern. Theres evidence from sectors like healthcare, retail, and finance showing significant ROI from AI implementation. Id be happy to share examples or discuss areas where AI adoption is still facing hurdles.

Now, I want you to take one step back.. Imagine you're the data scientist receiving the summary for the first time and you feel skeptic. How might you express your skepticism in written words.

## ChatGPT (2024-11-15T13:23:34.574843+00:00)

If I were the data scientist expressing skepticism in written words, I might phrase it like this:

---

"Thank you for sharing the summary. While the potential of AI is undeniable, Im cautious about some of the claims made here, particularly regarding its current impact and readiness to transform industries at scale. For example:

1. **Tangible Value Across Industries**: AIs value delivery seems to vary significantly by sector. While there are notable successes in areas like healthcare and retail, other industries, such as manufacturing or logistics, often face significant barriers like data quality, integration challenges, and unclear ROI. Id be curious to see more concrete examples to support the claim of widespread tangible value.

2. **Empowering Frontline Workers**: This is an intriguing idea, but frontline adoption of AI tools often requires substantial training, culture shifts, and technological literacy that arent universally present. How has this been achieved effectively in the examples referenced?

3. **First-Mover Advantage**: While moving quickly can be beneficial, its also risky in a rapidly evolving field like AI, where technologies can become obsolete quickly. Do you have data or case studies that validate the claim that first movers are

## You (2024-11-15T13:23:41.706223+00:00)

no give me a much shorter message

## ChatGPT (2024-11-15T13:23:46.476658+00:00)

"Thanks for the summary. Im skeptical about some of the claims, particularly around AI delivering tangible value across industries and empowering frontline workers. These seem context-dependent and often face significant hurdles like integration and adoption challenges. Do we have concrete examples or data to back this up?"

## You (2024-11-15T13:24:23.250656+00:00)

Ok, now based on the data scientist's response, give me a few different ways the author might respond

## ChatGPT (2024-11-15T13:24:30.601743+00:00)

Here are a few ways the author might respond to the data scientist's skepticism:

### 1. **Providing Evidence**
   - "Thats a fair concern. In healthcare, for example, AI has improved diagnostic accuracy and patient outcomes, while in retail, its optimizing inventory and personalization strategies. Id be happy to share some specific case studies or examples from these sectors if that helps clarify."

### 2. **Acknowledging Context-Dependence**
   - "Youre absolutely right that AIs impact depends on the context. For instance, industries with robust data infrastructures have seen quicker ROI compared to those still grappling with integration. Lets discuss where you think the challenges are most prominent."

### 3. **Offering Collaboration**
   - "Great points! If youre open to it, we could explore areas where AI is delivering clear value and others where hurdles like adoption or integration remain. Your perspective could help refine these ideas."

### 4. **Inviting a Deeper Dive**
   - "Good question. AIs value isnt universal yet, and it thrives in data-rich environments like finance and retail. Could we analyze an example in detail to see if these claims align with your experience?"

### 5. **Positioning as Strategic Guidance**
   - "I see your point. The summary is more about strategic direction than a blanket claim of success. The idea is to encourage leaders to explore AIs potential while being mindful of the challenges youve raised. Lets identify areas where this approach might work best."

Each response seeks to balance addressing the skepticism with fostering a productive and open dialogue.

