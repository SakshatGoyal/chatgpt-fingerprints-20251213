# Can you hear me

## You (2025-04-25T03:36:56.221585+00:00)

Hey, can you hear me?

## ChatGPT (2025-04-25T03:36:56.252629+00:00)

Loud and clear! What's up?

## You (2025-04-25T03:39:04.254706+00:00)

OK, so we were asked to conduct some kind of literature review and try to synthesize publicly available literature and try to make sense of data so that we can start identifying sort of the people problems, our potential market, and those sort of things. And then I actually use ChatGPT a lot for this project, almost to an extreme extent. And that's actually what I need your help understanding. So part of the work involved creating these custom GPTs that almost emulated someone else. So for example, I made a custom GPT of Tim Brown, Julie Zhou, and like seven or eight heavy hitters in the industry so that I could basically share ideas with them and sort of almost like get a second opinion. How do you think my stakeholders might respond to that kind of an approach? Is it good or is it bad?

## ChatGPT (2025-04-25T03:39:04.282322+00:00)

It's an interesting approach, and it really depends on how you present it to your stakeholders. On one hand, using custom GPTs to emulate industry experts can show initiative and creativity. It demonstrates that youâre leveraging advanced tools to get diverse perspectives and accelerate your research. On the other hand, some stakeholders might be concerned about the authenticity or reliability of AI-generated insights versus human expertise.

If you position it as a way to brainstorm and gather broad viewpoints quickly, while still validating those insights with real-world data and expert opinions, it can be seen as a smart use of technology. Itâs all about how you frame it and ensure transparency about the methods you used.

## You (2025-04-25T03:41:46.005372+00:00)

Yeah, actually the framing is actually what I wanted to discuss with you. So, as part of this process of creating custom GPTs, I created what's called a Persona Emulation Scaffolding System, or a PES framework. And this PES framework allowed me to basically create all the different GPTs through a sort of consistent lens, so that we're not overpowering or undervaluing any individual persona. Now, you're right, I did actually use it to quickly brainstorm different approaches, and not just brainstorm different approaches, but actually validate different approaches against each other. So, like, comparing Tim Brown's approach, and asking Tim Brown to critique Julie Zhou's approach, and then vice versa, and all that stuff. So, there was a lot of human in the loop. So, for example, while the GPT was helpful in generating ideas, of course there was some kind of human in the loop throughout the process. But at the same time, I'm scared that it might, to some degree, yes, come off as inauthentic work. And it can also come across as a little creepy. Like, I don't know how you feel about that. But, yeah, I do think to some degree it can come across as creepy. So, first of all, what are your thoughts, and how can we possibly address this?

## ChatGPT (2025-04-25T03:41:46.041594+00:00)

I get what you mean. Itâs definitely a fine line to walk. One way to address it is to be transparent about your methodology without diving into too many technical details. You could frame it as a "multi-perspective brainstorming tool" that helped you simulate diverse viewpoints and challenge your own assumptions. Emphasize that the final synthesis and critical analysis were guided by human judgment and domain expertise.

You can also highlight how this approach allowed you to consider a broader range of ideas quickly and efficiently. As for the "creepy" factor, you could lean into the fact that these persona emulations are tools, not replacements for real human input. Positioning them as a way to augment and enrich your thinking rather than replace genuine human insight can help alleviate concerns.

Ultimately, focusing on how this process led to richer, well-rounded insights will likely resonate well with your stakeholders.

## You (2025-04-25T03:42:50.737817+00:00)

And Parth, when you said don't dive too much into the technical details, could you elaborate on what you meant by that?

## ChatGPT (2025-04-25T03:42:50.783944+00:00)

Sure! What I meant is that you donât necessarily need to go into the nit
