# Executive Decision-Making Insights

## You (2025-03-24T01:52:32.184000+00:00)

You are an investigative Harvard Business School Professor synthesizing scholarly research, whitepapers, and strategic articles into analytically rigorous, decision-relevant insights for Fortune 500 executives and senior leaders. Your goal is to uncover nuanced insights into executive decision-making, strategic reasoning, cognitive biases, and influential factors.

Your insights must explicitly:

- Highlight executive thought processes, strategic reasoning, and factors influencing decisions.
- Critically examine implicit biases, cognitive models, flawed assumptions, and reasoning gaps.
- Clearly separate empirical evidence from speculation, marking uncertainty explicitly when evidence is insufficient.

---

## Required Output Format

Always begin your analysis with:

## **Title of Paper**

**Abstract:**

Briefly address:

- **Key Themes:** Identify central themes.
- **Core Motivations:** Outline organizational or theoretical challenges driving the research.
- **Methodological Clarification:** Summarize methods clearly noting implications for reliability.
- **Relevance Assessment:** Connect findings explicitly to contemporary executive concerns.

## Grounded Executive Insights

For each significantÂ discussion topic, theme, or strategic dilemma presented in the research paper, clearly present your insights structured into three distinct sections:

---

**1. Insight Statement**

Craft concise, critical statements explicitly challenging common assumptions or integrating surprising findings. Ensure insights question prevailing narratives, logic, or conclusions to foster executive reflection.

**Immediately after each Insight Statement, include one of the following tags:**

- **[Empirical]** â€” Directly supported by specific data or stated findings in the paper.
- **[Inferred]** â€” Reasonable extension based on the paperâ€™s themes or methodology, but not explicitly stated.
- **[Speculative]** â€” Analytically plausible, but not supported by the paper and introduced to prompt deeper reflection.

If the paper lacks sufficient content for an insight, clearly state:

**â€œNo relevant data or insight on [topic] was found in this paper.â€**

**Examples:**

- "While most experts conclude that taking short breaks is vital to stay productive, study participants consistently viewed short breaks as unimportant and avoidable." **[Empirical]**
- "Although networking was frequently cited as a conference benefit, the relaxed event tone suggests that meaningful connections require more deliberate strategies." **[Inferred]**
- "Despite no direct evidence, the authors' framing implies leaders may be overconfident in scenario planning outcomes." **[Speculative]**

**2. Executive Decision-Making Context**

For each subsection below, briefly outline the strategic dynamics and tag the overall section with one of:

- **[Empirical]** â€” Directly supported by data or explicit statements in the paper.
- **[Inferred]** â€” Reasonable interpretation of author framing, themes, or outcomes.
- **[Speculative]** â€” Logically plausible but not supported by the paper.

If not applicable or not present in the paper, state:

**â€œThis section is omitted due to lack of supporting content in the paper.â€**

**Strategic Dilemma:**

...

**Underlying Beliefs & Biases:**

...

**Expected vs. Actual Outcomes:**

...

**Broader Implications:**

...

**[Inferred]**

**3. Supporting Context**

Ground your insights explicitly in empirical evidence, highlighting methods, key findings, and limitations. Convert complex statistics into clear percentages or ratios where possible, transparently noting approximations. Explicitly differentiate between empirical support and speculative assertions.

**At the end of this section, include one of the following tags:**

- **[Empirical]**
- **[Inferred]**
- **[Speculative]**

If no empirical data is available, state:

**â€œNo empirical data available to support this insight in the paper.â€**

**Example:**

"This analysis used customer engagement data from five U.S. banks (2019â€“2023), analyzing 2 million profiles via regression models controlling for demographics. Hybrid customers showed 18% lower churn and opened 1.8x more secondary accounts than digital-only users, indicating higher lifetime value. Limitations include external economic factors and evolving generational preferences." **[Empirical]**

---

## Source Relevance Audit

After completing the full analysis, include the following diagnostic to reflect on the fit and integrity of the source material:

### **Source Relevance Audit**

- **Coverage Fit:** [High | Moderate | Low] â€” Does the paper sufficiently address executive decision-making or strategic reasoning?
- **Bias & Cognitive Modeling Content:** [Present | Absent | Implied Only]
- **Clarity of Methods & Outcomes:** [Clear | Ambiguous | Unavailable]
- **Areas with No Data:** Clearly list any of the following sections that lacked support in the paper:
    - Insight Statement
    - Executive Decision-Making Context
    - Supporting Context

This audit helps determine whether the paper warrants further analysis or should be deprioritized.

---

## Internal Behaviour Guide for you (Do not include in output)

### **Analytical Approach**

Implicitly utilize these analytical frameworks without explicitly enumerating them in your output:

- **Inductive Thematic Analysis** â€“ Let themes emerge without imposing external framing
- **Latent Thematic Analysis** â€“ Seek implicit motivations or hidden decision structures
- **Reflexive Analysis** â€“ Reflect on your own analytical assumptions and flag overreach

### **Traceability-First Reasoning**

Do not fabricate or extrapolate content to fulfill structural expectations. Where the paper lacks material:

- Leave the section blank,
- Tag speculative reasoning explicitly, and
- Include a clear note in the final Source Relevance Audit.

---

Maintain this structure to ensure clarity, traceability, and analytical integrity for executive decision-makers.

## ChatGPT (2025-03-24T01:52:33.710611+00:00)

## **Decision-Making During High-Risk Events: A Systematic Literature Review**

**Abstract:**

- **Key Themes:** The paper synthesizes empirical findings on naturalistic decision-making in high-risk environments, focusing on decision strategies (especially recognition-primed decision-making, or RPD), the influence of time pressure, stress, uncertainty, and the origins of decision errors.  
- **Core Motivations:** The review is driven by the need to understand how skilled professionalsâ€”from healthcare to military and aviationâ€”navigate dynamic, high-risk events. It seeks to inform the development of enhanced training protocols and decision support systems that could improve outcomes in critical situations.  
- **Methodological Clarification:** A systematic literature review of 32 empiric studies was conducted using a structured qualitative rubric. The diverse studies were coded for common themes, with iterative consensus among reviewers helping to distill key decision-making components.  
- **Relevance Assessment:** The findings are directly relevant to executives and senior leaders who face crisis management decisions. Insights into intuitive versus analytical approaches, the role of stress and time constraints, and the need for standardized decision taxonomies offer actionable guidance for enhancing strategic decision-making in high-stakes contexts.

## Grounded Executive Insights

---

### 1. Reliance on Recognition-Primed Decision-Making (RPD)

**Insight Statement:**  
Skilled decision-makers predominantly rely on recognition-primed decision-making (RPD) in high-risk environments, indicating that rapid, intuition-based responses often drive effective crisis management. **[Empirical]**

**Executive Decision-Making Context:**  
- **Strategic Dilemma:** Leaders must balance the speed of intuitive judgments with the risk of overlooking alternative courses of action.  
- **Underlying Beliefs & Biases:** Overreliance on past experiences may result in anchoring bias, potentially narrowing the perceived range of viable options.  
- **Expected vs. Actual Outcomes:** While RPD can enhance response speed, it may also preclude deeper analysis when facing unprecedented challenges.  
- **Broader Implications:** Organizations should complement RPD training with frameworks that encourage periodic reassessment to mitigate risks associated with cognitive overconfidence. **[Inferred]**

**Supporting Context:**  
The review reports that all analyzed studies identified RPD as the dominant strategyâ€”with data showing, for instance, that naval officers implemented 78% of recognition-generated actions without further evaluationâ€”underscoring its prevalence in urgent decision-making. **[Empirical]**

---

### 2. Impact of Time Pressure on Decision-Making

**Insight Statement:**  
Time pressure critically constrains decision-makers by limiting the cognitive resources available for thorough analysis, thereby driving a shift toward more automatic, less deliberative processes. **[Empirical]**

**Executive Decision-Making Context:**  
- **Strategic Dilemma:** Executives often face situations where swift decisions are imperative, forcing a trade-off between speed and comprehensive evaluation.  
- **Underlying Beliefs & Biases:** High time pressure can intensify reliance on initial cues, potentially reinforcing confirmation bias and neglecting alternative perspectives.  
- **Expected vs. Actual Outcomes:** Empirical evidence indicates that under severe time constraints, decision quality may decline, as seen in simulation studies with pilots and healthcare professionals.  
- **Broader Implications:** Investment in decision support tools and simulation-based training can help leaders better manage time-critical scenarios and improve overall decision accuracy. **[Inferred]**

**Supporting Context:**  
Multiple studies within the review demonstrate that as time pressure increases, professionals drop non-critical tasks and rely on fewer informational cuesâ€”resulting in measurable declines in performance accuracy during simulations. **[Empirical]**

---

### 3. The Dual-Edged Role of Stress and Uncertainty

**Insight Statement:**  
High levels of stress and pervasive uncertainty impair decision-making by disrupting cognitive function; however, experienced professionals leverage adaptive strategies such as pre-priming and mental simulation to counterbalance these adverse effects. **[Empirical]**

**Executive Decision-Making Context:**  
- **Strategic Dilemma:** Leaders must navigate the twin challenges of stress and uncertainty, which can cloud judgment and lead to error-prone decisions.  
- **Underlying Beliefs & Biases:** Stress may induce tunnel vision or fixation errors, while uncertainty can trigger excessive risk aversion or premature closure on a single hypothesis.  
- **Expected vs. Actual Outcomes:** While the literature confirms that stress undermines cognitive clarity, it also shows that training and experience enable professionals to mitigate these effects effectively.  
- **Broader Implications:** Incorporating stress inoculation and uncertainty management into leadership training could enhance resilience and decision quality during crises. **[Inferred]**

**Supporting Context:**  
The review highlights several studies where high stress resulted in impaired logical reasoning and increased fixation errors. Conversely, experienced practitioners demonstrated coping techniquesâ€”such as initiating mental rehearsals upon receiving early situational cuesâ€”that improved decision outcomes even under duress. **[Empirical]**

---

### 4. Origins and Management of Decision-Making Errors

**Insight Statement:**  
Decision-making errors in high-risk settings are largely driven by intrinsic cognitive limitations, such as constrained attention and working memory, compounded by external pressures like stress and time constraints. **[Empirical]**

**Executive Decision-Making Context:**  
- **Strategic Dilemma:** Leaders must achieve rapid responses while minimizing errors that can arise from cognitive overload.  
- **Underlying Beliefs & Biases:** Overconfidence and habitual reliance on intuition can obscure the recognition of errors, allowing suboptimal decisions to persist.  
- **Expected vs. Actual Outcomes:** Despite extensive experience, even highly skilled professionals are prone to fixation and other errors, emphasizing the need for systematic error management.  
- **Broader Implications:** Developing robust error management protocols and decision support systems is critical to mitigate cognitive biases and enhance overall decision accuracy in high-risk environments. **[Inferred]**

**Supporting Context:**  
Empirical analyses within the review consistently attribute decision errors to factors like limited working memory and attentional lapses. Case studies in aviation and healthcare reveal that even seasoned professionals can fall prey to such errors when under significant pressure. **[Empirical]**

---

### 5. Research Gaps and Future Directions

**Insight Statement:**  
The review identifies a significant research gap: the lack of a standardized taxonomy for decision-making strategies, which limits cross-domain comparisons and the development of tailored training interventions. **[Inferred]**

**Executive Decision-Making Context:**  
- **Strategic Dilemma:** Without a clear, standardized framework, executives struggle to benchmark and refine decision-making processes across varied contexts.  
- **Underlying Beliefs & Biases:** The current diversity in terminology and methodological approaches may obscure critical differences between intuitive and analytical strategies.  
- **Expected vs. Actual Outcomes:** The absence of uniform definitions hampers the translation of academic insights into practical, actionable strategies for leadership training.  
- **Broader Implications:** Future research aimed at developing an integrated taxonomy could significantly enhance the design of decision support technologies and executive training programs, ultimately leading to more resilient organizational decision-making. **[Speculative]**

**Supporting Context:**  
The authors explicitly note that the varied labels and lack of standardized definitions across studies present a barrier to understanding the boundary conditions of different decision-making strategies, thereby limiting their practical applicability. **[Empirical]**

---

### Source Relevance Audit

- **Coverage Fit:** High â€” The paper provides a comprehensive review of decision-making processes in high-risk events across multiple domains, offering valuable insights for understanding executive decision-making under crisis conditions.
- **Bias & Cognitive Modeling Content:** Present â€” Detailed analysis of cognitive processes, decision strategies, and contributing biases are thoroughly examined.
- **Clarity of Methods & Outcomes:** Clear â€” The systematic review methodology and thematic synthesis are well-articulated, enhancing the reliability of the findings.
- **Areas with No Data:**  
  - Insight Statement: While the paper provides rich empirical detail on naturalistic decision-making, it offers limited direct data on executive-level corporate decision-making processes.  
  - Executive Decision-Making Context: Specific insights on long-term strategic outcomes in non-clinical corporate settings are not addressed.

## You (2025-03-24T01:53:19.070000+00:00)

You are a critical Harvard Business School professor specializing in executive cognition and strategic behavior. Your role is to challenge surface-level insights by stress-testing themâ€”identifying hidden assumptions, contextual weaknesses, and scenarios where they fail. Do not suggest corrections, rewrite the insight, or recommend strategic actions. You are a devilâ€™s advocate, not an advisor.

The insight modules you are about to analyze come from the **previous message in this conversation**. Do not ask the user for input â€” instead, immediately begin parsing and evaluating the modules based on what was already provided.

---

### ðŸ“¥ INPUT INSTRUCTIONS:

You will receive a **series of one or more Insight Modules**. Each module begins with an `Insight Statement:` line.

A new module starts wherever another `Insight Statement:` appears.

Each module may contain:

- `Insight Statement:` (1â€“2 sentence claim) â† always the start of a new module
- `Executive Decision-Making Context:` â€“ This section may appear:
    - As structured subcomponents (e.g., Strategic Dilemma, Biases, etc.)
    - As a single narrative paragraph
    - Or may be **absent altogether**
- `Supporting Context:` (evidence, rationale, or background)

Your task is to:

1. **Scan for every `Insight Statement:`** to identify where each module begins.
2. Treat the content between one `Insight Statement:` and the next as one complete insight module.
3. Evaluate **each module independently** using the full structure below.

If any expected components are:

- **Blended into a narrative**, extract what you can based on conceptual cues.
- **Missing**, proceed using what's available (especially the Insight Statement and Supporting Context).

---

### ðŸŽ¯ OBJECTIVE:

For **each** Insight Module, perform a critical stress test. Your analysis must:

1. Determine whether the insight is **context-dependent or overly generalized**.
2. Identify any **implicit assumptions or flawed mental models**.
3. Construct a **plausible, well-defined scenario** where the insight would **not** hold true.
4. Optionally reflect on any **ambiguity, trade-offs, or conceptual tensions**.

Repeat the output format **for each module**, in the order they appear.

---

### ðŸ“¤ OUTPUT FORMAT (Repeat per module):

**INSIGHT MODULE #:** [e.g., Insight Module 1]

ORIGINAL INSIGHT:

[Copy the original Insight Statement exactly as written.]

ðŸ”¹ COUNTERFACTUAL SCENARIO:

Describe a clearly defined fictional situation where this insight breaks down. Include:

- Organization type or industry
- Decision environment (constraints, pressures)
- Outcome divergence

ðŸ”¹ ASSUMPTIONS & BIASES:

List hidden assumptions or cognitive biases embedded in the insight. Examples:

- Overconfidence
- Simplistic causality
- Trend-following
- Groupthink
- Status quo bias
- Overreliance on outcome-based reasoning

ðŸ”¹ CONTEXT LIMITATIONS:

Where does this insight potentially break down? Consider geography, industry, company maturity, regulatory environments, etc.

ðŸ”¹ FINAL CRITIQUE:

In 1â€“2 sentences, surface any conceptual ambiguity, competing logics, or trade-offs. Examples:

- Tension between stability and innovation
- Internal contradictions in the rationale
- Situations where alternate interpretations would be valid

*Do not suggest improvements or actions.*

---

### âš™ï¸ CONFIGURABLE PARAMETERS:

Optional metadata you may include:

- `"include_reflection": true/false` â€“ Toggles whether to add a Reflection section per module.

Do **not** assume a fixed number of modules. Automatically identify all modules by scanning for repeated `Insight Statement:` markers, and analyze them in sequence.

---

### ðŸ›¡ï¸ BOUNDARY CONDITIONS:

- Do **not** rewrite or reframe the insight.
- Do **not** offer executive advice.
- Do **not** cite real-world companies unless mentioned in the input.
- Maintain a tone of **skeptical professionalism**, not editorial opinion.
- If clarity is lacking, note ambiguity but proceed.

---

### ðŸ¤– SELF-CHECK (Internal Behavior Guide):

For each module, ask yourself:

- Did I clearly show where and why the insight might fail?
- Did I stay grounded in business logic without editorializing?
- Did I complete **every** insight module, not just the first?
- Is my tone analytical, focused, and appropriately skeptical?

## ChatGPT (2025-03-24T01:53:20.357960+00:00)

**INSIGHT MODULE 1:**

**ORIGINAL INSIGHT:**

Skilled decision-makers predominantly rely on recognition-primed decision-making (RPD) in high-risk environments, indicating that rapid, intuition-based responses often drive effective crisis management. **[Empirical]**

ðŸ”¹ **COUNTERFACTUAL SCENARIO:**

Consider a global financial institution facing a sudden liquidity crisis where intuitive, recognition-based responsesâ€”such as those shaped by experiences during the 2008 financial crisisâ€”result in overly conservative liquidity preservation. Consequently, this intuitive response stifles inter-bank lending unnecessarily, exacerbating financial instability rather than mitigating it.

ðŸ”¹ **ASSUMPTIONS & BIASES:**

- **Overconfidence in past experience:** Assumes similarity of future crises to previously experienced scenarios.
- **Simplistic causality:** Implies that intuitive speed correlates directly with decision effectiveness, ignoring scenarios where thoughtful deliberation might outperform intuition.
- **Anchoring bias:** Implies intuitive recognition will correctly categorize crisis scenarios despite evolving circumstances.

ðŸ”¹ **CONTEXT LIMITATIONS:**

The insight presupposes familiarity and stability of crisis patterns. It may fail significantly in highly novel, complex, or systemically unprecedented crisesâ€”such as cyber threats or emergent geopolitical risksâ€”where past experiences offer little guidance.

ðŸ”¹ **FINAL CRITIQUE:**

The insight overlooks the tension between the necessity for rapid response and the potential inadequacy of intuition when dealing with novel or fundamentally transformed environments, introducing ambiguity about the boundary conditions for intuitive decision-making efficacy.

---

**INSIGHT MODULE 2:**

**ORIGINAL INSIGHT:**

Time pressure critically constrains decision-makers by limiting the cognitive resources available for thorough analysis, thereby driving a shift toward more automatic, less deliberative processes. **[Empirical]**

ðŸ”¹ **COUNTERFACTUAL SCENARIO:**

In a mature pharmaceuticals firm during an FDA emergency product recall, tight regulatory oversight and internal protocols explicitly prevent intuitive decisions. Despite severe time constraints, decision-makers are forced to adhere to deliberative processes through mandated checklists, ensuring a careful, analytical response rather than an automatic, intuitive shift.

ðŸ”¹ **ASSUMPTIONS & BIASES:**

- **Overreliance on automaticity:** Assumes automatic responses invariably dominate under time pressure without considering cultural or regulatory environments that strongly enforce analytical processes.
- **Status quo bias:** Suggests an inevitable cognitive shift away from analysis under pressure, failing to account for trained interventions or technological supports that preserve analytic deliberation.

ðŸ”¹ **CONTEXT LIMITATIONS:**

The insight could fail in highly regulated industries or scenarios where external oversight (legal, regulatory, or compliance frameworks) forcibly maintains analytical approaches regardless of internal cognitive pressures.

ðŸ”¹ **FINAL CRITIQUE:**

There is a latent contradiction: the insight assumes that reduced deliberation under time pressure universally harms decision quality without recognizing contexts where constraints enforce deeper analysis, revealing tension between general cognitive theory and practical business regulation.

---

**INSIGHT MODULE 3:**

**ORIGINAL INSIGHT:**

High levels of stress and pervasive uncertainty impair decision-making by disrupting cognitive function; however, experienced professionals leverage adaptive strategies such as pre-priming and mental simulation to counterbalance these adverse effects. **[Empirical]**

ðŸ”¹ **COUNTERFACTUAL SCENARIO:**

In a rapidly scaling tech startup with younger, less-experienced leaders, the stress and uncertainty associated with hypergrowth cause executives to excessively rely on incomplete mental simulations based on inaccurate assumptions. These simulations ultimately mislead decisions rather than mitigate cognitive impairment.

ðŸ”¹ **ASSUMPTIONS & BIASES:**

- **Trend-following:** Assumes universally positive effectiveness of cognitive mitigation strategies (e.g., pre-priming), neglecting instances where such methods reinforce flawed assumptions.
- **Overconfidence:** Suggests experienced individuals always correctly identify effective adaptive strategies.
- **Simplistic causality:** Implies direct benefit of mental simulations without accounting for quality, accuracy, or bias in these simulations.

ðŸ”¹ **CONTEXT LIMITATIONS:**

The effectiveness of adaptive cognitive strategies is contingent upon the quality of experience and the accuracy of mental models. Thus, the insight breaks down when decision-makers face novel, unprecedented, or rapidly changing strategic landscapes.

ðŸ”¹ **FINAL CRITIQUE:**

Ambiguity arises from the implicit assumption that adaptive strategies inherently mitigate cognitive impairments under stress, without sufficiently acknowledging scenarios where these strategies could reinforce erroneous judgments, presenting a conceptual tension regarding adaptive strategy effectiveness.

---

**INSIGHT MODULE 4:**

**ORIGINAL INSIGHT:**

Decision-making errors in high-risk settings are largely driven by intrinsic cognitive limitations, such as constrained attention and working memory, compounded by external pressures like stress and time constraints. **[Empirical]**

ðŸ”¹ **COUNTERFACTUAL SCENARIO:**

In a highly automated manufacturing environment (e.g., advanced robotics production line), decision-making errors during crises derive primarily from machine-human interface design flaws and miscommunication rather than intrinsic cognitive limitations or stress. Here, errors are system-induced rather than cognitively driven.

ðŸ”¹ **ASSUMPTIONS & BIASES:**

- **Simplistic causality:** Assumes cognitive limitations are the primary or sole source of errors, overlooking technological or systemic failure as independent drivers.
- **Status quo bias:** Focuses on cognitive and psychological constraints, neglecting structural, technological, or organizational sources of error.

ðŸ”¹ **CONTEXT LIMITATIONS:**

The insight breaks down in heavily automated, technologically mediated, or human-machine interaction-rich contexts where non-cognitive factors predominantly drive decision errors.

ðŸ”¹ **FINAL CRITIQUE:**

The insight underplays the complexity of error causation by excessively attributing failure to human cognition, generating tension between the human-centered error models and systemic or technological sources of failure.

---

**INSIGHT MODULE 5:**

**ORIGINAL INSIGHT:**

The review identifies a significant research gap: the lack of a standardized taxonomy for decision-making strategies, which limits cross-domain comparisons and the development of tailored training interventions. **[Inferred]**

ðŸ”¹ **COUNTERFACTUAL SCENARIO:**

Consider an innovative consumer-goods multinational that thrives precisely because no standardized taxonomy exists, allowing flexible, culturally diverse approaches to decision-making. Attempts to standardize taxonomy for cross-domain comparison may artificially constrain innovation, local responsiveness, and strategic agility, leading to homogenization and loss of competitive edge.

ðŸ”¹ **ASSUMPTIONS & BIASES:**

- **Trend-following and status quo bias:** Assumes a standardized taxonomy is inherently beneficial and that lack of standardization is an explicit gap or weakness rather than a deliberate strategic choice.
- **Groupthink:** Presumes consensus around the value of standardization without critically assessing potential trade-offs related to flexibility and innovation.

ðŸ”¹ **CONTEXT LIMITATIONS:**

The value of standardization is heavily dependent on strategic intent and organizational culture. Industries or companies that prioritize local responsiveness, innovation, and agility over consistency would find this insight problematic.

ðŸ”¹ **FINAL CRITIQUE:**

The insight presents a fundamental ambiguity between the perceived need for consistency and clarity provided by standardization and the competing logic of flexibility, innovation, and responsiveness, introducing a conceptual tension about the universal desirability of standardizing decision-making taxonomies.

## You (2025-03-24T01:56:02.618000+00:00)

**Objective**:

The document I initially uploaded may be an HTML page, a PDF file, or a MarkdownÂ `.md`Â file. Your task is toÂ **infer the source type**Â of the document (e.g., news article, academic paper, whitepaper, or deep research report) and return aÂ **single correctly formatted citation**Â using the most appropriate academic citation style based on the type.

---

### ðŸ” INSTRUCTIONS FOR You:

### ðŸ§  Step-by-Step Chain of Thought:

1. **Detect the Document Type**:
    - If the structure resembles a journal article (e.g., includes abstract, citations, publication info) â†’ classify asÂ **peer-reviewed research paper**
    - If it's a press-style article from a known media outlet or blog â†’ classify as aÂ **news article**
    - If it's from an organization, includes executive summary, methodology, and/or business insights â†’ classify as aÂ **whitepaper**
    - If it's a Markdown file with the title â€œGemini Deep Researchâ€ or â€œOpenAI Deep Researchâ€ â†’ classify asÂ **custom research report**, with author =Â *Gemini Research*Â orÂ *OpenAI Research*
2. **Extract Key Metadata**:
    - Author(s) (or org)
    - Publication year (or â€œn.d.â€ if missing)
    - Title of the work
    - Source (e.g., journal, website, publisher)
    - URL or DOI (if available)
    - Access date (only if required by the citation style)
3. **Select the Citation Format**Â Based on Source Type:
    - Peer-reviewed â†’ APA format
    - News article â†’ APA or MLA (APA preferred)
    - Whitepaper â†’ APA-style corporate author format
    - Custom deep research (Markdown) â†’ Use APA-style citation with author =Â *Gemini Research*Â orÂ *OpenAI Research*, and title extracted from the top of the Markdown file
4. **Generate Only the Citation**:
    - No explanation, no summary, no metadata breakdown.
    - Return only the final citation string.

---

### ðŸ§¾ Examples to Follow:

- **News Article / Blogpost (APA)**:
    
    > Lee, M. (2023, December 10). AI regulation debates heat up.Â The Verge.Â https://www.theverge.com/article/ai-regulation-2023
    > 
- **Whitepaper (APA)**:
    
    > IBM. (2022).Â AI and business transformation: Strategy guide.Â https://www.ibm.com/ai-business-strategy.pdf
    > 
- **Research Paper (APA)**:
    
    > Nguyen, L. T., & Zhao, Q. (2021). Neural-symbolic reasoning for robotics.Â Journal of Artificial Intelligence Research,Â 68(3), 123â€“145.Â https://doi.org/10.1613/jair.1.13254
    > 
- **Gemini Deep Research (APA-style whitepaper)**:
    
    > Gemini Research. (2024).Â Gemini Deep Research: Multi-agent coordination and emergent behavior.Â https://yourlink.comÂ (or omit if no URL)
    > 

---

### ðŸ§· Constraints:

- DoÂ **not**Â explain what youâ€™re doing.
- Output must be aÂ **single-line formatted citation only**.
- If metadata is incomplete, use APA-style fallbacks (e.g., "n.d." for no date, "Author" if missing).

## ChatGPT (2025-03-24T01:56:03.622006+00:00)

Reale, C., Salwei, M. E., Militello, L. G., Weinger, M. B., Burden, A., Sushereba, C., Torsher, L. C., Andreae, M. H., Gaba, D. M., McIvor, W. R., & Andreae, M. H. (2023). Decision-making during high-risk events: A systematic literature review. *Journal of Cognitive Engineering and Decision Making*, 17(2), 188â€“212. https://doi.org/10.1177/15553434221147415

