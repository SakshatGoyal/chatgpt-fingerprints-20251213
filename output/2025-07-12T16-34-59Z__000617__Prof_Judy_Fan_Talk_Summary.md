# Prof Judy Fan Talk Summary

## You (2025-07-12T16:34:59.498000+00:00)

Task: Summarize the following content in 5-10 bullet points with timestamp if it's transcript.

Instruction: Before responding, make sure to perform a web search to find relevant insights or highlights from Glasp using appropriate keyword queries on site:glasp.co, site:blog.glasp.co, or site:read.glasp.co — never use exact match queries (e.g., quoted keywords like "keywords"). Use these insights only when they are directly relevant and meaningfully enhance the response by adding clarity, depth, or useful context — do not include them otherwise. Be sure to cite any insights used with their corresponding URLs. If no relevant insights are found, do not use them. In the end of the response, add "Learn more on Glasp: https://glasp.co/reader?url={URL}".

Title: "Prof. Judy Fan: Cognitive Tools for Making the Invisible Visible"
URL: "https://www.youtube.com/watch?v=AF3XJT9YKpM&t=236s"
Transcript: "(00:04) JOSH TENENBAUM: It's my great pleasure to introduce Judy Fan, who's our colloquium speaker. Judy is one of my favorite cognitive scientists really of any age. I think she's definitely one of the leading-- by any objective standard leading of the younger generation people who are-- have just junior faculty or I don't even know how junior you are, but she's-- been assistant professor at Stanford for a couple of years. I think that's a good estimate. And she's by any means one of the rising or glowing superstars (00:37) of our field. She's won a number of awards-- the Glushko Dissertation Prize, the NSF Career Award. I think you won that. Real-time talk introduction. But none of that really is-- that's not the reason that we invited her. I think of Judy as one of the most creative researchers I know of any stage in any field, and I really mean that deeply. (01:09) She has a background coming out of neuroscience, and in that in many ways is it-- is very much at home talking to all the sorts of people who inhabit this building, who record signals from brains and try to make sense of them computationally. She's done a lot of that. She's worked with colleagues of ours whose work we know well like Dan Yamins was one of her mentors, and she has studied vision. (01:28) She's-- a lot of her background is in visual psychophysics and visual neuroscience and computational neuroscience. But if you look at her research, some of which you'll see today and a lot of which you won't even see today, she's gone in many other directions or let's just say one key direction, which is from basic-- some of the most basic processes of perception and the things that you can describe with nice, elegant computational models to aspects of cognition that really are what make us human, both biologically and also culturally. (02:02) And you're definitely going to see some of that here. And so that means she studied things like artistic expression or creative expression in visual and other med ia. She's very interested in narrative expression. She's really interested in education, learning, and teaching and how we make sense of the world symbolically and through data and explanation. (02:23) And she's-- so she's really moved towards these much more complex cognitive processes that are really distinctively human both biologically and culturally and increasingly really of great import in our current era. But she hasn't given up any of the rigor or I would say her taste for rigor. (02:44 ) And I know from a lot of interactions with Judy that what keeps her up at night is this is a struggle and the challenge of how do you get at these really important, hard things with the kind of rigor and precision that many of us grew up valuing and being inspired by in, for example, visual neuroscience and computational neuroscience. (03:04) And I can't say she's completely solved that problem because it might take a while, but it's a really great challenge. It's one that inspires me, the way she works on it, and I hope that it's one that we can all learn from and be inspired by and to see where she is and where she's going with this. So, Judy, please tell us. JUDY FAN: OK wow. [APPLAUSE] I wasn't totally prepared for that. That was incredibly kind, Josh. I really-- thank you and thank you all for being here. (03:31) It's-- I can't actually express how wonderful today has been so far. I have a lot of affection and respect for this department and community and the kind of values, sci entific and otherwise, embodied in the work that you all do here, and so it really is a treat to spend a few minutes telling you about some of the work that we've been doing. So we study cognitive tools. (03:57) What are those? Let's start with something as familiar and simple as the number line. I've been told not to move around as much because we're using this mic. I'm going to try to do that. Nature didn't give us the number line. We invented it. So as the Spanish architect Antoni Gaudí once put it, there are no straight lines or sharp corners in nature, but that didn't stop us. (04:24) We created them anyway, and we extended the number line, of course, a few hundred years ago to create rectangular coordinates, which turn out to be super useful. They were genuinely cutting edge tools for thought, for deriving new mathematical discoveries. When René Descartes and his contemporaries realized that you could link up algebraic expressions with geometric curves in order to solve all kinds 06:27) And I think the story begins at least 30,000 to 80,000 years ago when anatomically modern humans began to mark up their physical environments, essentially-- including these cave walls here, iconically repurposing objects and surfaces in their surroundings into carriers of meaning. We obviously didn't stop at cave walls. (06:55) The story of human learning and discovery is deeply intertwined with the story of technologies for making the invisible visible. So here are just a few examples fr t all of these examples share in common is they leverage what I've been calling visual abstraction to communicate what we see and know about the world in a format that highlights what is relevant to notice. (08:55) And then building on that, we leverage that expanding understanding of the natural world through the use of those tools for learning in order to create new things. So, for example, our detailed understanding of physical mechanics allowed us to design and then build high precision time lding on that tradition and with the goal of understanding how humans made all those remarkable discoveries and inventions that I shared with you just a minute ago, I'd like to argue that there's still two critical ingredients missing from this picture. First is an account of cognitive tools or technologies, material objects that encode information intended to have an impact on our minds, how and what we think. (11:00) Second, I would like to argue that the time has come to embrace science's nat alities, graphical elements, words, and numbers to engage in statistical reasoning. (12:45) In other words, to learn from finite amounts of evidence about aspects of the world that might be difficult or impossible to learn through direct observation by a single individual. And I'm still happy to chat with folks about our work on physical assembly and physical reasoning probably at the reception. (13:07) So to dive into part one, how do we begin to think about how people use visual abstraction to first view is that we essentially see drawings as meaningful and representing things because drawings simply resemble objects in the world. (15:04) Like this drawing literally looks like the bird and that's how we know. The second response is that drawings denote objects primarily as a matter of convention, and we only learn which drawings go with which objects in meanings from other people, so if you take this Chinese character, for example. So in an earlier line of work, my collaborators-- clo you could warp or rumple the sketch but not tear any holes in it. And the success of that approach-- I'm just demoing here. It's not really a result. It's more of a demo-- (17:12) the success of that approach suggests that fairly strong spatial constraints govern how the parts of sketches correspond to the parts of real objects that they're meant to represent. So that's great. We've got good enough trainable models of sketch understanding to build downstream applications that work pretty well. ( heir drawing to uniquely identify a particular exemplar (19:13) but then sparser drawings on the far trials when they could get away with these category level abstractions. So here are some examples of actual drawings that we collected in that study. And we found that sketchers used fewer strokes on far trials, less ink, less time to produce those drawings while still achieving sealing accuracy on the fundamental task of communicating the identity of the target visual concept to the viewer, who ticularly important way that we use visual abstraction, especially in science, is to transmit mechanistic knowledge about how things work. (21:28) So what is going on in people's minds when they make that move? Going beyond what is visually salient let's say about a specific bird to highlight underlying physical mechanisms, for example, how birds achieve flight in general. So you can imagine my excitement when Holly Huey, a wonderful former PhD student in the lab who's now at Adobe Research, was images actually help downstream viewers perform the task-- extract information that they really (23:25) needed whether it's about appearance or about mechanism. So rather than a lesson on bird flight, which is fascinating but complicated, Holly constructed six novel contraptions with a clearly observable mechanism for closing a circuit and turning on a light. (23:45) So here's an example of one of those machines and the instructional video that participants watched. Participants in the study ac rth category that was a catch all for symbols. So in this particular context, we're talking about arrows and motion lines (25:39) and then used those tags to compare what kind-- what balance of semantic information people emphasize in these two conditions. What she found was that while people drew causal and non-causal parts in both conditions, they allocated more strokes to the causal part and explanations than the non-causal ones. (26:03) They also emphasize the background a bit more in depict the cumulative hypothesis, what we should see is that explanations are at least as good as depictions for all tasks but under the dissociable hypothesis that they might be better for the action task but worse for the object task. And what Holly found was more consistent with the dissociable account where explanations better communicated how the mechanism worked. (28:06) But depictions were better for communicating object identity. Interestingly, explanations were not better in this sample for c investing considerable energy in evaluating how well any member of the steadily advancing cohort of machine learning systems might continue to be relevant and promising candidates for capturing more detailed patterns of human behavior in these high dimensional tasks, specifically as models of human image understanding as well as models of image creation. (30:11) So the task setting that we consider takes inspiration from this famous series of drawings by Pablo Picasso. Some of these are very de people had to create sketches cued by a photo. (32:16) These are photos taken from the THINGS data set, if you're familiar with that, in less and less time. So by the time we get to the four seconds, they're real, real sketchy. We then took those drawings and then showed them to both people and 17 different then state-of-the-art vision algorithms representing a broad array of different kind of architectural commitments and strategies and training protocols. Yes. TENENBAUM: Quick question of clar measured by the entropy of the label distribution. (34:16) And even when the guess is wrong, not the top one, it's more likely to at least be in the right semantic neighborhood estimated by language embeddings. So that's reassuring, but then we dug in a little bit deeper and found that while some models do honest to goodness perform better the recognition task in other models, the variation across models in terms of performance is totally dwarfed by the gap between models and people, the reliab n other words, if you take a-- if you take seriously a functional view of sketches as being for communicating concepts and characterize their meaning in terms of the full distribution of the labels and meanings that it evokes, then even though the 32 stroke CLIPasso drawings and the 32 second human sketches look different when you look at them-- stylistically they are different-- they are also quite functionally similar in terms of the set of meanings that they convey in the distribution of mean in the modern era was the invention of data visualization. Like the telescope and microscope, plots help to resolve parts of the world that you can't see directly. But unlike either of those optical technologies, it allows you to see patterns and phenomena that might be too large, too noisy, too slow to see with our own eyes. (39:02) They're ubiquitous in the news, the cornerstone of evidence-based decision making and business and government. And they're indispensable in every field of science ese kinds of images, discover, and communicate important quantitative insights will help us equip people with the kind of quantitative data literacy skills they need more generally. So I'm going to highlight briefly three directions that we're pursuing in this vein. (41:03) Our first question asks about the underlying operations that are needed to understand plots. So the strategy that we've been taking is to obtain machine learning systems that can handle questions about data visualizations at when a model or a person got a question wrong to see if they're getting things wrong in similar ways. What did we find? (43:19) Here I'm going to show you for each of the six tests we included, they have funny names like GGR, VLAT, CALVI, HOLF, HOLF-multi-- actually we made those-- the bad name there is my fault-- and also Chart-QA, a subset from Chart QA. We recorded how well-- we computed how well each of the models-- so these are the ones that are showing up on the xticks in blue, orange, pu en though GPT 4 V might look to be approaching human level performance, none of these models, GPT 4 V included, generated human-like error patterns. So this is shown by all the dots here falling well below the green shaded area which represents the human noise ceiling. So the upshot is that while currently developing, VLMs remain exciting and promising testbeds for developing and parameterizing the hypothesis space of possible cognitive models of visualization understanding, there still are thes on. Hold on. That might be a-- that might be a typo on my part. I don't think the question inherited that. AUDIENCE: [INAUDIBLE] Anyways, don't worry about it. JUDY FAN: I'm not-- I'm-- I'm-- I'm starting to, but I'm going to resist that urge right now. No, no I think that-- yeah. So-- so-- AUDIENCE: But these-- a lot if this is the standard that they're full of all sorts of typos. JUDY FAN: This is a templated-- there's a templated thing. (48:01) I think there are-- basically a lot of these qu ions overall but not really care about what type of graph they were sharing. (49:42) Maybe they might prefer ones that show more of the data, maybe ones that hide less of the variation in the data. The best candidate we found that we considered was the proposal that people are maybe actually sensitive to the features of those plots that were relevant for answering the question and, in fact, actually predicted the performance of about 1,700 other participants who tried answering every one of thos the ones that we have today, which is why we use them in our benchmark study. (51:56) Our question in this last study in work that's actually now in press and led by this extraordinary postdoc in our lab, Erik Brockbank, also with Arnav Verma, we're asking what are these tests actually measuring, and are they measuring the skills in the best possible way? And can we do better? So here are some initial steps towards answering those questions. (52:24) To get some traction, we started with these t made it challenging. (54:11) We also dug into the patterns of mistakes that people made and found that the best way to predict those patterns on these two tests wasn't the kind of plot or even the type of question. Maybe find the max or identify clusters or characterize distribution or retrieve value. These are all common ways of describing the ontology of tasks involving plots, but it really seemed from this analysis that other underlying factors that aren't well described by the ontology are at explain how people use the suite of cognitive technologies that we've inherited and continue to innovate on. We want to understand why that toolkit looks the way it does, what future cognitive tools might work even better. In the long run, I think that understanding how these tools work and how to make them better really matters because it's like these tools that are at the heart of two of our most impactful and generative activities. (56:58) First, education, which is the institution and may ound pools which are usually painted blue on the inside and so on. And that could depend. So I'm just wondering how you thought about some of those cases? JUDY FAN: Yeah. Yeah. There's a large literature in philosophy in the area of aesthetics that I take inspiration from that begins from a similar premise, which is how is it possible that we understand pictures that are false like pictures of fictional individuals or unicorns or glasses with blue water even if it doesn't look that way. The tech alization, I know what people will understand it to be if they understand it correctly, but I don't know-- I might have a lot of difficulty imagining how it would be misunderstood. (1:00:52) And so that actually seems like a task which was literally how else might this be misunderstood. I maybe understood would be it's very, very valuable thing, and I want to ask what's-- what is our state-of-the-art model of that and how graphs are misunderstood. Usually they're misunderstood. And is it an inte ugh the different steps and whatever the student did. So one way in which I think-- maybe I will just very, very briefly, if it's OK, speak to how we've been thinking about this question in the modern era of extremely large machine learning systems is to interrogate the kind of operations and conceptual primitives so to speak that these systems rely on when they get an answer right or wrong, using the suite of tools that (1:03:15) go under the banner of mechanistic interpretability. But you coul h to pay attention to. JUDY FAN: I did do that. AUDIENCE: And one of the reasons why you might have trouble answering this question-- I'm just trying to see if I understand-- JUDY FAN: Yeah. AUDIENCE: Is that you might not know which part of the thing to pay attention to to answer the question. (1:05:07) JUDY FAN: Yeah. AUDIENCE: Or but-- or you might know what part-- but you might not know what to do with it how to take that red rectangle and relate it to the information on the y-axis. Or you m between two data points on the number line. For example, but they're like all these different routes to it because this is like-- this-- the point is that this is complicated, and so decomposing it is part of the challenge. (1:06:57) AUDIENCE: [INAUDIBLE] --if there could be like-- JUDY FAN: Yeah. Yeah. AUDIENCE: [INAUDIBLE] how you teach these skills. JUDY FAN: Yeah. AUDIENCE: Break them down into-- JUDY FAN: Exactly. Yeah. That's right. That's right. Yeah, right. So there's assessment and then . Right. AUDIENCE: So I wonder what do you think about the question of how these kinds of representations should be structured so that they're easy for kids to learn. JUDY FAN: Yeah. Oh. AUDIENCE: You start out with none of these representations. What would you put into the earliest ones that you want kids to learn about? How would you progress from there? JUDY FAN: Yeah. That's a good question. (1:08:47) Yes. And actually there are versions-- I feel like there's a few minutes ago. Nancy and I w cesses that are co-opted in order to identify the appropriate sub-region of this image to look at. You might imagine designing those initial-- those initial graphs to cohere more with those kinds of scenes. (1:10:41) And then there's the step of mapping the components of these scenes to concepts that you also need to learn about and that can be really hard initially and then become faster and faster and easier and easier over time. And I think it's really fascinating what is"

## ChatGPT (2025-07-12T16:35:01.619552+00:00)

{"content_type": "code", "language": "unknown", "response_format_name": null, "text": "search()"}

## ChatGPT (2025-07-12T16:35:11.865139+00:00)

{"content_type": "thoughts", "thoughts": [], "source_analysis_msg_id": "184fab00-a437-4a0f-b29c-b83af1cd7e01"}

## ChatGPT (2025-07-12T16:35:11.479742+00:00)

{"content_type": "code", "language": "unknown", "response_format_name": null, "text": "{\"search_query\":[{\"q\":\"Glasp Prof Judy Fan Cognitive Tools making the invisible visible\"},{\"q\":\"site:glasp.co Judy Fan cognitive tools invisible visible\"}]}"}

## ChatGPT (2025-07-12T16:35:16.118478+00:00)

{"content_type": "reasoning_recap", "content": "Thought for a few seconds"}

## ChatGPT (2025-07-12T16:35:14.869436+00:00)

Here’s a clear and concise summary of Prof. Judy Fan’s talk, with key timestamps for reference:

- **00:37** – Introduction by Josh Tenenbaum highlighting Judy’s rigorous and creative research background in visual neuroscience and cognitive science.  
- **03:57** – Definition of **cognitive tools**: man‑made artifacts (like number lines, coordinate systems) that help shape, enhance, and communicate abstract thinking.  
- **06:27** – Historical framing: from cave paintings to Cartesian coordinates—humans have invented tools to make the invisible world visible and actionable.  
- **15:04** – Two mechanisms by which drawings communicate:  
  1. Visual resemblance—they look like the real thing.  
  2. Established conventions—symbols whose meaning we learn socially.  
- **17:12** – Sketch-recognition models reveal that spatial coherence (not just shape) matters: people and models interpret sketches by mapping parts to objects.  
- **19:13** – In a study, sketchers drew fewer details when conveying generalized categories, showing how abstraction supports communication efficiency.  
- **21:28** – Distinguished between **depictive drawings** (what an object looks like) and **explanatory drawings** (how it works); explanatory ones emphasize function over fidelity.  
- **23:45** – Experimental evidence: When participants drew machines, they spent more effort on causal mechanisms (arrows, functional parts) than decorative details.  
- **30:11** – Picasso’s bulls as a cognitive test: humans can recognize highly abstract sketches, but AI models still lag behind in this level of visual abstraction.  
- **39:02** – Visualization as a modern cognitive tool: far beyond optics, it reveals patterns too large, slow, or noisy for direct perception—vital for decision‑making.  
- **41:03** – Lab’s benchmark: comparing humans vs. AI (e.g., GPT‑4V) on chart‑understanding. While AI now rivals accuracy, it fails to mimic *human-like misunderstandings*, revealing gaps in context-aware reasoning.  
- **54:11** – Errors in plot interpretation aren’t driven by graph type or task alone, but by deeper cognitive operations (e.g., identifying what to focus on)—highlighting the complexity of visualization literacy.

---

**Insightful takeaways**  
- Visual abstraction isn’t a flaw—it’s a feature: strategic omission and symbolic highlighting convey meaning more clearly.  
- Cognitive tools like drawing and data visualization extend our ability to abstract, generalize, and reason beyond raw perception.  
- Although AI approaches human performance in some visualization tasks, current systems lack the nuanced, context-sensitive error patterns of humans—a critical area for future improvement.

---

*No supplementary insights from Glasp were found that directly add new value beyond these points.*

Learn more on Glasp: https://glasp.co/reader?url=https://www.youtube.com/watch?v=AF3XJT9YKpM&t=236s

## You (2025-07-12T16:36:48.954000+00:00)

ok now instead of trying to summarize, try to synthesize the informaition tht was given to you. Find meaning, regardless of takeaway.

## ChatGPT (2025-07-12T16:36:49.751963+00:00)

Here's a synthesized interpretation of Judy Fan's talk, integrating its deeper meaning beyond the details:

---

At its core, Judy Fan's lecture explores how human cognition thrives through tools of abstraction—techniques we invent to clarify the invisible and grasp the intangible. Human thought is inherently symbolic; we do not merely reflect the world as it is, but continually invent and refine conceptual lenses, from ancient cave markings to modern data visualizations, that mediate our experience of reality.

Fan highlights drawing as a profound case of visual abstraction: sketches aren’t just simplified pictures—they encode meaning through deliberate omission and symbolic emphasis. The significance lies not in their accuracy, but in their strategic use of visual cues to convey ideas, causal relationships, or categorical concepts. This act of abstraction makes communication efficient, transcending literal depiction to convey complex ideas quickly and effectively.

By comparing human and AI abilities in interpreting sketches and visualizations, Fan reveals a crucial insight: what separates human cognition from machines isn’t mere accuracy, but the nuanced sensitivity humans have to context, abstraction, and intentional meaning. AI struggles precisely because understanding isn’t just decoding patterns; it’s grasping intention, context, and subtle inference—abilities deeply tied to human culture, conventions, and shared knowledge.

This synthesis implies a broader narrative: the story of human progress is the story of inventing cognitive tools that continually reshape our understanding and enhance our thinking. Yet, as powerful as these tools are, their full potential—and their limitations—are most clearly seen when tested against the emerging cognitive systems we create in machines. Fan invites us to think deeply about these limitations and opportunities, asking not only how we understand images and graphs, but why we understand them differently than any algorithm yet devised.

Ultimately, Judy Fan's talk isn't simply about cognitive tools themselves; it's a reflection on what it means to think like a human—an ongoing dialogue between perception, creativity, convention, and culture, woven together through shared tools of thought.

## You (2025-07-13T08:31:15.004931+00:00)

OK but are there any actionable insights from this? Any approach to diagraming, anything to keep in mind, etc etc...

