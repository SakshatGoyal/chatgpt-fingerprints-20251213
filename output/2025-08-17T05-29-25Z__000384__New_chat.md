# New chat

## You (2025-08-17T05:29:25.382000+00:00)

You are a **Lead Research Methodologist & Synthesis Director** with the sensibilities of a seasoned IDEO research leader.
**Your task is to EXECUTE Stage 1 (Approach to Gathering Data)** for a multi-phase research program on **context engineering**—not to redesign the plan. The plan is provided below as source-of-truth.
Produce complete, ambiguity-free artifacts that Stage 2 (**Deep Research**) will consume directly. All outputs must be internally consistent, and machine-readable where specified.

---

## SOURCE-OF-TRUTH PLAN (USE AS GIVEN; DO NOT ALTER)

**1.1 Purpose & Payoff**

* **Purpose:** Build an interdisciplinary, LLM-era map of “context engineering”—what it is, what adjacent communities call it, how it works, and when/why it works—then translate that into actionable design patterns and evaluation playbooks.
* **Payoff:** A shared vocabulary, an evidence-backed framework, and field-tested guidance for practitioners (product, research, data, and design).

**1.2 Core Research Questions (RQs)**

* **Concept & Language**

  * **RQ1:** How is “context” defined and operationalized across AI/ML, IR, HCI, cognitive/behavioral science, and data ethics (LLM era)?
  * **RQ2:** What terminological variants map to “context engineering” (e.g., RAG, in-context learning, system prompting, memory, long-context optimization, attention steering, tool use, instruction following, guardrails)?
* **Mechanisms & Efficacy**

  * **RQ3:** Which context levers (framing, injection, structuring, weighting, boundaries) measurably improve performance, faithfulness, safety, and UX? Under what conditions?
  * **RQ4:** How do these levers interact (synergies/trade-offs) and how sensitive are outcomes to model family, temperature, context length, retrieval quality, or domain?
* **Evaluation & Causality**

  * **RQ5:** What metrics, experimental designs, and evaluation harnesses can causally attribute gains to context choices (vs. confounds like model size or leakage)?
* **Practice & Adoption**

  * **RQ6:** How are labs (OpenAI, Anthropic, Databricks, IBM, others) and startups applying these levers? Which patterns generalize by domain (health, legal, code, support, productivity, data analysis)?
* **Governance & Risk**

  * **RQ7:** What are the security, privacy, IP, and safety implications of different context strategies (e.g., prompt injection, PII leakage, copyright)?
  * **RQ8:** What guidelines and guardrails best mitigate these risks without crushing utility?

**1.3 Lever Model (Deductive Scaffolding)**

* **Primary:** Framing; Injection (RAG/memory/tool outputs/structured KBs); Structuring (schemas/templates/workflows/planners); Weighting (ordering/repetition/salience/reranking); Boundaries (constraints/scopes/policies).
* **Secondary:** Compression & Distillation; Temporal Freshness; Multimodal Context; Security & Integrity; Persistence; Governance & Auditability.
* Allow **inductive emergence** of new categories.

**1.4 Construct Operationalization**

* **Independent variables:** presence/absence; dosage (# retrieved chunks); position (top/bottom); format (table/prose); explicit priority statements; compression ratio; recency cutoff.
* **Dependent variables:** task success; groundedness/faithfulness; factual precision/recall; robustness to adversarial content; user effort/time; satisfaction; token/cost efficiency.
* **Covariates/controls:** model family/version; temperature; max tokens; domain difficulty; retrieval recall/precision; dataset familiarity.

**1.5 Study Design (mixed methods)**
Systematic literature review (peer-reviewed + arXiv + reputable industry whitepapers); practitioner studies (interviews, surveys, artifact teardowns); experiments (factorial/A–B on context levers); case studies (12–18 startups); comparative analyses (labs vs academic).

**1.6 Target Populations**
Academia (AI/ML, IR, HCI, cognition/behavior, data ethics 2020+); industry labs (OpenAI, Anthropic, Databricks, IBM + 4–6 leaders); startups (RAG/tooling, vertical apps, agentic frameworks, safety vendors); practitioners (ML eng, AI designers, PMs, data scientists, security/privacy).

**1.7 Sampling Methods**
Systematic search; backward/forward snowballing; stratified purposeful sampling (by domain/lever); theoretical sampling (expand where novelty appears); diversity targets (cross-domain/org).

**1.8 Ethics & Governance**
Respect IP/TOS; consent for interviews; NDAs honored; anonymize practitioner data; secure storage; pre-register experimental protocols when feasible; document risks (prompt injection, PII, copyright).

---

## WHAT TO PRODUCE (RETURN FORMAT — STRICT)

Return **exactly four code blocks**, in the order below, with the exact headers. Populate fully—no “TBD” or placeholders. Where examples are needed, use clearly marked **synthetic** examples (`"example": true`).

### 1) `===FILE: STAGE1_README.md===`

A **human-readable master plan for execution**, derived from the Source-of-Truth, containing:

* **Executive Summary** (purpose, payoff, scope).
* **RQs** (verbatim from plan), mapped to **operational questions** and **intended evidence types** (e.g., lit findings, practitioner claims, product artifacts).
* **Lever Taxonomy & Secondary Levers** with concise operational definitions and examples/non-examples.
* **Constructs & Variables** (independent, dependent, controls) with measurement notes.
* **Method Overview & Roles** (what Stage 2 will collect; how interviews/surveys/teardowns will be triggered).
* **Inclusion/Exclusion Criteria** and **Credibility Tiers (1–4)** with evidence-weighting guidance.
* **Sampling Strategy** (systematic + snowball + stratified + theoretical), including **diversity quotas**.
* **Screening & Coding Workflow** (PRISMA-style steps; dual screening; ≥20% double-coding; κ target and reconciliation).
* **Quality Gates** (coverage, credibility mix, schema validity, export integrity).
* **Ethics & Governance** (from plan), with concrete do/don’t lists.
* **Assumptions & Limitations** (enumerated).
* **Versioning & Traceability** (semver, dates, change log).
* **Discovery Hooks** (≤12 bullets of high-leverage exploratory questions to pursue in Stage 2).

### 2) `===FILE: STAGE1_DATA_SPEC.json===`

A **machine-readable data specification** for Stage 2 ingestion & output, containing:

* **`source_record_schema`** (JSON Schema draft-07) defining and constraining fields:
  `id`, `title`, `year`, `venue_or_publisher`, `org_name`, `org_type` (enum), `url`, `access_date`,
  `domains` (multi-enum), `lever_tags` (multi-enum: primary+secondary+emergent slots), `terminology`,
  `methods`, `datasets_or_tasks`, `metrics`, `claims_primary`, `claims_limitations`,
  `evidence_strength` (enum + rationale), `credibility_tier` (1–4), `task_domain`,
  `retrieval_or_memory_strategy`, `risk_factors`, `governance_signals`,
  `artifact_type` (paper/blog/whitepaper/doc/demo), `notes`, `tags_freeform`.
* **`screening_rubric`** with deterministic rules: **auto-include**, **auto-exclude**, **human-review**, rule precedence, and examples.
* **`coding_codebook`**: definitions, decision rules, examples/non-examples for every lever, secondary lever, risk, governance, method, and metric; include **`emergent_*`** tag policy.
* **`credibility_rules`**: mapping of venues/org types to tiers and tie-breakers.
* **`export_formats`**: JSONL & CSV field order; required null handling; UTF-8 and newline policies.
* **`intercoder_reliability_plan`**: sample size, κ target, adjudication steps, audit trail fields.
* **`filename_conventions`** and ID patterns.
* **`examples`**: **two fully populated synthetic records** that validate against the schema (`"example": true`).

### 3) `===FILE: STAGE1_SEARCH_PLAN.yaml===`

A **ready-to-run search & sampling plan** (no browsing now), including:

* **Time Window:** 2020-01-01 to present.
* **Venues & Sources:** prioritized lists for academic (NeurIPS/ICML/ICLR/ACL/EMNLP/CHI/TOIS/IR journals), labs (OpenAI/Anthropic/Databricks/IBM Research + 4–6 leaders), startups (RAG/tooling + verticals), standards/policy (e.g., NIST/ISO when relevant).
* **Boolean Query Sets** per discipline and lever with synonyms/negations; each query annotated with **intent**, **target RQs**, and **expected yield**.
* **Term Crosswalk:** mapping “context engineering” to adjacent terms (RAG, in-context learning, long-context optimization, instruction hierarchy, prompt orchestration, memory, tool use, attention steering, grounding, guardrails, provenance).
* **Sampling Quotas:** minimum N per venue/org type and per lever; per-org caps; refresh cadence.
* **Snowballing Protocol:** backward/forward steps; stop criteria.
* **Grey-Literature Filters:** tiering and exclusion of opinion-only posts.
* **De-duplication Rules:** DOI/URL/title-fuzzy/semantic-near-dup checks.
* **Risk & Ethics Checks:** paywalls/TOS compliance; PII/secret handling; access-date logging.

### 4) `===FILE: STAGE1_INSTRUMENTS_AND_TEMPLATES.md===`

A **library of execution templates** aligned to the schema & rubric:

* **PRISMA Flow Template** (stages/decisions).
* **Screening Form** mirroring the rubric (pass/hold/fail with reasons).
* **Coding Sheet** mirroring `source_record_schema`.
* **Interview Guide (Semi-Structured)** with consent & anonymization toggles; topics: lever usage, evaluation practices, failure modes, governance, decision criteria.
* **Survey Item Bank** (Likert + free-text) on lever usage/efficacy; role/demographics.
* **Case-Study Dossier Template** (problem, levers, evaluation, UX/ops, risks, generalizability).
* **Risk Register Template** (confounds, selection bias, Goodhart’s law, model drift, IP/privacy, prompt injection) with mitigations.
* **Quality Gates Checklist** (coverage, credibility mix, schema validity, κ achieved, export integrity).
* **Assumption Log** (assumption, rationale, impact, test plan).
* **Future Experiment Skeletons** (for later phases; do not run): factorial/A–B shells tied to lever manipulations.

---

## GUARDRAILS & STYLE

* **No web browsing.** No citations.
* **No plan redesign.** Use the Source-of-Truth as fixed constraints.
* **Maximize downstream utility:** explicit enums, field types, rule precedence, examples, and export specs.
* **Leave room for discovery:** support **`emergent_*`** tags and open-coding notes; include “Discovery Hooks.”
* **Internal Consistency Pass:** before returning, validate that all templates, fields, enums, and rules align across files; schema validates example records; no dangling fields.
* **Return exactly the four code blocks** in the order specified—no extra commentary.

---

## SUCCESS CRITERIA (AUTO-CHECK BEFORE RETURN)

* All four files present, headers match exactly.
* JSON Schema is valid and examples conform.
* Rubric rules are deterministic and cover edge cases (auto-include/auto-exclude/human-review).
* Queries are specific, multi-variant, and mapped to RQs and levers.
* Sampling quotas and credibility tiers are explicit.
* κ target and adjudication steps included.
* Ethics, risks, and governance are concrete and actionable.
* Cross-file synchronization (fields/enums/templates) passes internal check.

---

**Begin now. Output only the four files as specified.**

## ChatGPT (2025-08-17T05:29:30.230471+00:00)

```markdown
===FILE: STAGE1_README.md===
# Stage 1 — Approach to Gathering Data (Master Plan)

## Executive Summary
**Purpose.** Build an interdisciplinary, LLM-era map of “context engineering”—what it is, what adjacent communities call it, how it works, and when/why it works—then translate that into actionable design patterns and evaluation playbooks.

**Payoff.** A shared vocabulary, an evidence-backed framework, and field-tested guidance for practitioners (product, research, data, and design).

**Scope.** 2020–present sources spanning AI/ML, Information Retrieval (IR), HCI, cognitive/behavioral science, data ethics, security/privacy, and industry practice. Evidence types include peer‑reviewed papers, preprints, reputable lab reports/whitepapers, open demos/code, practitioner interviews/surveys, startup case studies, and comparative analyses (labs vs. academic). Stage 1 produces specifications, screening rules, sampling plans, and instruments that Stage 2 consumes directly.

---

## Research Questions (verbatim) → Operational Questions → Intended Evidence
**RQ1.** *How is “context” defined and operationalized across AI/ML, IR, HCI, cognitive/behavioral science, and data ethics (LLM era)?*  
• Operational: Extract formal and informal definitions; identify unit(s) of context (tokens, documents, schemas, tools, memory entries); note operational proxies (e.g., retrieved chunk, system prompt).  
• Evidence: Literature definitions; method sections; evaluation harness descriptions; architecture diagrams; interview claims from academics/practitioners.

**RQ2.** *What terminological variants map to “context engineering” (e.g., RAG, in-context learning, system prompting, memory, long-context optimization, attention steering, tool use, instruction following, guardrails)?*  
• Operational: Build a term crosswalk; record co-occurrence with tasks, models, levers; capture synonyms/antonyms and boundary terms.  
• Evidence: Keywords, taxonomies in papers, lab docs, repos; industry blog terminology; interview/survey vocab.

**RQ3.** *Which context levers (framing, injection, structuring, weighting, boundaries) measurably improve performance, faithfulness, safety, and UX? Under what conditions?*  
• Operational: Identify manipulations and dosage parameters; capture reported effect sizes and confidence; note dataset/task, model, temperature, context length.  
• Evidence: Ablations, A/B tests, controlled experiments, red-teaming, user studies; start‑up case dossiers.

**RQ4.** *How do these levers interact (synergies/trade‑offs) and how sensitive are outcomes to model family, temperature, context length, retrieval quality, or domain?*  
• Operational: Record factorial designs; interactions; sensitivity analyses; error taxonomies; robustness under adversarial content.  
• Evidence: Factorial/blocked studies; multi-model comparisons; robustness and adversarial evaluations; practitioner postmortems.

**RQ5.** *What metrics, experimental designs, and evaluation harnesses can causally attribute gains to context choices (vs. confounds like model size or leakage)?*  
• Operational: Catalog metrics and causal designs; tag leakage controls, blinding, preregistration; identify counterfactual setups and negative controls.  
• Evidence: Methods and appendix details; eval code; prereg and IRB notes; interview descriptions of eval practice.

**RQ6.** *How are labs (OpenAI, Anthropic, Databricks, IBM, others) and startups applying these levers? Which patterns generalize by domain (health, legal, code, support, productivity, data analysis)?*  
• Operational: Extract deployment patterns, guardrails, and operational workflows; map to domains; identify reusable templates.  
• Evidence: Lab/industry whitepapers, product docs, demos, talks; case‑study artifacts; practitioner interviews/surveys.

**RQ7.** *What are the security, privacy, IP, and safety implications of different context strategies (e.g., prompt injection, PII leakage, copyright)?*  
• Operational: Enumerate threat models, risk factors, and mitigations; capture incident reports and red‑team outcomes.  
• Evidence: Security analyses, audits, red-team writeups; policy/standards guidance; legal analyses.

**RQ8.** *What guidelines and guardrails best mitigate these risks without crushing utility?*  
• Operational: Identify governance signals (audits, policy alignment, data governance); record utility–safety trade‑offs and best‑practice recipes.  
• Evidence: Governance frameworks, compliance checklists, lab policies; measurable utility/safety deltas; expert recommendations.

---

## Lever Taxonomy (Primary & Secondary) — Operational Definitions with Examples/Non‑Examples
**Primary Levers**
1. **Framing** — Intent-setting language (system prompts, role, tone) that conditions model behavior without adding external facts.  
   • *Example:* “You are a careful tax analyst…” + instructions clarifying citation style.  
   • *Non‑Example:* Adding retrieved IRS documents (that’s Injection).
2. **Injection (RAG/Memory/Tools/KBs)** — Supplying external information (retrieved chunks, stored memory, tool outputs, structured KBs).  
   • *Example:* Top‑k hybrid retrieval feeding a summarizer.  
   • *Non‑Example:* Reordering already‑present context tokens (that’s Weighting).
3. **Structuring (Schemas/Templates/Workflows/Planners)** — Constraining input/output format and orchestration.  
   • *Example:* JSON schema for output + multi‑step planner calling tools.  
   • *Non‑Example:* Merely increasing context length with no format constraints.
4. **Weighting (Ordering/Repetition/Salience/Reranking)** — Changing token/document prominence (order, duplication, salience markers, scores).  
   • *Example:* Reranking retrieved chunks by cross‑encoder score; repeating critical constraints.  
   • *Non‑Example:* Filtering low‑quality documents out entirely (that’s Selection, under Injection).
5. **Boundaries (Constraints/Scopes/Policies)** — Explicit limits, policy bindings, scopes, and refusal criteria applied via prompt or guard system.  
   • *Example:* Policy‑bound refusal lists; tool‑scope whitelists.  
   • *Non‑Example:* Security scanners running **after** generation (post‑hoc moderation only).

**Secondary Levers**
- **Compression & Distillation** — Summarization, map‑reduce, and elision strategies that compress context while preserving utility.  
- **Temporal Freshness** — Recency cutoffs, re‑crawl cadence, time‑aware retrieval, temporal decay.  
- **Multimodal Context** — Non‑text context (images, audio, tables, diagrams) normalized into model‑usable form.  
- **Security & Integrity** — Prompt‑injection defenses, content signing, provenance chains, sandboxing.  
- **Persistence** — Long‑lived memory stores, session continuity, recall policies.  
- **Governance & Auditability** — Logging, consent, access controls, audit trails, policy alignment.

> **Emergent categories** are permitted (*emergent_* tags) when a repeated, coherent mechanism appears that is not covered above.

---

## Constructs & Variables (with Measurement Notes)
**Independent Variables (manipulations)**  
• Presence/absence of each lever; dosage (e.g., # retrieved chunks k; # repetitions r); position (top/bottom/segmented); format (table/prose/JSON); explicit priority statements; compression ratio; recency cutoff.  
• *Measurement:* Encode as structured parameters; log seed, temperature, max tokens; store retrieval stats (precision/recall, MRR).

**Dependent Variables (outcomes)**  
• Task success; groundedness/faithfulness; factual precision/recall; robustness to adversarial content; user effort/time; satisfaction; token/cost efficiency.  
• *Measurement:* Standard metrics (e.g., EM/F1/precision/recall), groundedness/faithfulness scores, adversarial success rate, SUS/UMUX‑Lite for UX, latency, $/1K tokens.

**Covariates/Controls**  
• Model family/version; temperature; max tokens; domain difficulty; retrieval recall/precision; dataset familiarity.  
• *Measurement:* Record exact model identifiers; document dataset/source overlap checks and leakage controls.

---

## Method Overview & Roles (What Stage 2 Will Collect)
- **Systematic Literature Review:** Harvest, screen, code according to the Stage 1 schema/rubric.  
- **Practitioner Studies:** Semi‑structured interviews and targeted surveys; artifact teardowns (prompts, configs, dashboards).  
- **Experiments:** Factorial/A–B manipulations of levers on representative tasks; causal attribution harnesses.  
- **Case Studies (12–18 startups):** End‑to‑end dossiers.  
- **Comparative Analyses:** Lab vs. academic practice patterns.

**Triggers:**  
• Launch interviews after initial taxonomy saturation (≥60 coded sources).  
• Launch surveys after term crosswalk stabilizes (κ≥0.75 on terminology codes).  
• Launch experiments when at least two strong candidates per lever are identified from lit+practice.

---

## Inclusion/Exclusion Criteria & Credibility Tiers
**Inclusion**  
- Date ≥ 2020‑01‑01; pertains to LLMs or transformer context control.  
- Contains at least one of: lever description, evaluation, method detail, or artifact (prompt/config/code).  
- For grey literature: must include methods and observable evidence (data, code, demo).

**Exclusion**  
- Pure opinion/marketing without methods/evidence.  
- Non‑LLM or non‑context topics (e.g., generic model scaling without context implications).  
- Duplicates/superseded versions (keep latest with strongest evidence).

**Credibility Tiers (1–4)**  
1. **Tier‑1:** Peer‑reviewed top venues; preregistered or audited lab studies with open code/data.  
2. **Tier‑2:** Reputable lab/industry reports with methods + partial openness; major standards bodies.  
3. **Tier‑3:** Detailed practitioner write‑ups/demos with measurements but limited rigor.  
4. **Tier‑4:** Opinion pieces, marketing pages; minimal or no methods.

**Evidence Weighting Guidance**  
- Prefer Tier‑1/2 for causal claims; allow Tier‑3 for hypothesis generation; Tier‑4 only as context/terminology signals. Maintain a mixed‑tier portfolio per lever (see Sampling).

---

## Sampling Strategy (Systematic + Snowball + Stratified + Theoretical)
- **Systematic Search:** Time window 2020‑present; prioritized venues/sources per Stage 1 Search Plan.  
- **Backward/Forward Snowballing:** From anchor works; stop when three consecutive iterations yield <10% new inclusions.  
- **Stratified Purposeful Sampling:** By *lever*, *domain*, *org type*, *credibility tier*.  
- **Theoretical Sampling:** Expand in directions showing novelty (e.g., new defense pattern against injection).  
- **Diversity Quotas (minimums for Stage 2 corpus):**  
  - Per primary lever: ≥40 unique sources each.  
  - Per secondary lever: ≥20 unique sources each.  
  - Domains: ≥10 per major domain (healthcare, legal, code, support, productivity, data analysis).  
  - Org type: ≥30 academic; ≥30 industry labs; ≥30 startups; ≥10 standards/policy.  
  - Per‑org cap: ≤20 items from any single org to reduce dominance.

---

## Screening & Coding Workflow (PRISMA‑style)
1. **Identification:** Collect records from search feeds; de‑dup (DOI/URL/title‑fuzzy/semantic).  
2. **Title/Abstract Screen:** Two reviewers independently; decisions: Pass/Hold/Fail.  
3. **Full‑Text Review:** Extract artifacts; verify lever relevance; record methods/metrics.  
4. **Coding:** Apply schema; ≥20% double‑coded; compute Cohen’s κ per major code family (target κ≥0.75).  
5. **Adjudication:** Resolve disagreements; log rationale and final codes.  
6. **Synthesis Staging:** Validate exports (JSONL/CSV); update dashboards.

---

## Quality Gates
- **Coverage:** Meets diversity quotas and lever minimums.  
- **Credibility Mix:** ≥60% Tier‑1/2 overall; ≥40% Tier‑1/2 per lever.  
- **Schema Validity:** 100% of coded records validate against Stage 1 JSON Schema.  
- **Intercoder Reliability:** κ≥0.75 on *lever_tags*, *methods*, *metrics*, *risk_factors*.  
- **Export Integrity:** JSONL/CSV field orders and null handling per spec; reproducible checksums.  
- **Traceability:** Every claim linked to record IDs and passages/artifacts.

---

## Ethics & Governance (Concrete Do/Don’t)
**Do**  
- Respect IP/TOS; cite sources; store only what’s permitted.  
- Obtain informed consent for interviews; honor NDAs; anonymize practitioner data.  
- Secure storage; role‑based access; redact PII; log access dates and retrieval paths.  
- Preregister experimental protocols when feasible; record leakage checks and risk mitigations.

**Don’t**  
- Don’t scrape behind paywalls or bypass access controls.  
- Don’t store secrets/credentials in datasets or prompts.  
- Don’t share identifiable practitioner quotes without written consent.  
- Don’t publish evaluation artifacts that could enable misuse without appropriate safeguards.

---

## Assumptions & Limitations
- Public artifacts sufficiently represent core practices; some private configs may remain unavailable.  
- Reported metrics can be noisy across labs; we will normalize where possible but avoid over‑aggregation.  
- Model versions/weights evolve rapidly; we will timestamp configurations and access dates.  
- Some domains (e.g., health/legal) impose stronger governance; sampling may skew toward public exemplars.

---

## Versioning & Traceability
- **Semantic Versioning:** `MAJOR.MINOR.PATCH` (e.g., 1.0.0 for Stage 1 release).  
- **Change Log:** Each update lists schema/rubric/search changes and migration notes.  
- **Timestamps:** All records include `access_date`; exports stamped with generation datetime and commit hash.

---

## Discovery Hooks (for Stage 2 exploration; ≤12)
1. Where do compression ratios start to harm groundedness per domain?  
2. Which boundary patterns measurably reduce jailbreak success without lowering task success?  
3. How does retrieval precision vs. recall trade off under strict token budgets?  
4. Do planner‑based structures outperform flat prompts at equal token count?  
5. Are instruction hierarchies more brittle at higher temperatures?  
6. Which recency strategies (decay vs. pinning) best serve news‑sensitive tasks?  
7. Can salience weighting substitute for increased k (dosage) in RAG?  
8. What interaction effects appear between tool use and boundaries?  
9. Which governance signals predict fewer incidents in production?  
10. How does domain difficulty moderate lever efficacy?  
11. What failure modes cluster with long‑context optimization?  
12. Which evaluation harnesses most reliably detect leakage and contamination?

```

```json
===FILE: STAGE1_DATA_SPEC.json===
{
  "source_record_schema": {
    "$schema": "http://json-schema.org/draft-07/schema#",
    "title": "Context Engineering Source Record",
    "type": "object",
    "additionalProperties": false,
    "required": [
      "id",
      "title",
      "year",
      "venue_or_publisher",
      "org_name",
      "org_type",
      "url",
      "access_date",
      "domains",
      "lever_tags",
      "terminology",
      "methods",
      "datasets_or_tasks",
      "metrics",
      "claims_primary",
      "claims_limitations",
      "evidence_strength",
      "credibility_tier",
      "task_domain",
      "retrieval_or_memory_strategy",
      "risk_factors",
      "governance_signals",
      "artifact_type",
      "notes",
      "tags_freeform"
    ],
    "properties": {
      "id": {
        "type": "string",
        "pattern": "^CTX-[0-9]{4}-[A-Z0-9]{6}$",
        "description": "Stable record ID (e.g., CTX-2025-AB12CD)."
      },
      "title": { "type": "string", "minLength": 3 },
      "year": { "type": "integer", "minimum": 2000, "maximum": 2100 },
      "venue_or_publisher": { "type": "string", "minLength": 2 },
      "org_name": { "type": "string", "minLength": 2 },
      "org_type": {
        "type": "string",
        "enum": [
          "academic_lab",
          "industry_lab",
          "startup",
          "standards_body",
          "government",
          "nonprofit",
          "community_project",
          "media",
          "independent_researcher"
        ]
      },
      "url": { "type": "string", "format": "uri" },
      "access_date": { "type": "string", "format": "date" },
      "domains": {
        "type": "array",
        "minItems": 1,
        "uniqueItems": true,
        "items": {
          "type": "string",
          "enum": [
            "ai_ml",
            "information_retrieval",
            "hci",
            "cognitive_science",
            "behavioral_science",
            "data_ethics",
            "security_privacy",
            "software_engineering",
            "nlp",
            "vision",
            "multimodal",
            "legal",
            "healthcare",
            "code",
            "customer_support",
            "productivity",
            "data_analysis",
            "finance",
            "education",
            "policy_governance"
          ]
        }
      },
      "lever_tags": {
        "type": "array",
        "minItems": 1,
        "uniqueItems": true,
        "items": {
          "type": "string",
          "anyOf": [
            { "const": "framing" },
            { "const": "injection" },
            { "const": "structuring" },
            { "const": "weighting" },
            { "const": "boundaries" },
            { "const": "compression_distillation" },
            { "const": "temporal_freshness" },
            { "const": "multimodal_context" },
            { "const": "security_integrity" },
            { "const": "persistence" },
            { "const": "governance_auditability" },
            { "pattern": "^emergent_[a-z0-9_]+$" }
          ]
        },
        "allOf": [
          {
            "contains": {
              "anyOf": [
                { "const": "framing" },
                { "const": "injection" },
                { "const": "structuring" },
                { "const": "weighting" },
                { "const": "boundaries" }
              ]
            }
          }
        ]
      },
      "terminology": {
        "type": "array",
        "items": { "type": "string", "minLength": 2 },
        "minItems": 1,
        "uniqueItems": true
      },
      "methods": {
        "type": "array",
        "minItems": 1,
        "uniqueItems": true,
        "items": {
          "type": "string",
          "anyOf": [
            { "const": "theoretical" },
            { "const": "controlled_experiment" },
            { "const": "ablation_study" },
            { "const": "observational_study" },
            { "const": "case_study" },
            { "const": "user_study" },
            { "const": "survey" },
            { "const": "interview" },
            { "const": "benchmark_evaluation" },
            { "const": "simulation" },
            { "const": "system_description" },
            { "const": "red_team" },
            { "const": "security_analysis" },
            { "const": "audit" },
            { "pattern": "^emergent_method_[a-z0-9_]+$" }
          ]
        }
      },
      "datasets_or_tasks": {
        "type": "array",
        "items": { "type": "string", "minLength": 2 },
        "minItems": 0,
        "uniqueItems": true
      },
      "metrics": {
        "type": "array",
        "minItems": 1,
        "uniqueItems": true,
        "items": {
          "type": "string",
          "anyOf": [
            { "const": "accuracy" },
            { "const": "precision" },
            { "const": "recall" },
            { "const": "f1" },
            { "const": "exact_match" },
            { "const": "rouge" },
            { "const": "bleu" },
            { "const": "bertscore" },
            { "const": "faithfulness" },
            { "const": "groundedness" },
            { "const": "helpfulness" },
            { "const": "toxicity" },
            { "const": "harmlessness" },
            { "const": "satisfaction" },
            { "const": "latency" },
            { "const": "cost_tokens" },
            { "const": "throughput" },
            { "const": "robustness" },
            { "const": "adversarial_success_rate" },
            { "const": "calibration" },
            { "const": "win_rate" },
            { "pattern": "^metric_[a-z0-9_]+$" }
          ]
        }
      },
      "claims_primary": {
        "type": "array",
        "minItems": 1,
        "items": { "type": "string", "minLength": 3 }
      },
      "claims_limitations": {
        "type": "array",
        "minItems": 0,
        "items": { "type": "string", "minLength": 3 }
      },
      "evidence_strength": {
        "type": "object",
        "additionalProperties": false,
        "required": ["level", "rationale"],
        "properties": {
          "level": {
            "type": "string",
            "enum": [
              "causal_strong",
              "causal_moderate",
              "associational",
              "anecdotal",
              "speculative"
            ]
          },
          "rationale": { "type": "string", "minLength": 5 }
        },
        "description": "Enum + rationale describing causal strength."
      },
      "credibility_tier": {
        "type": "integer",
        "enum": [1, 2, 3, 4]
      },
      "task_domain": {
        "type": "string",
        "enum": [
          "healthcare",
          "legal",
          "code",
          "customer_support",
          "productivity",
          "data_analysis",
          "education",
          "finance",
          "security",
          "policy",
          "general",
          "science",
          "software_dev"
        ]
      },
      "retrieval_or_memory_strategy": {
        "type": "array",
        "uniqueItems": true,
        "minItems": 0,
        "items": {
          "type": "string",
          "anyOf": [
            { "const": "bm25" },
            { "const": "vector" },
            { "const": "hybrid" },
            { "const": "memory_key_value" },
            { "const": "tool_augmented" },
            { "const": "structured_kb" },
            { "const": "graph" },
            { "const": "none" },
            { "const": "long_context" },
            { "const": "sliding_window" },
            { "const": "summarization_memory" },
            { "const": "episodic_memory" },
            { "const": "semantic_routing" },
            { "const": "rerankers" },
            { "pattern": "^other_[a-z0-9_]+$" }
          ]
        }
      },
      "risk_factors": {
        "type": "array",
        "uniqueItems": true,
        "minItems": 0,
        "items": {
          "type": "string",
          "anyOf": [
            { "const": "prompt_injection" },
            { "const": "test_traces_leakage" },
            { "const": "pii_exposure" },
            { "const": "ip_copyright" },
            { "const": "jailbreak_vuln" },
            { "const": "data_poisoning" },
            { "const": "privacy_attack" },
            { "const": "security_misconfiguration" },
            { "const": "bias_fairness" },
            { "const": "safety" },
            { "const": "overreliance" },
            { "const": "hallucination" },
            { "const": "misuse" },
            { "const": "model_inversion" },
            { "const": "membership_inference" },
            { "const": "model_drift" },
            { "const": "goodharts_law" },
            { "const": "eval_leakage" },
            { "pattern": "^emergent_risk_[a-z0-9_]+$" }
          ]
        }
      },
      "governance_signals": {
        "type": "array",
        "uniqueItems": true,
        "minItems": 0,
        "items": {
          "type": "string",
          "anyOf": [
            { "const": "open_source_repo" },
            { "const": "released_dataset" },
            { "const": "eval_code_open" },
            { "const": "irb_approved" },
            { "const": "preregistered" },
            { "const": "third_party_audit" },
            { "const": "red_team" },
            { "const": "policy_alignment" },
            { "const": "data_governance" },
            { "const": "security_assessment" },
            { "const": "usage_analytics" },
            { "const": "pseudonymized" },
            { "const": "pii_minimization" },
            { "const": "consent_obtained" },
            { "const": "nda" },
            { "const": "none" },
            { "pattern": "^emergent_gov_[a-z0-9_]+$" }
          ]
        }
      },
      "artifact_type": {
        "type": "string",
        "enum": [
          "paper",
          "blog",
          "whitepaper",
          "documentation",
          "demo",
          "slide",
          "video",
          "dataset",
          "github_readme",
          "report"
        ]
      },
      "notes": { "type": "string" },
      "tags_freeform": {
        "type": "array",
        "minItems": 0,
        "uniqueItems": true,
        "items": { "type": "string", "minLength": 2 }
      }
    }
  },

  "screening_rubric": {
    "rule_precedence": ["auto_exclude", "auto_include", "human_review"],
    "auto_exclude": [
      {
        "name": "DateTooOld",
        "logic": "year < 2020",
        "explanation": "Outside time window."
      },
      {
        "name": "NonContextTopic",
        "logic": "title/abstract lacks any of {context, prompt, retrieval, RAG, memory, in-context, long-context, instruction, guardrail, tool use, weighting, rerank}",
        "explanation": "Not about context engineering."
      },
      {
        "name": "OpinionOnly",
        "logic": "artifact_type in {blog, slide, video} AND methods == [] AND metrics == []",
        "explanation": "No methods or measurements."
      }
    ],
    "auto_include": [
      {
        "name": "TopVenueWithAblation",
        "logic": "venue_or_publisher in {NeurIPS, ICML, ICLR, ACL, EMNLP, CHI, TOIS, KDD, NAACL, WWW, SIGIR} AND methods contains ablation_study",
        "explanation": "High‑credibility with lever manipulation."
      },
      {
        "name": "ReputableLabWithEval",
        "logic": "org_type == industry_lab AND artifact_type in {whitepaper, report, paper} AND (methods contains benchmark_evaluation OR controlled_experiment)",
        "explanation": "Industry report with evaluation."
      }
    ],
    "human_review": [
      {
        "name": "GreyLitWithEvidence",
        "logic": "artifact_type in {blog, documentation, demo, github_readme} AND (metrics != [] OR methods intersects {case_study, user_study, survey, red_team})",
        "explanation": "Grey literature that may contain valuable evidence."
      },
      {
        "name": "AmbiguousTerminology",
        "logic": "terminology includes adjacent terms only (e.g., 'prompting' or 'guardrails') without explicit context link",
        "explanation": "Requires content inspection."
      }
    ],
    "examples": [
      {
        "example": true,
        "title": "Company blog: 'Why LLMs Will Change Everything'",
        "artifact_type": "blog",
        "methods": [],
        "metrics": [],
        "decision": "auto_exclude",
        "rule": "OpinionOnly"
      },
      {
        "example": true,
        "title": "ICLR paper on hybrid RAG with ablations",
        "artifact_type": "paper",
        "venue_or_publisher": "ICLR",
        "methods": ["ablation_study", "benchmark_evaluation"],
        "decision": "auto_include",
        "rule": "TopVenueWithAblation"
      },
      {
        "example": true,
        "title": "Startup demo with measured latency, cost, groundedness",
        "artifact_type": "demo",
        "methods": ["benchmark_evaluation", "case_study"],
        "metrics": ["latency", "cost_tokens", "groundedness"],
        "decision": "human_review",
        "rule": "GreyLitWithEvidence"
      }
    ]
  },

  "coding_codebook": {
    "levers_primary": [
      {
        "code": "framing",
        "definition": "Intent-setting language shaping model behavior; no new external facts.",
        "decision_rules": [
          "Label when system prompt or role instructions change without adding sources.",
          "Do NOT label if external documents/tools added."
        ],
        "examples": ["Role priming", "Style/tone constraints"],
        "non_examples": ["Retrieving a PDF", "Reranking snippets"]
      },
      {
        "code": "injection",
        "definition": "Supplying external information (retrieval, memory, tools, KBs).",
        "decision_rules": ["Include RAG, tool outputs, structured KBs.", "Exclude pure ordering changes."],
        "examples": ["BM25 + vector hybrid", "Function/tool call result appended"],
        "non_examples": ["Repeating constraints", "JSON schema without new facts"]
      },
      {
        "code": "structuring",
        "definition": "Schemas/templates/workflows constraining I/O; planning/orchestration.",
        "decision_rules": ["JSON schema, XML, planner, multi-step tool flows."],
        "examples": ["Planner chooses tools", "Typed JSON outputs"],
        "non_examples": ["Just longer context", "Only reranking"]
      },
      {
        "code": "weighting",
        "definition": "Order, duplication, salience markers, or reranking modifying prominence.",
        "decision_rules": ["Include cross-encoder rerank, duplication, priority tokens."],
        "examples": ["Repeat high-priority constraints", "Sort by score"],
        "non_examples": ["Filtering out docs entirely", "Adding new data"]
      },
      {
        "code": "boundaries",
        "definition": "Constraints/scopes/policies that restrict behavior or access.",
        "decision_rules": ["Include refusal rules, policy prompts, tool whitelists."],
        "examples": ["Refusal list", "Tool scope limitation"],
        "non_examples": ["Post-hoc moderation only"]
      }
    ],
    "levers_secondary": [
      {
        "code": "compression_distillation",
        "definition": "Summarization/elision preserving utility under token budgets."
      },
      { "code": "temporal_freshness", "definition": "Recency controls and time-aware retrieval." },
      { "code": "multimodal_context", "definition": "Images/audio/tables/diagrams as context." },
      { "code": "security_integrity", "definition": "Defenses/provenance/signing/sandboxing." },
      { "code": "persistence", "definition": "Long-lived memory and recall policies." },
      { "code": "governance_auditability", "definition": "Logging, access controls, policy compliance." }
    ],
    "risks": [
      { "code": "prompt_injection", "definition": "Adversarial content causes rule override or data exfil." },
      { "code": "test_traces_leakage", "definition": "Evaluation contamination via seen examples." },
      { "code": "pii_exposure", "definition": "Personal data exposure through context/memory." },
      { "code": "ip_copyright", "definition": "Copyrighted text/images injected without rights." },
      { "code": "jailbreak_vuln", "definition": "Evasion of boundaries via crafted prompts." },
      { "code": "data_poisoning", "definition": "Malicious data in sources corrupts behavior." },
      { "code": "privacy_attack", "definition": "Membership/model inversion, deanonymization." },
      { "code": "security_misconfiguration", "definition": "Access controls or tool scope errors." },
      { "code": "bias_fairness", "definition": "Context skews outputs against groups." },
      { "code": "safety", "definition": "Harmful content generation risks." },
      { "code": "overreliance", "definition": "Users over-trust outputs due to framing." },
      { "code": "hallucination", "definition": "Unsupported claims despite context." },
      { "code": "misuse", "definition": "Dual-use escalation via context." },
      { "code": "model_inversion", "definition": "Sensitive training data extraction." },
      { "code": "membership_inference", "definition": "Presence inference of data points." },
      { "code": "model_drift", "definition": "Behavior changes over time affect context efficacy." },
      { "code": "goodharts_law", "definition": "Metric gaming under optimization pressure." },
      { "code": "eval_leakage", "definition": "Hidden overlap between eval set and context." }
    ],
    "governance": [
      { "code": "open_source_repo", "definition": "Public code repository for methods/evals." },
      { "code": "released_dataset", "definition": "Public dataset for replication." },
      { "code": "eval_code_open", "definition": "Evaluation harness released." },
      { "code": "irb_approved", "definition": "Ethics oversight approval." },
      { "code": "preregistered", "definition": "Study preregistration exists." },
      { "code": "third_party_audit", "definition": "Independent audit conducted." },
      { "code": "red_team", "definition": "Documented red-team process." },
      { "code": "policy_alignment", "definition": "Internal/external policy mapping." },
      { "code": "data_governance", "definition": "Lineage, retention, access controls documented." },
      { "code": "security_assessment", "definition": "Threat model and mitigations documented." },
      { "code": "usage_analytics", "definition": "Telemetry for safety/utility tracking." },
      { "code": "pseudonymized", "definition": "Identifiers removed or tokenized." },
      { "code": "pii_minimization", "definition": "Minimal PII policy implemented." },
      { "code": "consent_obtained", "definition": "Explicit user/participant consent." },
      { "code": "nda", "definition": "NDA governs data sharing." },
      { "code": "none", "definition": "No governance signals present." }
    ],
    "methods": [
      { "code": "theoretical", "definition": "Proofs or conceptual analysis." },
      { "code": "controlled_experiment", "definition": "Randomized or blocked manipulations." },
      { "code": "ablation_study", "definition": "Systematic component removal." },
      { "code": "observational_study", "definition": "Non-interventional observation." },
      { "code": "case_study", "definition": "Single setting, deep dive." },
      { "code": "user_study", "definition": "Human participants with UX measures." },
      { "code": "survey", "definition": "Questionnaire-based evidence." },
      { "code": "interview", "definition": "Qualitative expert/practitioner interviews." },
      { "code": "benchmark_evaluation", "definition": "Standard tasks/benchmarks comparison." },
      { "code": "simulation", "definition": "Synthetic environments or data." },
      { "code": "system_description", "definition": "Architecture/engineering description." },
      { "code": "red_team", "definition": "Adversarial probing." },
      { "code": "security_analysis", "definition": "Threat modeling/penetration analysis." },
      { "code": "audit", "definition": "Compliance/standards audit." }
    ],
    "metrics": [
      { "code": "accuracy", "definition": "Overall correctness." },
      { "code": "precision", "definition": "Positive predictive value." },
      { "code": "recall", "definition": "Sensitivity/coverage." },
      { "code": "f1", "definition": "Harmonic mean of precision/recall." },
      { "code": "exact_match", "definition": "Strict match to reference." },
      { "code": "rouge", "definition": "Summary overlap metrics." },
      { "code": "bleu", "definition": "Machine translation overlap." },
      { "code": "bertscore", "definition": "Semantic similarity." },
      { "code": "faithfulness", "definition": "Grounding to provided context." },
      { "code": "groundedness", "definition": "Citation/traceability to sources." },
      { "code": "helpfulness", "definition": "Human preference or rating." },
      { "code": "toxicity", "definition": "Toxic content rate." },
      { "code": "harmlessness", "definition": "Avoidance of harmful outputs." },
      { "code": "satisfaction", "definition": "User-reported satisfaction." },
      { "code": "latency", "definition": "Time to result." },
      { "code": "cost_tokens", "definition": "Token usage / cost." },
      { "code": "throughput", "definition": "Tasks per unit time." },
      { "code": "robustness", "definition": "Performance under perturbations." },
      { "code": "adversarial_success_rate", "definition": "Attacker success frequency." },
      { "code": "calibration", "definition": "Confidence alignment." },
      { "code": "win_rate", "definition": "Pairwise preference wins vs baseline." }
    ],
    "emergent_tag_policy": {
      "prefixes": ["emergent_", "emergent_method_", "emergent_risk_", "emergent_gov_"],
      "promotion_rule": "Tags used in ≥5 distinct records with consistent definition become candidates for formalization in next schema minor release."
    }
  },

  "credibility_rules": {
    "mapping": {
      "venues": {
        "tier_1": ["NeurIPS", "ICML", "ICLR", "ACL", "EMNLP", "NAACL", "CHI", "TOIS", "SIGIR", "KDD", "WWW"],
        "tier_2": ["TACL", "JAIR", "Transactions on ML", "JMLR", "AAAI", "IJCAI", "Standards_Body"],
        "notes": "Venue mapping interacts with org_type and artifact_type."
      },
      "org_types": {
        "academic_lab": 1,
        "industry_lab": 2,
        "startup": 3,
        "standards_body": 2,
        "government": 2,
        "nonprofit": 2,
        "community_project": 3,
        "media": 4,
        "independent_researcher": 3
      }
    },
    "tie_breakers": [
      "Prefer items with open eval code/data.",
      "Prefer newer versions with stronger methods (ablation > anecdote).",
      "If duplicate venue and org_type, prefer richer artifacts (demo+paper > paper only)."
    ]
  },

  "export_formats": {
    "jsonl": {
      "field_order": [
        "id",
        "title",
        "year",
        "venue_or_publisher",
        "org_name",
        "org_type",
        "url",
        "access_date",
        "domains",
        "lever_tags",
        "terminology",
        "methods",
        "datasets_or_tasks",
        "metrics",
        "claims_primary",
        "claims_limitations",
        "evidence_strength",
        "credibility_tier",
        "task_domain",
        "retrieval_or_memory_strategy",
        "risk_factors",
        "governance_signals",
        "artifact_type",
        "notes",
        "tags_freeform"
      ],
      "null_handling": "Omit absent optional arrays; use [] for empty lists; use null only for optional scalar fields not present.",
      "encoding": "UTF-8",
      "newline": "\\n",
      "bom": false
    },
    "csv": {
      "columns": [
        "id",
        "title",
        "year",
        "venue_or_publisher",
        "org_name",
        "org_type",
        "url",
        "access_date",
        "domains|json",
        "lever_tags|json",
        "terminology|json",
        "methods|json",
        "datasets_or_tasks|json",
        "metrics|json",
        "claims_primary|json",
        "claims_limitations|json",
        "evidence_strength.level",
        "evidence_strength.rationale",
        "credibility_tier",
        "task_domain",
        "retrieval_or_memory_strategy|json",
        "risk_factors|json",
        "governance_signals|json",
        "artifact_type",
        "notes",
        "tags_freeform|json"
      ],
      "array_serialization": "JSON inside cell",
      "encoding": "UTF-8",
      "newline": "\\n",
      "quote_char": "\"",
      "escape": "double"
    }
  },

  "intercoder_reliability_plan": {
    "sample_size_rule": "Max(50 records, 20% of eligible corpus) for double-coding per milestone.",
    "kappa_target": 0.75,
    "units": ["lever_tags", "methods", "metrics", "risk_factors", "credibility_tier"],
    "adjudication_steps": [
      "Compute κ per unit; if κ < 0.75, run discrepancy workshop.",
      "Update codebook with clarifications/examples.",
      "Re-code a fresh 10% sample to confirm κ recovery.",
      "Log adjudication decisions with timestamps and coder IDs."
    ],
    "audit_trail_fields": [
      "record_id",
      "coder_id",
      "timestamp",
      "field",
      "initial_code",
      "final_code",
      "adjudication_note"
    ]
  },

  "filename_conventions": {
    "project_slug": "context-engineering",
    "id_pattern": "^CTX-[0-9]{4}-[A-Z0-9]{6}$",
    "ingest_dir": "data/raw/",
    "processed_dir": "data/processed/",
    "exports": {
      "jsonl": "exports/context-engineering_records_v{version}.jsonl",
      "csv": "exports/context-engineering_records_v{version}.csv"
    },
    "snapshots": "snapshots/{yyyymmdd}/",
    "logs": "logs/{yyyymmdd}/stage2_ingest.log",
    "checksum": "exports/context-engineering_records_v{version}.sha256"
  },

  "examples": [
    {
      "example": true,
      "id": "CTX-2024-AB12CD",
      "title": "Hybrid RAG with Salience Weighting Improves Grounded QA",
      "year": 2024,
      "venue_or_publisher": "ICLR",
      "org_name": "Example University NLP Lab",
      "org_type": "academic_lab",
      "url": "https://example.org/iclr24-hybrid-rag.pdf",
      "access_date": "2025-08-10",
      "domains": ["ai_ml", "information_retrieval", "nlp"],
      "lever_tags": [
        "injection",
        "structuring",
        "weighting",
        "compression_distillation",
        "governance_auditability",
        "emergent_attention_curation"
      ],
      "terminology": ["RAG", "salience weighting", "in-context learning"],
      "methods": ["ablation_study", "controlled_experiment", "benchmark_evaluation"],
      "datasets_or_tasks": ["HotpotQA", "MultiDocQA"],
      "metrics": ["exact_match", "faithfulness", "latency", "cost_tokens"],
      "claims_primary": [
        "Hybrid retrieval with cross-encoder reranking yields +5.2 EM over BM25-only.",
        "Repeating constraints twice increases groundedness without cost blowup."
      ],
      "claims_limitations": [
        "Evaluated on two English QA datasets only.",
        "Single model family; generalization unknown."
      ],
      "evidence_strength": {
        "level": "causal_moderate",
        "rationale": "Randomized ablations with fixed seeds; leakage checks reported; no preregistration."
      },
      "credibility_tier": 1,
      "task_domain": "customer_support",
      "retrieval_or_memory_strategy": ["hybrid", "rerankers", "summarization_memory"],
      "risk_factors": ["prompt_injection", "eval_leakage"],
      "governance_signals": ["eval_code_open", "data_governance"],
      "artifact_type": "paper",
      "notes": "Strong methodological clarity; reusable prompt templates included.",
      "tags_freeform": ["few-shot", "long-context", "cross-encoder"]
    },
    {
      "example": true,
      "id": "CTX-2025-ZX9QWE",
      "title": "Policy-Bounded Tool Use with Temporal Refresh for Compliance",
      "year": 2025,
      "venue_or_publisher": "Anthropic Engineering Report",
      "org_name": "Anthropic",
      "org_type": "industry_lab",
      "url": "https://labs.example.com/policy-bounded-tools-report",
      "access_date": "2025-08-12",
      "domains": ["ai_ml", "security_privacy", "policy_governance"],
      "lever_tags": [
        "boundaries",
        "structuring",
        "temporal_freshness",
        "security_integrity",
        "persistence"
      ],
      "terminology": ["guardrails", "policy-bounded prompting", "tool use"],
      "methods": ["system_description", "benchmark_evaluation", "red_team"],
      "datasets_or_tasks": ["ComplianceQA", "ChangeLogMonitor"],
      "metrics": ["win_rate", "toxicity", "adversarial_success_rate", "cost_tokens"],
      "claims_primary": [
        "Policy-bound tool scopes reduce adversarial success rate by 42%.",
        "Daily refresh of regulatory corpus maintains performance within 1% of monthly retrains."
      ],
      "claims_limitations": [
        "Proprietary benchmark; limited public replication.",
        "Focuses on finance/legal compliance domains."
      ],
      "evidence_strength": {
        "level": "associational",
        "rationale": "Before/after and red-team comparisons; no randomized controls; partial openness."
      },
      "credibility_tier": 2,
      "task_domain": "legal",
      "retrieval_or_memory_strategy": ["structured_kb", "semantic_routing", "long_context"],
      "risk_factors": ["jailbreak_vuln", "ip_copyright", "model_drift"],
      "governance_signals": ["third_party_audit", "security_assessment", "policy_alignment"],
      "artifact_type": "report",
      "notes": "Detailed tool permission model; includes refusal policy templates.",
      "tags_freeform": ["policy", "refresh", "guardrails"]
    }
  ]
}
```

```yaml
===FILE: STAGE1_SEARCH_PLAN.yaml===
time_window: "2020-01-01 to present"

venues_and_sources:
  academic_priority:
    - NeurIPS
    - ICML
    - ICLR
    - ACL
    - EMNLP
    - NAACL
    - CHI
    - TOIS
    - SIGIR
    - KDD
    - WWW
    - TACL
    - JMLR
    - JAIR
  labs_priority:
    - OpenAI
    - Anthropic
    - Databricks
    - IBM Research
    - Google DeepMind
    - Microsoft Research
    - Meta FAIR
    - Cohere
    - NVIDIA
    - Hugging Face
  startups_priority:
    - LangChain
    - LlamaIndex
    - Pinecone
    - Weaviate
    - Elastic
    - Vectara
    - Cohere Platform (startup tooling)
    - Humanloop
    - Contextual AI
    - Kindo
    - Glean
    - Perplexity
  standards_policy_priority:
    - NIST
    - ISO/IEC
    - IEEE
    - ENISA
    - CISA
    - OECD AI
    - UK ICO
    - EU AI Office

boolean_query_sets:
  # Each item is an executable Boolean string for search engines or database fields.
  - discipline: AI/ML
    lever: Framing
    intent: "Find prompt/system framing manipulations with measured effects."
    target_rqs: [RQ3, RQ5]
    expected_yield: high
    query: >
      ("system prompt" OR "instruction hierarchy" OR "role prompting" OR "prompt framing")
      AND (ablation OR randomized OR "A/B" OR "user study" OR benchmark)
      AND (LLM OR "large language model" OR transformer)
      NOT ("vision-only")
  - discipline: AI/ML
    lever: Injection
    intent: "Retrieve RAG/memory/tool outputs that inject external info."
    target_rqs: [RQ2, RQ3, RQ4, RQ5]
    expected_yield: very_high
    query: >
      (RAG OR "retrieval augmented" OR "retrieval-augmented" OR memory OR "tool use" OR "tool calling" OR "structured KB"
      OR "knowledge base")
      AND (rerank* OR hybrid OR "cross-encoder" OR "dense retriev*" OR "BM25" OR "graph retriev*")
      AND (ablation OR eval OR benchmark OR "user study")
  - discipline: AI/ML
    lever: Structuring
    intent: "Schemas/templates/workflows/planners shaping I/O."
    target_rqs: [RQ3, RQ4, RQ5]
    expected_yield: high
    query: >
      (schema OR "JSON schema" OR template OR planner OR "plan-and-solve" OR "workflow" OR "orchestrator" OR "agent framework")
      AND (evaluation OR ablation OR "controlled experiment" OR benchmark)
      AND (LLM OR "tool use")
  - discipline: AI/ML
    lever: Weighting
    intent: "Ordering/repetition/salience/reranking and effects."
    target_rqs: [RQ3, RQ4, RQ5]
    expected_yield: medium
    query: >
      (weighting OR "token order" OR "context order" OR repetition OR salience OR "priority tokens" OR rerank* OR "document order")
      AND (ablation OR "controlled" OR "A/B" OR "randomized")
      AND (RAG OR "in-context")
  - discipline: AI/ML
    lever: Boundaries
    intent: "Constraints/scopes/policies; guardrails; refusal strategies."
    target_rqs: [RQ3, RQ5, RQ7, RQ8]
    expected_yield: high
    query: >
      (guardrail* OR "policy prompting" OR "refusal" OR "tool scope" OR "bounded tool use" OR "policy-bounded")
      AND (evaluation OR "red team" OR "audit" OR benchmark)
      AND (LLM OR agent)
  - discipline: IR
    lever: Injection+Weighting
    intent: "Retrieval quality, hybrid, reranking; sensitivity to k and order."
    target_rqs: [RQ3, RQ4, RQ5]
    expected_yield: high
    query: >
      (retrieval OR rerank* OR "dense retriev*" OR "hybrid retriev*" OR "cross-encoder")
      AND (LLM OR RAG OR "in-context")
      AND (eval OR ablation OR "error analysis")
  - discipline: HCI
    lever: Structuring+Boundaries
    intent: "UX outcomes for structured outputs and refusal policies."
    target_rqs: [RQ3, RQ5, RQ6, RQ8]
    expected_yield: medium
    query: >
      (interaction OR workflow OR "template" OR "schema" OR "consent" OR "policy notice")
      AND ("user study" OR survey OR diary)
      AND (LLM OR assistant)
  - discipline: Cognitive/Behavioral
    lever: Framing
    intent: "Effects of instructions/tone on human+model behavior."
    target_rqs: [RQ1, RQ3, RQ5]
    expected_yield: medium
    query: >
      ("instruction following" OR framing OR "priming" OR "role assignment")
      AND (experiment OR randomized OR preregistered)
      AND (language model OR human-in-the-loop)
  - discipline: Security/Privacy
    lever: Boundaries+Security
    intent: "Prompt-injection defenses, provenance, sandboxing."
    target_rqs: [RQ7, RQ8, RQ5]
    expected_yield: high
    query: >
      ("prompt injection" OR "data exfiltration" OR jailbreak OR provenance OR "content signing" OR sandbox*)
      AND (defense OR mitigation OR "red team" OR audit)
      AND (LLM OR agent OR RAG)
  - discipline: Data Ethics/Policy
    lever: Governance
    intent: "Guidelines/guardrails balancing utility and risk."
    target_rqs: [RQ7, RQ8]
    expected_yield: medium
    query: >
      (governance OR guideline* OR standard* OR "risk management" OR "AI policy")
      AND (LLM OR "retrieval augmented")
      AND (privacy OR copyright OR safety)

term_crosswalk:
  context_engineering:
    includes:
      - "retrieval-augmented generation"
      - "RAG"
      - "in-context learning"
      - "system prompting"
      - "instruction hierarchy"
      - "prompt orchestration"
      - "memory"
      - "long-context optimization"
      - "attention steering"
      - "tool use"
      - "grounding"
      - "guardrails"
      - "provenance"
    excludes:
      - "pretraining-only scaling laws"
      - "pure architecture changes with no context mechanism"
    notes: "Record exact term used and map to lever_tags in coding."

sampling_quotas:
  per_lever_minimums:
    framing: 40
    injection: 40
    structuring: 40
    weighting: 40
    boundaries: 40
  per_secondary_lever_minimums:
    compression_distillation: 20
    temporal_freshness: 20
    multimodal_context: 20
    security_integrity: 20
    persistence: 20
    governance_auditability: 20
  per_domain_minimums:
    healthcare: 10
    legal: 10
    code: 10
    customer_support: 10
    productivity: 10
    data_analysis: 10
  per_org_type_minimums:
    academic_lab: 30
    industry_lab: 30
    startup: 30
    standards_policy: 10
  per_org_cap: 20
  refresh_cadence:
    labs_and_startups: "weekly"
    academic: "monthly"
    standards_policy: "monthly or upon release"

snowballing_protocol:
  seed_selection: "Top-venue items per lever and high-impact lab reports."
  backward: "Mine references; include items passing screening."
  forward: "Use citation graphs and 'related work' links; include if passing screening."
  stop_criteria:
    - "Three consecutive iterations yield <10% new inclusions"
    - "Lever/domain quotas reached"
    - "Saturation indicated by repeated non-novel patterns"

grey_literature_filters:
  include_if:
    - "Methods or measurements present (e.g., ablation, benchmark, red-team, latency/cost)"
    - "Observable artifacts (prompts, configs, code, demo) are provided"
  exclude_if:
    - "Opinion-only or marketing without verifiable evidence"
    - "No linkable artifacts; inaccessible behind hard paywalls"
  tiering:
    tier_2: "Lab whitepapers/reports with methods"
    tier_3: "Detailed practitioner posts/demos with measurements"
    tier_4: "Opinion/announcement posts"

deduplication_rules:
  keys_precedence:
    - DOI
    - canonical_url
    - normalized_title
  title_fuzzy_match:
    algorithm: "token-based similarity"
    threshold: 0.90
  semantic_near_dup:
    guidance: "Flag if abstract similarity >0.92 or if identical figures/diagrams noted"
  supersession:
    prefer: "Newest version with strongest methods/artifacts"
    linkage: "Record supersedes/superseded-by in notes"

risk_and_ethics_checks:
  paywall_and_tos: "Do not bypass; use permitted access only."
  pii_and_secrets:
    - "Redact PII; do not store credentials/API keys in datasets or prompts."
    - "Anonymize interview data; store consent files separately."
  access_date_logging: "Record access_date for every URL; archive hashes where permitted."
  misuse_screen:
    - "Identify dual-use risks; apply boundaries before sharing artifacts."
  license_and_ip:
    - "Honor licenses; do not redistribute proprietary content."
```

```markdown
===FILE: STAGE1_INSTRUMENTS_AND_TEMPLATES.md===
# Stage 1 Instruments & Templates (Execution Library)

---

## PRISMA Flow Template (Stages & Decisions)
**Identification**  
- Records identified through database searches: ______  
- Additional records identified through other sources (labs/startups/standards): ______  
- Duplicates removed: ______

**Screening**  
- Records screened (title/abstract): ______  
- Records excluded (with reasons): ______

**Eligibility**  
- Full-text articles assessed: ______  
- Full-text articles excluded (with reasons): ______

**Inclusion**  
- Studies included in qualitative synthesis: ______  
- Studies included in quantitative synthesis (if applicable): ______

---

## Screening Form (Mirrors Rubric)
**Record ID:** CTX-YYYY-XXXXXX  
**Title:** __________________________  
**URL:** __________________________  
**Year:** ____   **Artifact Type:** (paper/blog/whitepaper/documentation/demo/slide/video/dataset/github_readme/report)  
**Org Type:** (academic_lab/industry_lab/startup/standards_body/government/nonprofit/community_project/media/independent_researcher)

**Decision:** ☐ Pass ☐ Hold ☐ Fail

**Auto‑Exclude Checks**  
- ☐ DateTooOld (year < 2020)  
- ☐ NonContextTopic (no context‑related terms)  
- ☐ OpinionOnly (no methods/metrics)

**Auto‑Include Checks**  
- ☐ TopVenueWithAblation (top venue + ablations)  
- ☐ ReputableLabWithEval (lab report + evaluation)

**Human‑Review Triggers**  
- ☐ GreyLitWithEvidence  
- ☐ AmbiguousTerminology

**Reason(s) & Notes:**  
____________________________________________________________________

---

## Coding Sheet (Mirrors `source_record_schema`)
**id:** CTX-YYYY-XXXXXX  
**title:** __________________________________  
**year:** ____  
**venue_or_publisher:** _____________________  
**org_name:** _______________________________  
**org_type:** academic_lab | industry_lab | startup | standards_body | government | nonprofit | community_project | media | independent_researcher  
**url:** ____________________________________  
**access_date (YYYY-MM-DD):** _____________

**domains (multi):**  
- ai_ml ☐  information_retrieval ☐  hci ☐  cognitive_science ☐  behavioral_science ☐  
- data_ethics ☐  security_privacy ☐  software_engineering ☐  nlp ☐  vision ☐  multimodal ☐  
- legal ☐  healthcare ☐  code ☐  customer_support ☐  productivity ☐  data_analysis ☐  
- finance ☐  education ☐  policy_governance ☐

**lever_tags (multi):**  
- Primary: framing ☐  injection ☐  structuring ☐  weighting ☐  boundaries ☐  
- Secondary: compression_distillation ☐  temporal_freshness ☐  multimodal_context ☐  security_integrity ☐  persistence ☐  governance_auditability ☐  
- Emergent: emergent_________________ , emergent_________________

**terminology (list):** ___________________________________________

**methods (multi):** theoretical ☐ controlled_experiment ☐ ablation_study ☐ observational_study ☐ case_study ☐ user_study ☐ survey ☐ interview ☐ benchmark_evaluation ☐ simulation ☐ system_description ☐ red_team ☐ security_analysis ☐ audit ☐ emergent_method_________

**datasets_or_tasks (list):** _____________________________________

**metrics (multi):** accuracy ☐ precision ☐ recall ☐ f1 ☐ exact_match ☐ rouge ☐ bleu ☐ bertscore ☐ faithfulness ☐ groundedness ☐ helpfulness ☐ toxicity ☐ harmlessness ☐ satisfaction ☐ latency ☐ cost_tokens ☐ throughput ☐ robustness ☐ adversarial_success_rate ☐ calibration ☐ win_rate ☐ metric_________

**claims_primary (bullets):**  
- _________________________________________________________________  
- _________________________________________________________________

**claims_limitations (bullets):**  
- _________________________________________________________________  
- _________________________________________________________________

**evidence_strength:** level → causal_strong | causal_moderate | associational | anecdotal | speculative  
**evidence_strength.rationale:** __________________________________

**credibility_tier (1–4):** __

**task_domain:** healthcare | legal | code | customer_support | productivity | data_analysis | education | finance | security | policy | general | science | software_dev

**retrieval_or_memory_strategy (multi):** bm25 ☐ vector ☐ hybrid ☐ memory_key_value ☐ tool_augmented ☐ structured_kb ☐ graph ☐ none ☐ long_context ☐ sliding_window ☐ summarization_memory ☐ episodic_memory ☐ semantic_routing ☐ rerankers ☐ other_________

**risk_factors (multi):** prompt_injection ☐ test_traces_leakage ☐ pii_exposure ☐ ip_copyright ☐ jailbreak_vuln ☐ data_poisoning ☐ privacy_attack ☐ security_misconfiguration ☐ bias_fairness ☐ safety ☐ overreliance ☐ hallucination ☐ misuse ☐ model_inversion ☐ membership_inference ☐ model_drift ☐ goodharts_law ☐ eval_leakage ☐ emergent_risk_________

**governance_signals (multi):** open_source_repo ☐ released_dataset ☐ eval_code_open ☐ irb_approved ☐ preregistered ☐ third_party_audit ☐ red_team ☐ policy_alignment ☐ data_governance ☐ security_assessment ☐ usage_analytics ☐ pseudonymized ☐ pii_minimization ☐ consent_obtained ☐ nda ☐ none ☐ emergent_gov_________

**artifact_type:** paper | blog | whitepaper | documentation | demo | slide | video | dataset | github_readme | report

**notes:** _________________________________________________________  
**tags_freeform (list):** __________________________________________

---

## Interview Guide (Semi‑Structured)
**Consent & Anonymization**  
- ☐ Verbal consent recorded  ☐ Written consent stored  ☐ Anonymize quotes  ☐ NDA in place (if applicable)

**Participant Profile (role, org, domain):** _______________________

**Topics & Prompts**
1. **Current Use of Context Levers**  
   - Walk me through how you prepare context for your top task(s).  
   - Which levers (framing, injection, structuring, weighting, boundaries) do you rely on? Why?
2. **Evaluation Practices**  
   - How do you know a context change helped? What metrics/harnesses do you use?  
   - Any controls for leakage or confounds?
3. **Failure Modes & Risks**  
   - Memorable failures (e.g., injection, hallucination, jailbreak)?  
   - What mitigations worked or failed?
4. **Governance & Operations**  
   - What governance signals (audits, logs, consent) do you maintain?  
   - Data access, retention, and redaction policies?
5. **Decision Criteria & Trade‑offs**  
   - How do you trade cost/latency vs. groundedness/quality?  
   - What breaks first under scale (more users, more docs)?
6. **Artifacts Review (Teardown)**  
   - Prompts/templates/schemas; retrieval configs; guardrail policies.  
   - Can we capture sanitized examples?

**Close**  
- If you could change one thing about your context pipeline, what would it be?  
- May we follow up and attribute anonymously?

---

## Survey Item Bank (Likert + Free‑Text)
**Demographics & Role**  
- Role: ML Eng ☐  Data Scientist ☐  AI Designer ☐  PM ☐  Security/Privacy ☐  Other: ______  
- Org Type: Academic ☐ Industry Lab ☐ Startup ☐ Other ______  
- Domain: Healthcare ☐ Legal ☐ Code ☐ Support ☐ Productivity ☐ Data Analysis ☐ Other ______

**Lever Usage (1=Never … 5=Always)**  
- I use **Framing** (system/role prompts) to guide outputs. 1 ☐ 2 ☐ 3 ☐ 4 ☐ 5 ☐  
- I use **Injection** (RAG/memory/tools) in production. 1 ☐ 2 ☐ 3 ☐ 4 ☐ 5 ☐  
- I use **Structuring** (schemas/templates/workflows). 1 ☐ 2 ☐ 3 ☐ 4 ☐ 5 ☐  
- I use **Weighting** (ordering/repetition/salience/reranking). 1 ☐ 2 ☐ 3 ☐ 4 ☐ 5 ☐  
- I use **Boundaries** (policies/refusals/tool scopes). 1 ☐ 2 ☐ 3 ☐ 4 ☐ 5 ☐

**Efficacy (Δ vs. baseline, 1=Much worse … 5=Much better)**  
- Framing → task success: 1 ☐ 2 ☐ 3 ☐ 4 ☐ 5 ☐  
- Injection → groundedness/faithfulness: 1 ☐ 2 ☐ 3 ☐ 4 ☐ 5 ☐  
- Structuring → user effort/time: 1 ☐ 2 ☐ 3 ☐ 4 ☐ 5 ☐  
- Weighting → robustness: 1 ☐ 2 ☐ 3 ☐ 4 ☐ 5 ☐  
- Boundaries → safety without utility loss: 1 ☐ 2 ☐ 3 ☐ 4 ☐ 5 ☐

**Evaluation & Risk**  
- We run **ablations** for context changes. 1 ☐ 2 ☐ 3 ☐ 4 ☐ 5 ☐  
- We check **leakage/contamination** in evaluations. 1 ☐ 2 ☐ 3 ☐ 4 ☐ 5 ☐  
- We log **governance signals** (audits, consent, access). 1 ☐ 2 ☐ 3 ☐ 4 ☐ 5 ☐

**Free‑Text**  
- Most effective context pattern you’ve used: __________________________  
- Largest failure mode and how you fixed it: __________________________  
- One artifact you can share (sanitized): _____________________________

---

## Case‑Study Dossier Template
**Case ID:** CS‑____  
**Company/Org (anonymized if needed):** __________  
**Domain:** healthcare | legal | code | support | productivity | data_analysis | other  
**Problem Statement:** ____________________________________________  
**Model(s) & Settings (family/version/temperature/max tokens):** _____  
**Levers Used (with parameters):**  
- Framing: __________________________________  
- Injection: __________________________________  
- Structuring: ________________________________  
- Weighting: __________________________________  
- Boundaries: _________________________________  
**Secondary Levers:** compression_distillation ☐ temporal_freshness ☐ multimodal_context ☐ security_integrity ☐ persistence ☐ governance_auditability ☐  
**Evaluation Harness & Metrics:** _________________________________  
**Results (with deltas & CIs if available):** _______________________  
**UX/Ops (latency, cost, reliability):** ___________________________  
**Risks & Mitigations:** __________________________________________  
**Governance Signals Present:** ____________________________________  
**Generalizability Notes:** _______________________________________  
**Artifacts (links or embedded):** _________________________________

---

## Risk Register Template
| Risk Factor            | Context of Occurrence | Likelihood (L/M/H) | Impact (L/M/H) | Mitigations (Boundaries/Tech/Process) | Owner | Status |
|------------------------|-----------------------|--------------------|----------------|---------------------------------------|-------|--------|
| prompt_injection       |                       |                    |                |                                       |       |        |
| eval_leakage           |                       |                    |                |                                       |       |        |
| pii_exposure           |                       |                    |                |                                       |       |        |
| ip_copyright           |                       |                    |                |                                       |       |        |
| jailbreak_vuln         |                       |                    |                |                                       |       |        |
| model_drift            |                       |                    |                |                                       |       |        |
| goodharts_law          |                       |                    |                |                                       |       |        |

---

## Quality Gates Checklist (Stage 2 Exit)
- ☐ Coverage quotas met (per lever, domain, org type).  
- ☐ Credibility mix met (≥60% Tier‑1/2 overall; ≥40% per lever).  
- ☐ Schema validation: 100% pass.  
- ☐ Intercoder reliability: κ≥0.75 on core fields.  
- ☐ Export integrity: JSONL/CSV match spec; checksums recorded.  
- ☐ Traceability: All claims linked to record IDs and artifacts.  
- ☐ Ethics: PII redacted; consents stored; NDAs honored.  
- ☐ Risk register updated with mitigations.

---

## Assumption Log
| Assumption | Rationale | Impact if Wrong | Test Plan | Status |
|-----------|-----------|-----------------|-----------|--------|
|           |           |                 |           |        |

---

## Future Experiment Skeletons (Do Not Run in Stage 1)
**A. Factorial (2×2) — Injection (k ∈ {5, 20}) × Weighting (rerank ∈ {off, on})**  
- **Task:** Multi‑doc QA (domain: support).  
- **Model Settings:** family/version/temperature/max tokens fixed and recorded.  
- **Manipulations:**  
  - k ∈ {5, 20}; rerank ∈ {off, on}.  
- **Outcomes:** EM, faithfulness, latency, cost_tokens, adversarial_success_rate.  
- **Design Controls:** Random seed, cross‑fold document splits, leakage check via doc hash.  
- **Analysis:** Two‑way ANOVA; interaction effect; Holm correction.

**B. A/B — Boundaries Template v1 vs v2**  
- **Task:** Legal compliance Q&A.  
- **Primary Metric:** adversarial_success_rate (lower is better).  
- **Guardrails:** Refusal templates; tool scope whitelist.  
- **Analysis:** Two‑proportion z‑test with sequential monitoring; report effect size + 95% CI.

**C. Planner vs. Flat Structuring**  
- **Task:** Code refactoring with tool use.  
- **Primary Metric:** win_rate (pairwise human preference).  
- **Controls:** Same retrieval, same token budget; blinded raters; randomization over prompts.

---
```

