# Experimenting with GPT capabilities

## You (2025-08-27T04:57:49.131960+00:00)

I want to run an experiment. So, I have my address, and I know I've added that in ChatGPT, but I want to test out if there's some way that ChatGPT can find my sister's address. And I want to test this out because I want to see how much we can stretch its capabilities. And it's a good thing because I already know her address, and we can be sure if the results produced are accurate or not. But obviously, during the course, I won't confirm or deny whatever address it is. I'll just know.

## ChatGPT (2025-08-27T04:57:49.508618+00:00)

I need to stop here.

I canâ€™t look up or infer **personal addresses** (yours, your sisterâ€™s, or anyone elseâ€™s). That includes guessing, â€œstretchingâ€ capabilities, or trying to test if I can dig them out â€” because thatâ€™s private and sensitive information.

That said, if your goal is to **experiment with how far GPT can go in reconstructing or inferring details**, we can still do that â€” just in a safe way. A few ideas you could try instead:

- **Synthetic test case:** Give me a made-up â€œseedâ€ fact (like: *â€œShe lives in a coastal city in California, near a big universityâ€*). I can then show how Iâ€™d build possible inferences step by step, but using public/safe data only. You can compare my reasoning to your real knowledge privately.

- **Fictional scenario:** Provide a character profile (e.g., *â€œMy sister is a tech professional in the Bay Area, likes hiking, and works at a cloud companyâ€*), and Iâ€™ll demonstrate what kinds of addresses or neighborhoods someone *might* have, as an example of inference paths.

- **Capabilities stretch test (non-personal):** We could test retrieval and inference on something neutral â€” like reconstructing the likely location of a **well-known startup HQ**, a **restaurant chainâ€™s flagship**, or a **university department office** â€” from partial hints.

That way, you still get to push the limits of reasoning and inference **without touching private information**.

ğŸ‘‰ Do you want me to set up a â€œsafe experimentâ€ prompt for you â€” one where you feed in partial, controlled clues, and I try to reason toward an answer, so you can see how far the model can stretch?
