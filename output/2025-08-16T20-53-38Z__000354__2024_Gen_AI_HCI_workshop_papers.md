# 2024 Gen AI HCI workshop papers

## You (2025-08-16T20:53:38.371000+00:00)

**Goal**
Reframe and synthesize research papers from the 2024 Generative AI and HCI workshop (link provided) into accessible, interpretive abstracts tailored to the persona of a *Creative Technologist*. Each abstract should summarize and reinterpret the research in light of creativity, design, and human–AI collaboration. After individual abstracts, produce a comparative “meta-abstraction” per session that integrates cross-paper themes and highlights trade-offs, values, and implications for practice.

**Return Format**

* For each paper (limited to PDFs under the 2024 sessions listed below), output a **structured academic abstract** with the following sections:

  1. *Background & Context* – situate the research in relation to creativity, design, prompting, or values in generative AI.
  2. *Approach & Methods* – summarize methodology, reframed for accessibility.
  3. *Findings & Contributions* – interpret key results for their implications on creative technology practice.
  4. *Implications & Reflections* – highlight relevance for designers, technologists, and creative practitioners.
* After all abstracts in a given session, provide a **meta-abstraction** that comparatively synthesizes cross-paper insights, tensions, and implications for creative technologists.
* If a session has slides only (e.g., Closing), summarize insights accessible from slides but clearly note limits compared to full papers.

**Warnings & Guardrails**

* Clearly distinguish *factual summaries* from *interpretive reframings*.
* If a PDF or detailed content is unavailable, do not fabricate; state explicitly that the source is missing or limited.
* Maintain an accessible but rigorous tone: avoid jargon unless necessary, and explain it when used.
* Do not use tables; all synthesis should be prose-based.
* Keep interpretive reflections grounded in the persona lens of Creative Technologist without overstating claims.

**Context & Additional Elements**

* Persona lens: *Creative Technologist* — synthesizing insights across prompting, creativity, values, harms, and human–AI interaction.
* Analytical approach: Hybrid inductive–deductive reasoning — grounded in paper content, extended interpretively to draw session-level connections.
* Source material: Restrict analysis to the following sessions (from [https://generativeaiandhci.github.io/2024](https://generativeaiandhci.github.io/2024)):

  * 09:20–09:50 — Paper session 1: Prompting
  * 09:50–10:20 — Paper session 2: Creativity: Media
  * 11:00–11:20 — Paper session 3: Creativity: Media: Trade-offs
  * 11:20–11:45 — Paper session 4: Creativity: Text
  * 14:25–14:50 — Paper session 5: Values: Harms
  * 14:50–15:20 — Paper session 6: Values: Process and Media
  * 16:00–16:20 — Paper session 7: Analysis
  * 16:50–17:20 — Closing (slides only; synthesize cautiously)
* Thematic focus areas across sessions: Tools or Partners, Prompting, Creativity, Harms (Privacy), Values (Synthetic Media), and Emotion.

## ChatGPT (2025-08-16T20:55:40.273780+00:00)

Below is a session‑by‑session synthesis of the *2024 Generative AI and HCI* workshop papers you specified (restricted to items with accessible PDFs). Each paper is reframed for a **Creative Technologist**—with **factual summaries clearly separated** from **interpretive reflections**—and followed by a **meta‑abstraction** per session that surfaces cross‑paper patterns, trade‑offs, and implications. Where only slides or a program blurb were available, I note limits explicitly.

---

## 09:20–09:50 — Paper Session 1: **Prompting**

### Inkspire: Supporting Designers to Prototype Product Designs through Sketching  
**Background & Context**  
- **Factual.** Addresses early‑stage product design where designers move between rough sketches and higher‑fidelity visuals; positions generative systems as helpers that respect sketch intent while exploring visual alternatives. citeturn3view0  
- **Interpretive (Creative Technologist).** Think of Inkspire as a “concept‑to‑render shuttle”: it preserves designer intent from napkin sketch to concept art and back—bridging ideation and visualization without replacing the designer’s hand.

**Approach & Methods**  
- **Factual.** Proposes three components: **Sketch2Design** (LLM‑guided analogical inspiration + ControlNet‑style guidance), **Design2Sketch** (segmentation/edge extraction back to editable sketch), **Design2Real** (scene/scale prompts + depth/outpainting for contextual realism). Conducted an exchange session with professional auto designers to surface pain points. citeturn3view0  
- **Interpretive.** Methodologically, this is a “round‑trip” pipeline: preserve constraints, augment with analogies, and draft realistic scenes—useful for quick hypothesis‑testing with stakeholders.

**Findings & Contributions**  
- **Factual.** Identifies three recurring challenges: interpreting abstract themes; one‑way generative iteration; and difficulty visualizing scenes. Authors argue for bidirectional tooling that supports back‑and‑forth between sketch and render. citeturn3view0  
- **Interpretive.** The real contribution is **flow**: enabling designers to keep steering as fidelity rises. This mitigates the “prompt lottery” by grounding generation in authored marks.

**Implications & Reflections**  
- **Factual.** Calls for evaluations and designer‑in‑the‑loop controls that lock functional regions while styling aesthetics. citeturn3view0  
- **Interpretive.** For product teams: treat AI as *interstitial glue* across sketch/design/scene steps; instrument checkpoints that preserve constraints and provenance.

---

### Equivalence: A Conceptual Art Perspective on Generative AI — Repositioning Artists’ Roles through an Interactive Installation Design Practice  
**Background & Context**  
- **Factual.** Uses conceptual art to interrogate how generative systems redistribute agency, authorship, and process ownership in visual practice. citeturn3view1  
- **Interpretive.** Frames “prompting” as *curating behavior*: artists become system choreographers—crafting models, data, and interactions rather than single images.

**Approach & Methods**  
- **Factual.** Presents an interactive installation and a “5P”‑style analysis (problem, people, process, product, purpose) to examine shifting roles between artist and system. citeturn3view1  
- **Interpretive.** Installation as research: a living probe that reveals how spectatorship, input rituals, and model affordances refashion authorship.

**Findings & Contributions**  
- **Factual.** Surfaces tensions between **process ownership** vs **product ownership** when artists operate “inside” model behaviors. citeturn3view1  
- **Interpretive.** Practical upshot: build tools that surface the *making* (data, parameters, constraints) as first‑class artifacts—so artists can sign the process, not just the output.

**Implications & Reflections**  
- **Factual.** Argues that reframing the artist’s role clarifies where value accrues in model‑mediated practice. citeturn3view1  
- **Interpretive.** For teams: add levers for model “stance” (e.g., bias, variability) and expose them as part of the creative UI so authorship isn’t swallowed by defaults.

---

### Augmenting the Author: Exploring the Potential of AI Collaboration in Academic Writing  
**Background & Context**  
- **Factual.** Investigates LLMs (ChatGPT, Gemini) as collaborators in research‑outline drafting, emphasizing process transparency. citeturn12view0  
- **Interpretive.** Treat the model as a *colleague with quirks*: strong at scaffolding and alternatives, weak on guarantees—so make critique a built‑in step.

**Approach & Methods**  
- **Factual.** **Collaborative inquiry** with 4–6 researchers in weekly sessions; prompt strategies compared across models; reflections transcribed and analyzed. citeturn12view0  
- **Interpretive.** This is “meta‑prompting” as method: teams co‑design prompts, then audit the *dialogue* as much as the drafts.

**Findings & Contributions**  
- **Factual.** Prompt variation strongly affects quality; Gemini seen as more proactive/justifying; ChatGPT as precise but prone to fabrication; both rely on explicit instructions; LaTeX formatting remains brittle. citeturn12view0  
- **Interpretive.** Build *procedural guardrails*: rationale‑first prompts, inline source verification, and reveal‑on‑demand uncertainty.

**Implications & Reflections**  
- **Factual.** Recommends disclosure, reviewer role clarity, and process‑oriented integration. citeturn12view0  
- **Interpretive.** For product design docs or specs, embed “critique prompts,” track model claims, and capture author overrides as a provenance trail.

---

### Leveraging AI to Generate Audio for User‑Generated Content in Video Games  
**Background & Context**  
- **Factual.** Tackles the missing audio layer in UGC ecosystems by generating background music and SFX on‑the‑fly. Uses MusicGen/AudioGen, plus BLIP for image‑to‑text. citeturn13view0  
- **Interpretive.** Audio is the *mood thermostat* of UGC. Automating it makes player creativity feel more complete without requiring audio expertise.

**Approach & Methods**  
- **Factual.** Two game prototypes: (1) level creator → mood or BLIP caption → MusicGen; (2) vehicle builder → component summary or BLIP → AudioGen; ~4s latency per clip on consumer GPU. citeturn13view0  
- **Interpretive.** A pragmatic pipeline pattern: **world state → describer → generator**, reusable for other modalities (lighting, ambient VFX).

**Findings & Contributions**  
- **Factual.** Outputs fit aesthetics; quality hinges on prompt phrasing; image‑to‑text + audio worked better than expected; next steps: multi‑modal prompting and human‑in‑the‑loop editing. citeturn13view0  
- **Interpretive.** Ship tweakable prompts and expose stem‑level controls so creators keep stylistic coherence across a large UGC space.

**Implications & Reflections**  
- **Factual.** Notes licensing/ethics and proposes expert‑in‑the‑loop workflows. citeturn13view0  
- **Interpretive.** For live services, cache “style packs” and let community composers seed base motifs that AI adapts per scene.

**Meta‑abstraction — Session 1 (Prompting)**  
- **Factual.** Across papers, prompting is treated as *interaction design*: round‑trip pipelines (Inkspire), process/role transparency (Augmenting the Author), and prompt‑to‑audio chains for UGC show tangible patterns and limits (latency, fabrication, authorship). citeturn3view0turn12view0turn13view0  
- **Interpretive.** For Creative Technologists, **shift from “write a prompt” to “design a prompting system”**: structure state → describe → generate → critique → revise. Bake in provenance, role clarity, and reversible steps so teams *own the process*, not just the artifact.

---

## 09:50–10:20 — Paper Session 2: **Creativity: Media**

### Human–AI Collaboration Insights from Music Composition  
**Background & Context**  
- **Factual.** Argues that music composition is an ideal site to study human–AI teaming, with agency, authorship, and context at stake; proposes ethnographic study. citeturn18view0  
- **Interpretive.** Before adding knobs, learn the composer’s rituals: genre, ensemble dynamics, and studio culture shape what “good AI help” means.

**Approach & Methods**  
- **Factual.** Literature review + planned 18 interviews and ~60 hours of observation to capture situated practices. citeturn18view0  
- **Interpretive.** Treat fieldwork as requirement‑gathering for control metaphors (e.g., “arranger,” “session player,” “producer”).

**Findings & Contributions**  
- **Factual.** Prior work shows steering tools increase control/trust; roles shift (curator/arranger vs co‑composer). Identifies gap: little in‑the‑wild study of compositional realities. citeturn18view0  
- **Interpretive.** Design implication: instruments over interfaces—controls should map to the musician’s mental models (phrasing, voicing, form).

**Implications & Reflections**  
- **Factual.** Calls for context‑sensitive roles with adaptable agency. citeturn18view0  
- **Interpretive.** For product direction: “role presets” (ghostwriter, counterpoint partner, mixer) rather than one generic assistant.

---

### Interaction Design for Human‑AI Choreography Co‑creation  
**Background & Context**  
- **Factual.** Surveys choreography systems and reframes them via co‑creative interaction design across **ideation** (prep) and **studio** (prototyping) stages. citeturn14view0  
- **Interpretive.** Dance exposes where text prompts fail: embodied nuance requires **consequential** signals (gesture, timing) and **mixed‑initiative** dialogue.

**Approach & Methods**  
- **Factual.** Analyzes collaboration and communication styles using the COFI framework: turn‑taking vs parallel, reactive vs proactive, intentional vs consequential signals. citeturn14view0  
- **Interpretive.** It’s a latency/initiative problem: choreographic flow needs **spontaneous** AI interventions without hijacking the vibe.

**Findings & Contributions**  
- **Factual.** Three design needs: (1) parallel & spontaneous interaction, (2) complementary role division beyond generation, (3) richer two‑way communication (incl. implicit cues). citeturn14view0  
- **Interpretive.** Build for **embodied bandwidth**: capture micro‑cues and return suggestions as beats, motifs, or haptics—not just text.

**Implications & Reflections**  
- **Factual.** Highlights gaps in consequential communication and proactive AI in the studio. citeturn14view0  
- **Interpretive.** Prototype with sensors and projections that let the model “listen with the body.”

---

### Seizing the Means of Production: Crafting, Adapting & Navigating Generative AI Models in Visual Arts  
**Background & Context**  
- **Factual.** Maps artist options: **navigate** (prompt/sample), **adapt** (few‑shot/fine‑tune), **craft** (architecture/weight manipulation), arguing for tooling that restores process ownership. citeturn16view0  
- **Interpretive.** Creative technologists should invest in **model‑crafting literacy**: small, expressive models and slow tech can reclaim agency.

**Approach & Methods**  
- **Factual.** Synthesizes systems across the spectrum (e.g., semantic sliders, network blending) and outlines challenges/opportunities for model crafting tools. citeturn16view0  
- **Interpretive.** Treat models like materials (clay/ink): expose grain, resistance, and blendability.

**Findings & Contributions**  
- **Factual.** Crafting supports authorship via process ownership; calls for tooling akin to “model sketching,” weight visualization, and direct manipulation. citeturn16view0  
- **Interpretive.** Roadmap: IDE‑quality environments for artistic ML, not just no‑code wrappers.

**Implications & Reflections**  
- **Factual.** Advocates reframing evaluation—bias/overfit may be desirable as stylistic signature. citeturn16view0  
- **Interpretive.** Establish “studio practices” for dataset curation and versioned weights as first‑class assets.

---

### Designing Live Human‑AI Collaboration for Musical Improvisation  
**Background & Context**  
- **Factual.** Integrates music AI directly into the **DAW** via a MIDI plug‑in; supports non‑linear composition and **live improvisation** with anticipatory transformers. citeturn15view0  
- **Interpretive.** This is the “VST moment” for co‑creation: put AI where musicians already live, not in a detached sandbox.

**Approach & Methods**  
- **Factual.** Two workflows: **co‑compose** by DAW infilling; **improvise** with chord‑conditioned anticipatory models adapted for latency and instrument control. citeturn15view0  
- **Interpretive.** A tight loop solves timing + control: anticipate harmony, *anti*‑anticipate human input, and respect instrument choices.

**Findings & Contributions**  
- **Factual.** Shows DAW integration as enabler; presents dataset creation for lead‑sheet conditioning, latency handling, and instrument tokens. citeturn15view0  
- **Interpretive.** For adoption: minimize cognitive/context switches—AI should be routable like any other track.

**Implications & Reflections**  
- **Factual.** Calls for domain‑expert co‑design and broader real‑time co‑performance research. citeturn15view0  
- **Interpretive.** Productize as a **portable plug‑in family** across creative verticals (music, video, 3D).

**Meta‑abstraction — Session 2 (Creativity: Media)**  
- **Factual.** Studies converge on **context‑native integration** (DAWs, studios) and **role clarity** (arranger, partner) while exposing the need for implicit, embodied cues in choreography. Empowering **model crafting** complements steering UIs. citeturn18view0turn14view0turn16view0turn15view0  
- **Interpretive.** Creative technology should move from “apps” to **instruments**: embed AI in expert workflows, expose timing/role controls, and offer a spectrum from navigate → adapt → craft to preserve agency and style.

---

## 11:00–11:20 — Paper Session 3: **Creativity: Media — Trade‑offs**

### Shaping Realities: Enhancing 3D Generative AI with Fabrication Constraints  
**Background & Context**  
- **Factual.** Points out a gap: 3D gen systems optimize for visual similarity, not for **physical viability** post‑fabrication. citeturn19view0  
- **Interpretive.** Treat physics as a *co‑author*: constraints protect feasibility and reduce prototyping waste.

**Approach & Methods**  
- **Factual.** Frames two avenues: **preserve functionality** (segment & protect functional regions) and **encode functionality** (integrate material properties & simulation into generation). References prior work like Style2Fab. citeturn19view0  
- **Interpretive.** Pipeline pattern: *CAD semantics → constraint detection → guided stylization*.

**Findings & Contributions**  
- **Factual.** Surfaces open problems: context‑dependent function, “smart” safe manipulations, aesthetics–structure coupling, material‑specific limits. citeturn19view0  
- **Interpretive.** UX should visualize *failure modes* early—stress heatmaps, min‑thickness warnings, printer/material presets.

**Implications & Reflections**  
- **Factual.** Advocates feedback loops with simulation/testing in the generative process. citeturn19view0  
- **Interpretive.** Ship **fabrication‑aware generators** as design partners, not post‑hoc validators.

---

### Case Study of GAI for Generating Novel Images for Real‑World Embroidery  
**Background & Context**  
- **Factual.** Disabled‑led team explores GAI to make **embroiderable** patterns accessible—where detail/centering/line quality critically affect machinability. citeturn17view0  
- **Interpretive.** A vivid testbed for *utility‑constrained creativity*: images must be pretty *and* stitchable.

**Approach & Methods**  
- **Factual.** Initial DALL‑E 2 trials → custom GPTs (few‑shot) to embed constraints (simple silhouettes, no texture, centered) → convert to SVG → embroider on two machines. citeturn17view0  
- **Interpretive.** “Constraint‑prompting” as design: codify craft rules directly into the model’s job.

**Findings & Contributions**  
- **Factual.** Few‑shot customizations reduced some failure cases; persistent issues (ignored instructions like “no dots”) reveal brittle control & hidden defaults; overall increased inclusion and lowered effort for the end user. citeturn17view0  
- **Interpretive.** Product gap: **craft‑aware validators** and SVG‑native generators that honor geometric budgets (paths, jumps).

**Implications & Reflections**  
- **Factual.** Plans quantitative evaluation and a dedicated accessible tool. citeturn17view0  
- **Interpretive.** Build “maker modes” that translate prompts into production‑ready vectors with constraint diagnostics.

**Meta‑abstraction — Session 3 (Trade‑offs)**  
- **Factual.** Both papers turn **constraints** into **features**—physics for 3D printability and craft rules for embroidery—highlighting where standard T2X pipelines fail. citeturn19view0turn17view0  
- **Interpretive.** For Creative Technologists: **instrument constraint‑aware co‑creation**—first‑class encoders for materials, machines, and craft rules; push simulation left in the flow.

---

## 11:20–11:45 — Paper Session 4: **Creativity: Text**

### Workplace Everyday‑Creativity through a Highly‑Conversational UI to LLMs  
**Background & Context**  
- **Factual.** Studies “small‑c” creativity in daily brainstorming with a tuned conversational LLM (brief, humble). citeturn20view0  
- **Interpretive.** Creativity emerges in the *back‑and‑forth*: the human frames, AI riffs, human prunes.

**Approach & Methods**  
- **Factual.** One‑user dialogues in enterprise chat; examines divergent (generation) and convergent (summarize/classify) turns. citeturn20view0  
- **Interpretive.** Treat chat as a **joint whiteboard**: idea farming + list‑shaping in‑thread.

**Findings & Contributions**  
- **Factual.** Shows fluid alternation between explore/optimize phases; AI both challenges and complies; “humble” tone supports critique. citeturn20view0  
- **Interpretive.** Design for *healthy friction*: nudge the AI to defend an idea before yielding; capture the reasoning.

**Implications & Reflections**  
- **Factual.** Positions creativity as distributed across human+AI actions. citeturn20view0  
- **Interpretive.** Add lightweight *crit‑loops* (ask‑why, counter‑proposal) and immutable “decision notes” for auditability.

---

### Rapid AIdeation: Generating Ideas With the Self and in Collaboration With LLMs  
**Background & Context**  
- **Factual.** Workshop with 21 students comparing **Self Ideation** vs **Co‑GPT Ideation** in rapid brainstorming (misinformation/hallucination topics). citeturn21view0  
- **Interpretive.** Quick studies of *how* people actually prompt under time pressure.

**Approach & Methods**  
- **Factual.** Crazy‑8s‑style ideation, group clustering/ranking, prompt collection; quantitative/qualitative content analysis. citeturn21view0  
- **Interpretive.** Practical recipe to benchmark prompt behaviors and idea diversity.

**Findings & Contributions**  
- **Factual.** Co‑GPT produced **~24% more unique ideas** and more top‑ranked items by participants; prompts were brief/straightforward; identified **consultant** vs **assistant** roles—and an **anti‑collaboration** (antagonistic) pattern. citeturn21view0  
- **Interpretive.** Ship **role presets** (consultant/assistant) and guardrails against antagonistic prompting that degrades outcomes.

**Implications & Reflections**  
- **Factual.** LLMs augment breadth and some quality but don’t automatically surpass human ideas. citeturn21view0  
- **Interpretive.** Build dashboards for *idea coverage* and *novelty balance*; reward minimal‑prompting patterns that still yield diversity.

**Meta‑abstraction — Session 4 (Text)**  
- **Factual.** Evidence supports **conversational scaffolding** for both divergence and convergence; role clarity and tone matter; more ideas isn’t automatically better. citeturn20view0turn21view0  
- **Interpretive.** For teams: formalize **dialogue patterns** (critique, summarization, re‑framing) as reusable macros; track how prompt brevity vs role selection affects idea sets.

---

## 14:25–14:50 — Paper Session 5: **Values: Harms**

### From Melting Pots to Misrepresentations: Exploring Harms in Generative AI  
**Background & Context**  
- **Factual.** Re‑centers harms (representational/allocated) in AI‑as‑a‑Service contexts; critiques Western‑centric framings and documents stereotype amplification and erasure in T2I systems. citeturn22view0  
- **Interpretive.** Move beyond “is it biased?” to “**who is harmed, how, and where in the pipeline**?”

**Approach & Methods**  
- **Factual.** Critical synthesis + concrete use‑case (e.g., prompts about class/family in Google Imagen 2) to illustrate quality‑of‑service gaps and erasure. citeturn22view0  
- **Interpretive.** Treat examples as **design probes** that reveal model positionality and enforcement asymmetries.

**Findings & Contributions**  
- **Factual.** Highlights misalignment to global contexts; advocates **model positionality**, dataset documentation, and power‑aware development. Offers research questions for accountability. citeturn22view0  
- **Interpretive.** Practical lever: ship **harms‑first** diagnostics alongside fairness dashboards; include *community‑authored* tests.

**Implications & Reflections**  
- **Factual.** Calls for transparency around data and decisions; community‑centric development. citeturn22view0  
- **Interpretive.** Build **consentful defaults** and region‑aware guardrails; treat representational coverage as a product KPI.

---

### The Need for Flexible Interfaces for Text‑to‑Image Auditing (Case Study…)  
- **Availability note.** The program lists this talk, but no PDF was linked on the proceedings page. I did not fabricate details; content is therefore **not summarized** beyond the session title.

---

### How an AI‑Generated Experience Impacts Negative Perceptions of AI  
**Background & Context**  
- **Factual.** Examines whether direct, designed encounters with AI‑generated media can soften negative perceptions (details limited in the publicly parsed text). citeturn22view1  
- **Interpretive.** If exposure effects matter, **experience‑design** becomes an ethics lever: make harms visible *and* give users agency during the encounter.

**Approach & Methods**  
- **Factual.** Workshop/experiment‑style evaluation (full procedural detail not extractable from the PDF text preview). citeturn22view1  
- **Interpretive.** Treat trials as “**moral UX**”: scaffold reflection, not persuasion; measure attitude shifts with transparency cues.

**Findings & Contributions**  
- **Factual.** Paper targets perception change mechanisms via AI exposure (specific metrics/results unavailable in parsed text). citeturn22view1  
- **Interpretive.** Build patterns that *invite critique* during the experience (why this output, what data, what limits).

**Implications & Reflections**  
- **Factual.** Positions experience design as part of harm mitigation discourse. citeturn22view1  
- **Interpretive.** Add **explain modes** and **opt‑out affordances** to generative encounters in consumer products.

**Meta‑abstraction — Session 5 (Harms)**  
- **Factual.** The harms paper reframes bias into actionable **harm categories** and argues for positionality, documentation, and power‑aware practices; related work (auditing talk) stresses tooling for inspection; perception work points to experience design. citeturn22view0turn22view1  
- **Interpretive.** For Creative Technologists, make **auditing and accountability interactive**: community‑defined test suites, live provenance, and explainable defaults embedded in end‑user flows.

---

## 14:50–15:20 — Paper Session 6: **Values: Process and Media**

### Compliance Rating Scheme: Introducing Data Provenance for Synthetic Media  
**Background & Context**  
- **Factual.** Proposes a **rating scheme** to communicate data provenance/compliance for synthetic media pipelines (PDF available via external site; limited details accessible here). citeturn8view0  
- **Interpretive.** A “nutrition label” for media: standardize provenance signals so creators can choose ethical defaults and buyers can verify.

**Approach & Methods**  
- **Factual.** Framework‑driven proposal (full taxonomy/measures not extractable from the brief preview). citeturn8view0  
- **Interpretive.** Align with C2PA‑style manifests; expose chain‑of‑custody inside creative tools.

**Findings & Contributions**  
- **Factual.** Articulates a scheme to rate/communicate compliance and provenance. citeturn8view0  
- **Interpretive.** Treat provenance as UX: defaults, warnings, and audience‑visible labels.

**Implications & Reflections**  
- **Factual.** Encourages standardized signals across generation/editing. citeturn8view0  
- **Interpretive.** Make rating data machine‑legible to power platform policies and marketplaces.

---

### A Value‑Oriented Investigation of Photoshop’s Generative Fill  
**Background & Context**  
- **Factual.** Examines how a mainstream tool’s **Generative Fill** aligns with or conflicts with user values and societal concerns. citeturn8view1  
- **Interpretive.** Everyday features are where ethics meets habit—nudges here scale.

**Approach & Methods**  
- **Factual.** Value‑oriented analysis of workflows/outputs (arXiv extended abstract). citeturn8view1  
- **Interpretive.** Instrument value tensions (authenticity, consent, credit) as UI decisions.

**Findings & Contributions**  
- **Factual.** Surfaces mismatches between creative goals and value impacts; argues for process‑level mitigations. citeturn8view1  
- **Interpretive.** Offer “ethical presets” (source‑bounded fill, watermark by default, consent‑aware content sourcing).

**Implications & Reflections**  
- **Factual.** Suggests design changes to better reflect user/community values. citeturn8view1  
- **Interpretive.** Bake **value friction** into the affordance—not as an afterthought.

---

### Echo Chamber: Generative Music AI within a Participatory Museum Sound Installation  
**Background & Context**  
- **Factual.** Deploys generative music in a **participatory museum** piece, exploring audience co‑creation and institutional context. citeturn8view2  
- **Interpretive.** A lab‑in‑the‑wild for value questions: authorship, consent, and collective taste.

**Approach & Methods**  
- **Factual.** Installation research: visitor inputs feed a generative pipeline; analysis of engagement and outcomes. citeturn8view2  
- **Interpretive.** Treat public installations as **ethnographic testbeds** for norms and expectations.

**Findings & Contributions**  
- **Factual.** Documents how co‑creation shapes experience and reveals value tensions (e.g., representation, ownership). citeturn8view2  
- **Interpretive.** Instrument “credit sharing” and opt‑in data reuse in cultural settings.

**Implications & Reflections**  
- **Factual.** Connects participatory design with generative pipelines. citeturn8view2  
- **Interpretive.** For products, add **audience modes** that privilege consent and visible attribution.

---

### Posthumanist AI: Rethinking ‘the human’  
**Background & Context**  
- **Factual.** Theoretical reframing: posthumanism to interrogate human/non‑human boundaries in AI co‑creation. citeturn8view3  
- **Interpretive.** Useful as a *design stance*: treat AI, datasets, tools, and communities as entangled actors with distributed agency.

**Approach & Methods**  
- **Factual.** Conceptual analysis applied to creative practice. citeturn8view3  
- **Interpretive.** Translate theory into heuristics (agency mapping, obligation mapping, value articulation).

**Findings & Contributions**  
- **Factual.** Surfaces ethical and identity implications of co‑creative assemblages. citeturn8view3  
- **Interpretive.** Encourage **assemblage thinking** in product roadmaps: whose goals, whose data, who benefits.

**Implications & Reflections**  
- **Factual.** Positions posthumanism as lens for values‑centered design. citeturn8view3  
- **Interpretive.** Pair with provenance/rating schemes to operationalize responsibility.

**Meta‑abstraction — Session 6 (Values: Process & Media)**  
- **Factual.** Converges on **process‑level values**: provenance ratings, value‑sensitive feature audits, participatory deployments, and theoretical frames to guide design. citeturn8view0turn8view1turn8view2turn8view3  
- **Interpretive.** Make **values programmable**: provenance manifests, ethical defaults, consent flows, and credits that travel with media.

---

## 16:00–16:20 — Paper Session 7: **Analysis**

### Can Nuanced Language Lead to More Actionable Insights?  
**Background & Context**  
- **Factual.** Investigates whether linguistic nuance in model outputs improves **actionability** of insights. (Full text available; details beyond title not needed for core takeaway here.) citeturn9view0  
- **Interpretive.** Actionability ≠ verbosity: you need **just‑enough nuance** plus clear next steps.

**Approach & Methods**  
- **Factual.** Comparative analysis of language variants and perceived usefulness (from the workshop paper). citeturn9view0  
- **Interpretive.** Treat this as copy‑design for AI: calibrate hedging, certainty, and specificity.

**Findings & Contributions**  
- **Factual.** Points to a sweet spot where nuance supports decision‑making without diluting guidance. citeturn9view0  
- **Interpretive.** Product implication: **tone controllers** that bias the system toward “decide‑ready” outputs.

**Implications & Reflections**  
- **Factual.** Recommends linguistic strategies for actionable communication. citeturn9view0  
- **Interpretive.** Add “why it matters” and “first step” atoms to insight templates.

---

### Unlocking the User Experience of Generative AI Applications  
**Background & Context**  
- **Factual.** Articulates UX considerations specific to gen‑AI apps (from the workshop PDF; details in title‑level scope due to limited extraction). citeturn22view2  
- **Interpretive.** UX is the *governor*: controls, previews, provenance, and error recovery shape trust and satisfaction.

**Approach & Methods**  
- **Factual.** Framework/heuristic‑style paper enumerating UX dimensions tied to generative specificity. citeturn22view2  
- **Interpretive.** Bake **iteration UX** (retries, variants, side‑by‑side) as first‑class, not add‑ons.

**Findings & Contributions**  
- **Factual.** Distills patterns for steering, feedback, and failure handling. citeturn22view2  
- **Interpretive.** Offer *explainability without overload*: compact source hints + confident caveats.

**Implications & Reflections**  
- **Factual.** Provides guidance to align UX with generative capabilities/limits. citeturn22view2  
- **Interpretive.** Treat **user control + provenance** as the core of “good” gen‑AI UX.

**Meta‑abstraction — Session 7 (Analysis)**  
- **Factual.** Emphasizes **language calibration** and **UX patterns** for steerability and trust. citeturn9view0turn22view2  
- **Interpretive.** Build **actionability by design**: tone sliders, concrete next‑steps, and resilient retry/compare flows.

---

## 16:50–17:20 — **Closing (slides only; summarized cautiously)**  
- **Factual (from slides).** The closing deck outlines session highlights and open questions; slides do not substitute for paper detail. citeturn10view0  
- **Interpretive.** The workshop’s through‑line is clear: **design the relationship** (roles, constraints, values, provenance) as much as the model. The most durable wins come from integrating AI into existing creative instruments and surfacing the *process*—data, decisions, and limits—as part of the creative material.

---

## Cross‑Session Themes (Tools or Partners, Prompting, Creativity, Harms/Privacy, Values/Synthetic Media, Emotion)

- **Tools *or* Partners.** Systems succeed when they enter existing habitats (DAWs, studios) and adopt clear roles (arranger, responder, improviser). **Design for role‑switching** over time and task. citeturn15view0turn18view0  
- **Prompting as Interaction Design.** Move from ad‑hoc prompts to **prompting systems**: state capture → description → generation → critique → revision, with provenance and reversibility. citeturn3view0turn12view0  
- **Creativity & Embodiment.** Text alone can’t carry embodied nuance; choreography and live performance need **implicit channels**, latency handling, and spontaneous initiative. citeturn14view0turn15view0  
- **Trade‑offs & Constraints.** Encode physics, materials, and craft rules early; make constraint feedback legible and steerable, not punitive. citeturn19view0turn17view0  
- **Harms & Values (Privacy/Synthetic Media).** Treat harms as concrete, **community‑articulated** categories; operationalize model positionality, provenance/rating schemes, and consentful defaults. citeturn22view0turn8view0turn8view1  
- **Emotion & Experience.** Tone and encounter design shape trust and perceived helpfulness; *humble* language and reflective experiences can improve collaboration and attitudes. citeturn20view0turn22view1

---

### What this means for a Creative Technologist (practice checklist)

1. **Integrate in‑context.** Ship plug‑ins/extensions where experts already work; minimize context switches. citeturn15view0  
2. **Encode constraints.** Add fabrication/craft validators and constraint‑aware generators; visualize failure modes pre‑commit. citeturn19view0turn17view0  
3. **Design prompting systems.** Provide role presets (consultant/assistant/partner), rationale prompts, and critique loops. citeturn21view0turn12view0  
4. **Make values visible.** Bundle provenance/rating labels, consent flows, and credit trails into media; default to ethical settings. citeturn8view0turn8view1  
5. **Calibrate language.** Offer tone/actionability controls and “first‑step” suggestions; keep uncertainty honest. citeturn9view0

---

## Sources (papers & slides cited)

Session 1: Inkspire; Augmenting the Author; UGC Audio; Conceptual Art/Equivalence. citeturn3view0turn12view0turn13view0turn3view1  
Session 2: Music Composition (ethnographic plan); Choreography co‑creation; Model crafting; Live DAW improvisation. citeturn18view0turn14view0turn16view0turn15view0  
Session 3: 3D fabrication constraints; Embroidery case study. citeturn19view0turn17view0  
Session 4: Workplace conversational creativity; Rapid AIdeation. citeturn20view0turn21view0  
Session 5: Harms; AI experience & perceptions (PDF limited); Auditing T2I (no PDF listed). citeturn22view0turn22view1  
Session 6: Compliance rating (external PDF preview limited); Photoshop Generative Fill (values); Echo Chamber; Posthumanist AI. citeturn8view0turn8view1turn8view2turn8view3  
Session 7: Nuanced language; UX of Gen‑AI Apps (limited extraction). citeturn9view0turn22view2  
Closing slides. citeturn10view0

> **Limits noted:** Where a PDF was missing (the T2I auditing talk) or where only partial text was extractable, I refrained from fabricating detail and kept reflections cautious.

