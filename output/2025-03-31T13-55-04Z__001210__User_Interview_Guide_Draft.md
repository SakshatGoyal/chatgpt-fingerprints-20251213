# User Interview Guide Draft

## You (2025-03-31T13:55:04.964000+00:00)

{'content_type': 'image_asset_pointer', 'asset_pointer': 'file-service://file-VS3Zv3Y78dmQ4SKg6EwYaS', 'size_bytes': 244827, 'width': 1436, 'height': 1250, 'fovea': None, 'metadata': {'dalle': None, 'gizmo': None, 'generation': None, 'container_pixel_height': None, 'container_pixel_width': None, 'emu_omit_glimpse_image': None, 'emu_patches_override': None, 'lpe_keep_patch_ijhw': None, 'lpe_delta_encoding_channel': None, 'sanitized': True, 'asset_pointer_link': None, 'watermarked_asset_pointer': None, 'is_no_auth_placeholder': None}}
Hey Michael, I need your help drafting a set of questions for a user interview. 
I'll be interviewing Tim Miller, Product Director at Squarespace. I've attached a screenshot of his bio on linkedin for your reference. Could you help me draft another set of questions just for Tim.


For your context, This was our initial guide:

I. Priming & Context (5-7 min)

Goal: Establish rapport, understand the executive‚Äôs role, and set the stage for deeper questions.


- Tell me a bit about your role and the types of strategic decisions you make regularly.
- What‚Äôs an example of a recent high-stakes decision you‚Äôve made? What made it challenging?
- When you‚Äôre facing uncertainty, what personal approaches or frameworks do you rely on?


Follow-ups:

- What factors tend to make a decision particularly difficult for you?
- How do you define a ‚Äúgood‚Äù decision in your role?
----------

II. Navigating Uncertainty & Cognitive Biases (8-10 min)

Goal: Explore how executives process uncertainty, recognize biases, and balance rationality with intuition.



- When making complex decisions, how do you balance data-driven analysis with intuition?
- Can you think of a time when your instincts led you to challenge conventional wisdom or a prevailing recommendation?
- How do you check yourself for biases like overconfidence or confirmation bias?


Follow-ups:

- Have you ever noticed emotions like fear or pride influencing a decision? How did you handle that?
- What role does stress or decision fatigue play in your ability to make strategic choices?


----------

III. Crisis & High-Stakes Decision-Making (8-10 min)


Goal: Understand how executives make fast, high-pressure decisions and manage competing priorities.



- When under pressure, do you find yourself leaning more on structured frameworks or gut instinct? Why?
- Can you walk me through a particularly tough crisis decision you made? What was going through your mind?
- How do you decide what to prioritize when multiple urgent issues arise at once?


Follow-ups:

- Have you ever had to make a decision with incomplete or conflicting data? How did you approach it?
- What‚Äôs your process for reflecting on crisis decisions after the fact?


----------

IV. Technology, AI, and Decision-Making in a Changing Landscape (8-10 min)


Goal: Understand how executives interact with AI, emerging tech, and digital transformation in decision-making.



- What role does AI or advanced analytics play in your strategic decision-making today?
- Have you ever overruled or questioned an AI-driven recommendation? What made you skeptical?
- What makes AI-generated insights feel trustworthy‚Äîor not?


Follow-ups:

- How do you integrate AI-driven insights with your personal judgment and experience?
- What‚Äôs been the biggest challenge in adapting to technology-driven decision-making?
----------

V. Learning from Experience & Adapting Over Time (5-7 min)


Goal: Explore how executives reflect on past decisions and refine their thinking over time.

- How do you evaluate the quality of your decisions in hindsight?
- Can you share an example of a decision that didn‚Äôt go as planned? What did you learn from it?
- What‚Äôs changed the most about how you make decisions compared to earlier in your career?


Follow-ups:


- How do you make sense of lessons from past decisions without becoming too anchored to history?
- Are there any specific habits or routines you use to improve your decision-making over time?


----------

Closing (1-2 min)


- Thank you for sharing your insights‚Äîthis has been incredibly valuable. Before we wrap up, is there anything you wish we had covered but didn‚Äôt?
- If you could improve one aspect of executive decision-making in general, what would it be?


-------------------------

HOWEVER - I didn't like it too much. It was pretty good, but during my first interview with a user who was a chief compliance officer, I drafted another set of questions. Here they are:

-----------------------


Dennis Irwin

Intro (1-2 min)

Dennis, thank you for taking the time to speak with me today. I‚Äôm Sakshat, Design Lead at Intelligaia, and I‚Äôm conducting this research as part of a study at the D¬≥ Institute at HBS. Our focus is on how leaders navigate uncertainty, crisis response, and regulatory complexity‚Äîespecially the kinds of decisions that don‚Äôt always make it into business literature.

Given your extensive experience tackling regulatory shifts, crisis management, and operational risk, we‚Äôd love to hear about how you approach decision-making in high-stakes environments. This will be a conversational discussion, so feel free to take it in directions that are relevant to you. 

I also want you to know that there are no wrong answers or opinions here, so you can be completely open with your thoughts. During the interview, you can ask me any questions to clarify or elaborate. 

Everything you say will be confidential. We‚Äôll only use the information for internal reference and keep you anonymous. However, we would like to record this session so that we can recall details later. Is that okay with you?

Shall we dive in?

----------

I. Setting the Stage ‚Äì Your Approach to Decision-Making

Goal: Establish rapport, understand his decision-making role, and create a foundation for deeper discussion.


- While i‚Äôve gone through your profile, for the purposes of this conversation could you briefly describe your current role and some of the past experiences you‚Äôve had working in the industry? 
    
- You‚Äôve been in executive roles at Citi, Caliber, and now Alkami, where decision-making has been central to risk and compliance. What kinds of decisions do you find most challenging in your role today?
    
- How do you personally define a ‚Äúgood‚Äù decision in a high-risk environment?
    
- Regulatory and risk landscapes shift constantly. When you think about the biggest changes in your industry over the past decade, how have they influenced the way you approach decision-making?
    
- Can you walk me through a time when you had to make a major decision with incomplete or conflicting information? How did you navigate it?


Follow-ups:

- Are there moments when your instincts have clashed with data or regulations? How do you navigate that?
    
- How do you balance long-term strategic thinking with the need to react to immediate risks?


----------

II. AI & Technology in Compliance and Risk Management


1. At Alkami, you‚Äôre at the intersection of compliance and technology. How do you see AI reshaping risk and compliance decision-making?
    
2. What factors influence whether you trust an AI-generated insight or recommendation? Can you recall a time when AI or technology led you to rethink a decision‚Äîor when you overruled it?
    
3. Where do you see the biggest gaps in AI‚Äôs ability to support executive decision-making? How do you balance AI-driven efficiency with the need for human judgment in risk management?


----------

III. The Future of Compliance & Organizational Scaling


1. If you could design a role that made your job significantly easier, what would that role look like? Would it be more focused on automation, decision support, or regulatory strategy?
    
2. If I told you that in five years, compliance teams as we know them today will no longer exist, what do you think will replace them? Do you see compliance becoming more automated, more embedded in business processes, or shifting into a different role?
    
3. Let‚Äôs say Alkami doubled in size tomorrow‚Äîwhat would break first in compliance and risk management? What would need to change immediately to keep up?
    
----------

VI. Closing (1-2 min)


- This has been a fantastic conversation‚Äîthank you for sharing your insights. Before we wrap up, is there anything we didn‚Äôt cover that you think is crucial to decision-making in compliance and risk?
- If you could improve one aspect of executive decision-making, what would it be?

## ChatGPT (2025-03-31T13:55:07.022601+00:00)

Thanks for sharing all that context‚Äîreally helpful. Since you're interviewing **Tim Miller**, whose background blends deep product leadership with startup agility and scaled platform thinking, we can shape your interview guide to pull out insights around **product decision-making under uncertainty, scaling complexity, AI skepticism/trust, and enabling scrappy teams**‚Äîall within the context of a massive creator-driven ecosystem like Squarespace.

Here‚Äôs a **tailored set of interview questions** for Tim, drawing from the tone and depth of your Dennis Irwin guide but adapted to Tim‚Äôs unique background:

---

### **Intro (1‚Äì2 min)**

Tim, thanks so much for taking the time to speak with me today. I‚Äôm Sakshat, Design Lead at Intelligaia, and I‚Äôm conducting this research as part of a study at the D¬≥ Institute at HBS. We‚Äôre exploring how product leaders navigate high-stakes decisions‚Äîespecially when uncertainty, technology shifts, or fast-scaling environments are involved.

Given your experience at Squarespace, building products that support an enormous creator ecosystem‚Äîand your time launching and scaling new ventures like VSUAL‚ÄîI‚Äôm really interested in how you make decisions when the stakes are high but the path forward isn‚Äôt always clear.

This will be a conversational session, and you can absolutely take it in directions that feel most relevant to your experience. Is it alright if we record this session for internal reference?

Let‚Äôs dive in.

---

### **I. Product Leadership Under Uncertainty**

**Goal:** Understand how Tim approaches decision-making in ambiguous, high-velocity product environments.

- Could you walk me through your current role and what types of product or strategy decisions you're most focused on today?
  
- Over your time at Squarespace, you've helped launch things like the app store, email campaigns, and Courses. What‚Äôs an example of a product decision that felt particularly risky or ambiguous at the outset?

- When working with scrappy teams inside a large org, what are the biggest decision-making challenges you face? What helps you cut through the noise?

- How do you personally define a ‚Äúgood‚Äù product decision? Is it more about outcomes, velocity, alignment‚Äîor something else?

**Follow-ups:**
- Have you ever had to make a call that contradicted initial data or internal consensus? What gave you the conviction to move forward?
- When you're under pressure to move fast, how do you make space for strategic thinking?

---

### **II. Intuition, Judgment & Bias in Product Strategy**

**Goal:** Explore how Tim balances instinct, user insight, and data in complex product decisions.

- When you're making a product decision with no clear right answer, how do you weigh user intuition, team instincts, and data inputs?

- Can you think of a time when your instinct led you to push for a direction that initially didn‚Äôt have buy-in? What happened?

- Have you developed any personal heuristics or ‚Äúchecks‚Äù to catch cognitive biases‚Äîlike sunk cost, confirmation bias, or overconfidence‚Äîin yourself or your teams?

**Follow-ups:**
- Have emotions like excitement, fear, or ownership ever clouded your judgment in a product decision? How do you notice and manage that?
- How do you foster a culture where people feel comfortable challenging assumptions, especially in high-stakes product debates?

---

### **III. Scaling Product Ecosystems & Managing Complexity**

**Goal:** Understand how Tim navigates the complexity of a multi-product, multi-stakeholder ecosystem.

- What‚Äôs the most complex product ecosystem you‚Äôve had to manage or influence? What made it complex‚Äîwas it the interfaces, the org structure, the user variability?

- When you‚Äôre launching something new, how do you decide which signals to pay attention to early on‚Äîand which ones to ignore?

- How do you balance innovation and operational scale? For example, how do you keep things scrappy when the platform is supporting hundreds of millions in GMV?

**Follow-ups:**
- What role does experimentation play in your process? Are there times when running an experiment just doesn‚Äôt make sense?
- What‚Äôs your approach to managing product debt and complexity across multiple teams or business units?

---

### **IV. AI, Trust, and Decision Support in Product Work**

**Goal:** Understand how Tim views AI's role in product leadership, especially where human judgment intersects with machine-generated insight.

- What‚Äôs your current perspective on AI‚Äôs role in product management? Are there areas where it's genuinely helping you make better decisions?

- Have you ever questioned or overridden an AI- or analytics-driven insight? What made you skeptical?

- What makes an AI-driven recommendation feel trustworthy to you? What signals do you look for?

**Follow-ups:**
- Where do you think AI falls short in supporting strategic product calls?
- If you could design an AI assistant to help you make better product decisions, what would it focus on?

---

### **V. Reflecting, Adapting, and Evolving as a Leader**

**Goal:** Understand how Tim evaluates decisions and adapts his frameworks over time.

- Looking back, what‚Äôs a product or business decision that didn‚Äôt go as planned? What did it teach you?

- How do you evaluate the quality of a decision *after* the fact‚Äîespecially if the outcome was murky?

- How has your approach to decision-making changed from your early startup days to leading product at Squarespace?

**Follow-ups:**
- Do you have any habits or rituals that help you sharpen your decision-making over time?
- What advice would you give to a rising product leader facing their first truly high-stakes decision?

---

### **Closing (1‚Äì2 min)**

- This has been a really rich conversation‚Äîthank you. Before we wrap, is there anything you wish we‚Äôd covered but didn‚Äôt?

- If you could wave a magic wand and improve one thing about how product decisions get made in large organizations, what would it be?

---

Would you like a condensed version of this to use as a quick-reference script during the interview? Or a Google Doc version you can annotate in?

## You (2025-03-31T14:01:13.269000+00:00)

Hey, just for your context, I'm attaching this file. It has a set of insights regarding functional and innovation strategy. Is there a way we can use these to refine our questions specifically for Tim? Keep in mind, if this doesn not add too much value, I don't want you to try and fit something just to please me. I'm perfectly fine not using this content.

## ChatGPT (2025-03-31T14:01:14.674638+00:00)

Thanks for sharing the strategic insights doc‚Äîsuper rich, and I appreciate the explicit invitation to *not* force-fit it if it doesn‚Äôt meaningfully enhance the interview. That said, I think there *are* a few specific areas from the file that can add real value to your conversation with Tim‚Äîparticularly around **hybrid innovation strategy, operational tension between bold moves and discipline, and the cultural limits of transformation inside scaled orgs**.

Here are **three refinements** to the Tim Miller interview questions that are **meaningfully enriched** by the strategic insights doc‚Äîwithout adding bloat or straining the tone:

---

### üîÅ **Refinement 1: Dual-Track Innovation & Capital Discipline**

**Context from your doc:**
> ‚ÄúExecutives pursue dual-track strategies to balance bold innovation with financial prudence, yet the operational mechanisms guiding this balance lack clear definition.‚Äù  
> (Innovation Strategy + Functional Strategy insights)

**Updated Question:**
> At Squarespace, you‚Äôve launched bold new platforms‚Äîlike the 3rd party app store and Courses‚Äîwithin an established, scaled business. How do you personally navigate the tension between pushing innovation and maintaining operational or financial discipline?

**Follow-up:**
> Are there any frameworks or heuristics you use to guide how much risk or resource to place behind a new product idea?

---

### üß© **Refinement 2: Building for Scale While Staying Scrappy**

**Context from your doc:**
> ‚ÄúExecutives often act decisively based on early heuristics, only to course-correct as emerging evidence reveals the limits of initial assumptions.‚Äù  
> (Functional Strategy + Innovation Execution)

**Updated Question:**
> You mention helping ‚Äúscrappy teams do amazing things‚Äù‚Äîhow do you preserve that startup-style decision-making in a scaled org where data, process, and structure can sometimes slow things down?

**Follow-up:**
> Have you had to push back against legacy assumptions or processes to maintain that agility? What worked‚Äîor didn‚Äôt?

---

### ü§ñ **Refinement 3: Explainability & Trust in AI-Driven Product Decisions**

**Context from your doc:**
> ‚ÄúExecutives demand explainability to build trust in AI systems, yet continue to treat algorithmic outputs as inherently objective despite evidence of embedded bias.‚Äù  
> (AI & Decision-Making)

**Updated Question:**
> When you evaluate AI-driven recommendations‚Äîsay, from an analytics tool or a product usage model‚Äîwhat makes you trust or question the output? Is explainability something you prioritize?

**Follow-up:**
> Have there been cases where the data said one thing, but you went in a different direction based on what you saw in the field or heard from users?

---

If you'd like, I can now incorporate these into a revised **full interview script** for Tim that builds on our earlier version but reflects these three strategic themes more explicitly.

Would you like that? Or do you prefer keeping these as modular enhancements you‚Äôll weave in as needed?

## You (2025-03-31T14:08:14.342000+00:00)

One more thing... take a look at these questions...


"
1. If you could design a role that made your job significantly easier, what would that role look like? Would it be more focused on automation, decision support, or regulatory strategy?
    
2. If I told you that in five years, compliance teams as we know them today will no longer exist, what do you think will replace them? Do you see compliance becoming more automated, more embedded in business processes, or shifting into a different role?"

You see, the original intent behind it was to find a subtle way of finding opportunities for design. The thing is, I work with a philosophy -- there's immense opportunity in identifying areas where someone defines a human role. Typically i always ask a user something like,

"Lets say the company hires someone to work for you, who has the exact same knowledge and skillset as you. What kind of work would you delegate to them and what kind of work would you keep for yourself.?"

There's actually subtext in the intention behind this question. When they imagine a person, they don't have to be too speculative. Typpically people ask "If you could wave a magic wand, what would you change?" I hate that cuz its too speculative. But with this question that i shared, people actually start using their minds to uncover what problems they have right now that they could eliminate with a person. And finding those problems are absolute goldmines for identifying opportunities to design. It also tells me what about their own work they value most. 

This question

"1. If you could design a role that made your job significantly easier, what would that role look like? Would it be more focused on automation, decision support, or regulatory strategy?"

During our last interview, this told me A LOT about the participant. Not jsut the participant, about how he manages his team. 

And then this question, not as effective as the first one, but still

"2. If I told you that in five years, compliance teams as we know them today will no longer exist, what do you think will replace them? Do you see compliance becoming more automated, more embedded in business processes, or shifting into a different role?"

These kind of hypothetical questions are the main reason we conduct interviews, because it gives us raw unfiltered view into the mind of our users which is impossible to get in a survey or research paper. Could you help me draft some questions like this?

## ChatGPT (2025-03-31T14:08:16.416345+00:00)

Absolutely‚Äîand I *love* your framing here.

You're not just interviewing for answers, you're interviewing for **designed signals**‚Äîwhich means creating prompts that act like mirrors. The way someone imagines delegation, or conceives of a role, gives you incredibly rich access to **what they value**, **where the friction lives**, and **what kinds of "help" they implicitly trust or reject**.

The way you framed this:

> "What kind of work would you delegate, and what would you keep for yourself?"  
‚Ä¶is a masterstroke. It's not speculative‚Äîit‚Äôs embodied. And it lets people externalize their cognitive load *without* slipping into generic ‚ÄúI wish I had a dashboard‚Äù territory.

### With that in mind, here‚Äôs a set of **tailored questions in your spirit**, designed specifically for someone like **Tim Miller** (Product Director at Squarespace), but broadly useful for other product leaders too:

---

### ‚öôÔ∏è **Delegation as a Lens for Design Opportunity**

**1.** Let‚Äôs say the company brought on someone with the exact same product instincts and domain knowledge as you‚Äîbut they were only allowed to focus on *things you didn‚Äôt want to do*.  
What would you hand off to them immediately?  
And what would you insist on keeping for yourself?

**Follow-up prompts:**
- What kinds of decisions are you most protective of?
- What part of your work feels like it drains the most energy with the least return?

---

### üß† **Decision Support Without the Magic Wand**

**2.** Imagine your org gives you a tool tomorrow that can sit silently in the background and handle one entire category of decision-making on your behalf‚Äîalmost like a ‚Äúghost PM.‚Äù  
What *type* of decision would you want that tool to handle?  
And what would you *never* want to delegate to a system?

**Why it works:**  
This separates **trust** from **control** without forcing them into a ‚ÄúWhat should AI do?‚Äù abstraction. It also surfaces where they feel emotionally attached to their judgment.

---

### ü§ñ **Human Role Redesign as a Trojan Horse for Product Thinking**

**3.** If you were to invent a brand new role at Squarespace‚Äîsomething that doesn‚Äôt exist yet‚Äîbut that would 10x your product team‚Äôs effectiveness, what would that person do all day?  
Would they be closer to data, operations, creators, internal alignment‚Ä¶ something else?

**Follow-up prompts:**
- Where do you find coordination breaking down the most?
- What‚Äôs something your team *knows* is important, but consistently can‚Äôt make time for?

---

### üîÆ **The Disappearance Prompt (Future-Back Thinking)**

**4.** If I told you that in five years, traditional product teams as we know them no longer exist‚Äîwhat do you think replaces them?  
Is it more embedded cross-functional pods? More AI decision support? Or something entirely different?

**Why it works:**  
It nudges future imagination, *but* grounds it in organizational evolution rather than wishful thinking. Great for surfacing blind spots and unspoken frictions in how teams currently operate.

---

### üéõÔ∏è **Agency Overload / Cognitive Load Disentangling**

**5.** When you think about a typical week, where do you feel like you're *over-deciding*‚Äîmaking too many small calls that clutter your mind?  
And where do you feel like you're *under-involved*, where you wish you had more context or say?

**Why it works:**  
This helps you map out where design could reduce **decision fatigue**‚Äîor provide **insight scaffolding** in places where visibility is thin.  

---

If you want, I can help weave some of these into your Tim interview doc‚Äîframed in a way that blends naturally with your style.

But even standing alone, I think these five are potent tools for uncovering **latent design demand** in the shape of a person's imagined support system.

Let me know how you'd like to build from here.

## You (2025-03-31T14:14:01.998000+00:00)

I'm gonna attach a whole bunch of questions here now. See if you can use them to add more questions...


All these are tiny research questions we were trying to answer through research papers but failed. 

# Decision Making

### **1. When do executives act with limited information‚Äîand what gives them confidence?**

### üîç Deepening Questions:

- What kinds of **signals** (internal or external) help execs decide ‚Äúnow is the time to act‚Äù?
- What forms of **clarity** are most valued? (e.g., market signals, gut feeling, precedent)
- Is confidence rooted in **data**, **narrative coherence**, **leadership mandate**, or something else?
- How does **tolerance for ambiguity** vary across industries or company types?
- What distinguishes a ‚Äúwait and watch‚Äù mindset from a ‚Äúfirst mover‚Äù one?

### üß† Pattern Prompts:

- Are there certain *trigger conditions* (e.g., competitive pressure, internal dissent) that consistently nudge action?
- How do leaders frame *not acting* as a decision?

---

### **2. What distinguishes high-stakes from low-stakes decisions in an exec‚Äôs mind‚Äîand how does that shape behavior?**

### üîç Deepening Questions:

- What **criteria** are used to determine ‚Äústakes‚Äù? (e.g., financial exposure, visibility, reversibility, impact on culture)
- How does *stake perception* shape speed, delegation, and decision structure?
- Are ‚Äúhigh-stakes‚Äù decisions more centralized? More narrative-driven?
- In what scenarios do leaders **overestimate or underestimate** stakes?

### üß† Pattern Prompts:

- Are stakes understood differently in regulated vs. unregulated industries?
- How is *emotional* weight (e.g., ‚Äúthis affects my legacy‚Äù) playing a role?

---

### **3. How do execs decide to stay the course vs. pivot?**

### üîç Deepening Questions:

- What kinds of **feedback** (quantitative, qualitative, narrative) trigger a reassessment?
- How are early signs of failure **interpreted or reframed**?
- When is sticking with a plan seen as *strategic discipline* vs. *rigidity*?
- Do executives pivot more often when pressure is internal (team tension) or external (market feedback)?
- What past experiences shape a bias toward reversal vs. perseverance?

### üß† Pattern Prompts:

- Do pivots tend to happen at predictable inflection points (e.g., quarterly review, new leadership)?
- How do pivots get *socialized* internally?

---

### **4. What inputs do execs weigh most‚Äîdata, advisors, culture‚Äîand how do those priorities shift?**

### üîç Deepening Questions:

- What *types* of data are treated as authoritative? What is treated as noise?
- Who has *credible voice* in the room? (e.g., internal teams, external consultants, board members)
- How does **company culture** mediate which voices are heard?
- Are some industries more **data-dominant** than others?
- Does the decision shift when the stakes touch **values**, not just metrics?

### üß† Pattern Prompts:

- Are there examples where culture **overrode** data?
- Do smaller companies rely more on **relational inputs** vs. formal data?

---

### **5. How do execs balance short-term pressure with long-term vision?**

### üîç Deepening Questions:

- What tools or practices support *dual-time horizon thinking*?
- How do leaders frame long-term vision to **justify short-term pain**?
- When do quarterly results *override* long-term goals?
- Is ‚Äúvision‚Äù often held as a static north star, or recalibrated?
- What structural pressures (investors, boards, cash flow) distort this balance?

### üß† Pattern Prompts:

- Are long-term goals more narrative-driven, symbolic, or data-backed?
- How is **hope** maintained when short-term conditions worsen?

---

### **6. How does company size or stage shape decision-making and delegation?**

### üîç Deepening Questions:

- What decisions **can‚Äôt be delegated** in early-stage companies? How does that change over time?
- Do startups move faster because of agility, or because of lower perceived risk?
- How does **information structure** change‚Äîwho sees what, and when?
- Is there more **individual discretion** in startups and more **process discipline** in enterprises?

### üß† Pattern Prompts:

- Are mid-sized firms caught between startup agility and enterprise formality?
- How does **stage of growth** influence the use of data vs. gut?

---

### **7. How do industry/culture shape decision-making styles‚Äîand what assumptions live under the surface?**

### üîç Deepening Questions:

- Are some industries (e.g. pharma, aerospace) biased toward **risk-aversion**, while others (e.g., tech, media) favor **experimentation**?
- How does **organizational culture** manifest in decision cadence, tone, and participation?
- Are decisions framed more **technically** (what is optimal) or **socially** (what will land well)?
- What unspoken rules govern authority and dissent?

### üß† Pattern Prompts:

- What is *assumed* to be common sense in one industry that would be *radical* in another?
- How do legacy companies and disruptors diverge in mental models?

# Challenges in Decision Making

### **1. What makes certain strategic decisions especially difficult‚Äîand how do execs navigate the mess?**

### üîç Deepening Questions:

- Is the difficulty **cognitive** (ambiguity), **emotional** (risk of regret), or **relational** (misalignment)?
- Are these decisions hard because of what's **at stake**, or because of **how visible** they are?
- How does second-guessing show up‚Äîand when is it healthy vs. corrosive?
- How do execs manage the **psychological stress** of doubt, ambiguity, or high consequence?
- What practices, frameworks, or rituals help them ‚Äúsit with‚Äù a hard decision?

### üß† Pattern Prompts:

- Look for cases where the problem isn‚Äôt technical‚Äîit‚Äôs *relational* or *existential*
- Identify decision types that repeatedly trigger anxiety, delay, or avoidance
- Pay attention to **signals of discomfort**, not just outcomes

---

### **2. What are the most common internal bottlenecks or frictions‚Äîand how do they derail strategy?**

### üîç Deepening Questions:

- What roles do **politics, misalignment, incentives**, or **hierarchy** play in slowing things down?
- Where do *power dynamics* show up subtly? (e.g., "We had the data, but nobody wanted to touch it.")
- How do stakeholder conflicts manifest? Who gets left out, and why?
- Does organizational culture encourage **challenging assumptions** or suppress dissent?
- Where does **process rigidity** get in the way of adaptive action?

### üß† Pattern Prompts:

- What ‚Äúsilent forces‚Äù shape decision velocity or derail momentum?
- Are there **breakdowns of trust, transparency, or clarity**?
- Where do **feedback loops fail** to form or land?

---

### **3. How do execs weigh conflicting priorities‚Äîand what guides trade-offs?**

### üîç Deepening Questions:

- What kinds of conflicts arise most often? (e.g., growth vs. sustainability, speed vs. quality)
- Do executives frame trade-offs as **sacrifices**, **bets**, or **balancing acts**?
- What frameworks (explicit or implicit) guide these decisions?
- When is instinct trusted over analysis in these moments?
- How is trade-off *framed internally* to justify the final choice?

### üß† Pattern Prompts:

- Are trade-offs presented as **inevitable**, or **negotiable**?
- Is there evidence of ‚Äúpath dependency‚Äù (i.e., sunk cost logic)?
- Are there different trade-off styles by company size or stage?

---

### **4. What external pressures distort internal decision-making‚Äîand how do execs cope?**

### üîç Deepening Questions:

- How do investor demands, customer reactions, or media scrutiny influence decisions?
- What happens when *external timeframes* (e.g., quarterly pressure) conflict with *internal pacing*?
- Do execs filter external signals‚Äîor absorb them wholesale?
- What pressures get **voiced**, and which get **internalized silently**?
- How do execs justify acting against their better judgment due to external pressure?

### üß† Pattern Prompts:

- Look for patterns of **external overreach** (e.g., ‚Äúwe pivoted too fast because investors panicked‚Äù)
- Are some industries more externally volatile?
- Do leaders in large firms feel more **publicly accountable**?

---

### **5. When disruption happens, how do execs choose to pivot‚Äîor not?**

### üîç Deepening Questions:

- What kinds of signals are treated as **credible early warnings**?
- What makes a company *miss* the disruption (e.g., denial, overconfidence)?
- Is change resisted due to **ego**, **data skepticism**, or **operational inertia**?
- How is disruption *framed internally*‚Äîas threat, opportunity, or proof of failure?
- When do execs double down‚Äîand why?

### üß† Pattern Prompts:

- Are there **myths of stability** that get punctured?
- Is disruption handled better in flat orgs or hierarchical ones?
- What industries have stronger immune systems to outside change?

---

### **6. How do challenges differ by company size or complexity?**

### üîç Deepening Questions:

- What unique challenges do **startups** face in decision-making (e.g., resource scarcity, founder entrenchment)?
- What slows down large orgs‚Äî**bureaucracy, risk aversion, cultural entropy**?
- Do mid-sized firms suffer from **identity confusion**‚Äîtoo big to be nimble, too small to standardize?
- What gets *outsourced* to process in big firms that‚Äôs *held personally* in small ones?
- What lessons travel well across stages‚Äîand what doesn't?

### üß† Pattern Prompts:

- Are big firms *slow but stable*, or *rigid and brittle*?
- Where do startups *fail faster* because of unstructured chaos?
- Are the most impactful decisions in big firms actually *non-decisions*?

---

### **7. What concerns emerge during strategy-to-execution handoff‚Äîand how is strategic intent protected?**

### üîç Deepening Questions:

- What parts of strategy get **lost in translation**?
- Who ‚Äúowns‚Äù the strategy after it's handed off?
- What gets compromised under **operational pressure**?
- How do execs **monitor alignment** during execution?
- Is intent diluted by culture, misinterpretation, or capability gaps?

### üß† Pattern Prompts:

- Are execs involved past the vision stage‚Äîor do they ‚Äúset it and forget it‚Äù?
- How does leadership **signal commitment** beyond announcement moments?
- What mechanisms exist (or fail) to check fidelity to original goals?

# AI related questions

### **1. What makes AI feel like a *trusted strategic companion*, not just a tool?**

### üîç Deepening Questions:

- What kinds of tasks or decisions feel ‚Äúsafe‚Äù to share with AI‚Äîand which ones don‚Äôt?
- When does AI feel like an *extension of their thinking*, versus an *external black box*?
- What does ‚Äútrust‚Äù mean here‚Äîaccuracy? interpretability? alignment with human values?
- Does AI feel more trustworthy when it helps them **structure** ambiguity, or when it **reduces** it?
- What triggers ‚ÄúI trust this insight‚Äù vs. ‚ÄúThis feels wrong‚Äù?

### üß† Pattern Prompts:

- Look for language around **companionship, reflection, or co-creation**
- Watch for signs of **conditional trust** (‚ÄúI use it for X, but not for Y‚Äù)
- Identify moments where AI helps **make sense**, not just deliver results

---

### **2. How have past experiences (good or bad) shaped current openness to AI?**

### üîç Deepening Questions:

- Are executives *optimistic*, *burned*, *disillusioned*, or *neutral* based on prior AI exposure?
- Are there ‚Äúlegacy scars‚Äù from failed integrations or overhyped tools?
- What **positive surprises** have shifted their mental model of AI?
- Do personal or industry-wide examples influence their current posture?
- Is trust shaped more by *functionality* or *cultural narratives*?

### üß† Pattern Prompts:

- Look for stories of early adoption gone well‚Äîor gone wrong
- Does *exposure* increase curiosity, skepticism, or dependence?

---

### **3. What kinds of decisions or thinking are instinctively reserved for humans‚Äîand why?**

### üîç Deepening Questions:

- Where does ‚Äúthis is my call‚Äù show up?
- What kinds of decisions feel too **values-based**, **political**, or **intuitive** for AI to weigh in on?
- Is the resistance **ethical, emotional, or epistemic** (i.e., ‚ÄúAI can‚Äôt know what I know‚Äù)?
- Do execs feel that **judgment, accountability**, or **narrative ownership** should remain human?

### üß† Pattern Prompts:

- Are certain decision types universally reserved (e.g., firing someone, changing culture)?
- Look for cases where human responsibility is linked to *authenticity* or *legitimacy*

---

### **4. How do execs evaluate the *quality* of AI insights‚Äîespecially when they can‚Äôt verify them?**

### üîç Deepening Questions:

- Do they trust **confidence scores**, **explainability**, or **source references**?
- Are there thresholds for credibility (e.g., ‚Äúif it aligns with what I know,‚Äù or ‚Äúif it surprises me in a good way‚Äù)?
- How do they handle insights based on **public models** or **non-proprietary data**?
- What are the **implicit expectations of rigor** or *alignment with domain logic*?

### üß† Pattern Prompts:

- Look for proxy signals of quality: clarity, surprise, coherence, alignment
- Identify skepticism triggers (e.g., ‚Äúfeels generic,‚Äù ‚Äútoo polished,‚Äù ‚Äúdoesn‚Äôt get our business‚Äù)

---

### **5. In what ways do execs want AI to *challenge their assumptions*‚Äîand what does respectful challenge look like?**

### üîç Deepening Questions:

- Are there signs that execs want **friction, not just confirmation**?
- What would it mean for AI to ‚Äúpush back‚Äù‚Äîa counter-scenario? a provocative question? a historical analogy?
- What makes a challenge feel **provocative vs. disrespectful**?
- When do execs welcome challenge‚Äîand when do they shut it down?

### üß† Pattern Prompts:

- Look for appetite for **devil‚Äôs advocacy**, second opinions, or alternative framings
- Are there limits to how far AI should go in questioning a person‚Äôs stance?

---

### **6. What workflows or *thinking rituals* could AI naturally plug into without causing friction?**

### üîç Deepening Questions:

- When do execs already have *reflective moments*? Can AI join them there?
- Are there structured practices (e.g., pre-mortems, offsite strategy sessions, scenario planning) that AI could augment?
- Do they want AI to be *always on*, *invoked as needed*, or *reactive to context*?
- Is the barrier to AI *technical*, *cultural*, or *cognitive overload*?

### üß† Pattern Prompts:

- Look for natural pauses or loops in the thinking process where AI could gently enter
- Is AI most useful as a **thinking partner**, a **mirror**, or a **clarifier**?

---

### **7. What frameworks or models of strategy feel like a *natural fit* for AI‚Äîand where does it break down?**

### üîç Deepening Questions:

- Can AI plug into established strategic models (e.g., SWOT, Porter‚Äôs 5 Forces, scenario trees)?
- Where does AI support structure‚Äîand where does it feel clunky or reductive?
- When does AI *expand* strategic thinking, and when does it *flatten* nuance?
- Where does AI fail to ‚Äúget‚Äù the *human* or *relational* aspects of strategy?

### üß† Pattern Prompts:

- Look for frameworks that invite *simulation*, *exploration*, or *structured synthesis*
- Identify moments where AI‚Äôs limitations create strategic blind spots

## ChatGPT (2025-03-31T14:14:02.986698+00:00)

Thank you for sharing this rich set of research questions‚Äîthis is like a goldmine of unresolved signals you‚Äôre hoping to surface in conversation. I can clearly see the throughline: you're trying to **backdoor your way into complexity** through questions that are grounded, embodied, and behaviorally revealing‚Äînot abstract, speculative, or performative.

What I‚Äôll do is propose **tailored, conversation-ready questions** that map to each major research theme you've outlined‚Äîquestions that are lightweight enough to drop into a real-time interview, but carefully engineered to expose those deeper patterns you‚Äôre hunting for. I‚Äôll keep the tone and logic aligned with your previous ‚Äúdelegation lens‚Äù and your desire to keep things grounded in **real choices, tradeoffs, and lived moments**.

---

## üß≠ DECISION-MAKING QUESTIONS (inspired by your research prompts)

### **When do you act without full clarity‚Äîand why?**
> Can you remember a moment when you made a significant decision *without having all the information* you ideally wanted?  
> What gave you the confidence to move forward anyway?

*Follow-up*:  
- Was it a gut call, a pattern you recognized, pressure from above, or something else?
- What‚Äôs your signal that it‚Äôs time to stop gathering and start acting?

---

### **What feels *high-stakes* to you, and what does that trigger?**
> What kind of decisions *feel* high-stakes in your role?  
> Is it about visibility, risk, irreversibility‚Ä¶ something else?

*Follow-up*:  
- When something feels high-stakes, what changes about how you approach it? Do you slow down, loop in more voices, or shift into a different mode?

---

### **How do you know when to *stay the course* versus *pivot*?**
> Can you walk me through a time when you *changed your mind* mid-stream on a major initiative?  
> What pushed you over the edge?

*Follow-up*:  
- Do you look for a tipping point? Or is it more of a feeling that accumulates?

---

### **Whose input matters most‚Äîand when?**
> In big decisions, whose input has the most influence on you?  
> Is it data? Direct reports? Customers? Exec peers?

*Follow-up*:  
- Have you ever overruled the ‚Äúright data‚Äù because something didn‚Äôt sit right?
- Are there voices you seek out specifically to challenge you?

---

### **Balancing short-term vs. long-term thinking**
> In your day-to-day, what helps you stay connected to long-term vision‚Äîwhen short-term fires are everywhere?

*Follow-up*:  
- Is vision something you hold in your head, share with your team, or revisit through structured rituals?

---

### **Startup vs. scaled org decision dynamics**
> You‚Äôve worked in both startup-style teams and scaled orgs‚Äîwhat feels different about how decisions get made?

*Follow-up*:  
- Is speed really about fewer layers‚Äîor something else, like culture or ownership?

---

## üß† CHALLENGE-FRAMED QUESTIONS

### **What kind of decisions feel the most *psychologically heavy* for you?**
> What types of calls tend to keep you up at night‚Äîor make you hesitate more than usual?

*Follow-up*:  
- Is it because of ambiguity, potential backlash, or something more personal‚Äîlike your reputation or relationships?

---

### **Where do things break down inside the org?**
> Are there any common points where decisions get stuck, diluted, or misinterpreted between strategy and execution?

*Follow-up*:  
- Is it about clarity, politics, misalignment‚Äîor just too many layers?

---

### **How do you weigh trade-offs when priorities collide?**
> When two good things are in tension‚Äîlike speed vs. depth, or growth vs. risk‚Äîhow do you personally navigate that?

*Follow-up*:  
- Do you lean on frameworks, values, conversation‚Äîor your gut?

---

## ü§ñ AI + STRATEGIC TECH QUESTIONS

### **Where does AI belong in your decision-making process‚Äîif anywhere?**
> Is there any part of your product or strategy decision-making where you‚Äôve started leaning on AI‚Äîor where you *wish* it could help?

*Follow-up*:  
- Would you want it more as a pattern spotter, a challenger, a validator‚Ä¶ or something else entirely?

---

### **What‚Äôs something you‚Äôd never trust AI to handle?**
> Is there a category of judgment‚Äîbig or small‚Äîyou‚Äôd *never* want to outsource to AI, no matter how good it gets?

*Follow-up*:  
- Is that about ethics, ownership, nuance‚Ä¶ or just intuition?

---

### **What would ‚Äúrespectful challenge‚Äù look like from AI?**
> If an AI system were to challenge one of your assumptions, how would you want that to show up?  
> A counterfactual? A caution flag? A sharp question?

*Follow-up*:  
- Where‚Äôs the line between helpful nudge and annoying second-guessing?

---

### **Past experience shaping current trust**
> Have you had any past experiences with AI‚Äîgood or bad‚Äîthat still shape how open or skeptical you are now?

*Follow-up*:  
- Was there a moment where AI *surprised* you in a good way?

---

## üîÆ DESIGNING THE ROLE OR SYSTEM THEY SECRETLY WANT

I‚Äôm bringing back and expanding on your delegation-style approach, with even more precision.

### **Delegation Mirror:**
> Let‚Äôs say the company hired someone just like you‚Äîsame skills, same brain‚Äîbut they could only handle the stuff that *you personally wish you didn‚Äôt have to do*.  
> What would you delegate immediately? And what would you *never* let go of?

---

### **‚ÄúGhost PM‚Äù Prompt:**
> Imagine you had a shadow PM that could quietly handle one entire type of decision for you.  
> What kind of decision would you hand off‚Äîand what would you *insist* on keeping in your own hands?

---

### **Role Creation as Strategic Self-Reflection:**
> If you could invent a new role on your team that would 10x your impact‚Äîbut not replace you‚Äîwhat would that person do all day?

*Follow-up*:  
- Would they be cleaning up coordination messes? Building product narratives? Making signals out of noise?

---

### **Workflow Insertion:**
> If an AI system could slot into *just one* moment of your week without disrupting your flow, where would it be most helpful?

*Follow-up*:  
- Would you want it in a pre-read, a 1:1, a roadmap review‚Ä¶ or just sitting quietly in your inbox surfacing weird patterns?

---

Let me know if you want these clustered by theme (e.g. decision clarity, organizational friction, AI trust), or turned into a script format. Also happy to cross-map each to your original research prompt for auditability, if you want to trace the question to its underlying research question.

Would that be useful to you?

## You (2025-03-31T14:20:37.448000+00:00)

I'll tell you the questions I like. Lets keep them for sure, the rest we can probably eliminate. Remember, its a 30 minute call and usually the first 5 go in introductions. 


Can you remember a moment when you made a significant decision without having all the information you ideally wanted?
What gave you the confidence to move forward anyway?
Follow-up:

Was it a gut call, a pattern you recognized, pressure from above, or something else?
What‚Äôs your signal that it‚Äôs time to stop gathering and start acting?

In big decisions, whose input has the most influence on you?
Is it data? Direct reports? Customers? Exec peers?
Follow-up:

Have you ever overruled the ‚Äúright data‚Äù because something didn‚Äôt sit right?
Are there voices you seek out specifically to challenge you?

In your day-to-day, what helps you stay connected to long-term vision‚Äîwhen short-term fires are everywhere? (this can be rephrased as, "We've found in our research that short term goals tend to often interfere with long-term vision. and that businesses tend to try and make long term goals revert to short term urgencies. Could you talk about instances where short term goals have interfered with long term vision?" something like that"
Follow-up:

Is vision something you hold in your head, share with your team, or revisit through structured rituals?


You‚Äôve worked in both startup-style teams and scaled orgs‚Äîwhat feels different about how decisions get made? (this is excellent)
Follow-up:

Is speed really about fewer layers‚Äîor something else, like culture or ownership?

